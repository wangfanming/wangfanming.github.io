<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hadoop-2.7.2高可用集群搭建(Ubuntu14.04)</title>
    <url>/2020/08/31/Hadoop-2.7.2%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA/</url>
    <content><![CDATA[<p><strong>以root用户身份进行配置</strong></p>
<h3 id="环境需求："><a href="#环境需求：" class="headerlink" title="环境需求："></a>环境需求：</h3><ul>
<li>JDK版本：1.7+</li>
<li>Hadoop版本：hadoop-2.7.2</li>
<li>zookeeper版本：zookeeper-3.4.5</li>
</ul>
<span id="more"></span>

<h4 id="详细配置"><a href="#详细配置" class="headerlink" title="详细配置"></a>详细配置</h4><table>
<thead>
<tr>
<th>主机名IP</th>
<th align="center">Namenode</th>
<th align="right">Datanode</th>
<th align="right">Yarn</th>
<th align="right">Zookeeper</th>
<th align="right">JournalNode</th>
</tr>
</thead>
<tbody><tr>
<td>node-1:192.168.111.130</td>
<td align="center">是</td>
<td align="right">是</td>
<td align="right">否</td>
<td align="right">是</td>
<td align="right">是</td>
</tr>
<tr>
<td>node-2:192.168.111.129</td>
<td align="center">是</td>
<td align="right">是</td>
<td align="right">是</td>
<td align="right">是</td>
<td align="right">是</td>
</tr>
<tr>
<td>node-3:192.168.111.128</td>
<td align="center">否</td>
<td align="right">是</td>
<td align="right">是</td>
<td align="right">是</td>
<td align="right">是</td>
</tr>
</tbody></table>
<p>1、安装JDK</p>
<p> (1)  下载 jdk-7u80-linux-x64.tar 文件</p>
<p> (2)  解压缩文件 tar -zxvf jdk-7u80-linux-x64.tar(尽量使用jdk1.7)</p>
<p> (3)  在 &#x2F;etc&#x2F;profile文件末尾，添加jdk的配置信息</p>
<p> (4) 重新加载文件，使配置生效：#source &#x2F;etc&#x2F;profile</p>
<p> 2、配置SSH免密登陆</p>
<blockquote>
<p>SSH免密钥原理：<br>      我们使用ssh-keygen在ServerA上生成私钥跟公钥，将生成的公钥拷贝到远程机器ServerB上后,就可以使用ssh命令无需密码登录到另外一台机器ServerB上。生成公钥与私钥有两种加密方式，第一种是rsa(默认)，还有一种是dsa,使用时两种方式随便选一种即可</p>
</blockquote>
<p>  (1) 安装SSH服务<br>  <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">apt-get install ssh</span></span><br></pre></td></tr></table></figure></p>
<p>  (2) 在三个节点上分别都使用rsa加密生成密钥对<br>  <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">ssh-keygen -t rsa</span></span><br></pre></td></tr></table></figure><br>   按3次Enter键后，会在&#x2F;root&#x2F;.ssh&#x2F;下生成id_rsa (私钥)，和id_rsa.pub(公钥)</p>
<p>  (3) 将node-1上，将id_rsa.pub读取到authorized_keys中(authorized_keys 第一次读入是不存在的)<br>  <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">cat</span> ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys</span></span><br></pre></td></tr></table></figure></p>
<p>  (4) 分别将node-2和node-3上的公钥都读入到master的authorized_keys中</p>
<pre><code>   在node-2和node-3上：
        #scp /root/.ssh/id_rsa.pub  master:/root/
   在node-1上：
   每收到一个公钥都读取一次(一个一个地写入文件)：
        # cat /root/id_rsa.pub &gt;&gt; /root/.ssh/authorized_keys
</code></pre>
<p>  (5) 将node-1上的authorized_keys发送到node-2和node-3，以实现三个节点之间的免密钥登录<br>  <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">scp /root/.ssh/authorized_keys   node-2:/root/.ssh/</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">scp /root/.ssh/authorized_keys   node-3:/root/.ssh/</span></span><br></pre></td></tr></table></figure></p>
<p>  (6) 在3个节点上修改authorized_keys的权限：<br>  <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">chmod</span> 600 ~/.ssh/authorized_keys</span></span><br></pre></td></tr></table></figure></p>
<p> 3、Zookeeper集群搭建</p>
<p>  (1) 下载zookeeper-3.4.9.tar.gz</p>
<p>  (2)  解压<br>   <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">tar -zxvf zookeeper-3.4.9.tar.gz -C /home/</span></span><br></pre></td></tr></table></figure><br>  (3) 修改zoo.cfg（可以使用zoo_sample.cfg来生成zoo.cfg）<br>   <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash"><span class="built_in">cp</span> zoo_sample.cfg zoo.cfg</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">vim zoo.cfg</span></span><br></pre></td></tr></table></figure></p>
<p>   <strong>参数说明</strong>:</p>
<ul>
<li>tickTime: zookeeper中使用的基本时间单位, 毫秒值.</li>
<li>dataDir: 数据目录. 可以是任意目录.</li>
<li>dataLogDir: log目录, 同样可以是任意目录. 如果没有设置该参数, 将使用和dataDir相同的设置.</li>
<li>clientPort: 监听client连接的端口号.</li>
<li>server.X&#x3D;A:B:C 其中X是一个数字, 表示这是第几号server. A是该server所在的IP地址. B配置该server和集群中的leader交换消息所使用的端口. C配置选举leader时所使用的端口. 由于配置的是伪集群模式, 所以各个server的B, C参数必须不同.</li>
</ul>
<p>  (4). 根据zoo.cfg各自在节点上的 dataDir下添加myid</p>
<pre><code>    node-1：
            #echo &quot;1&quot; &gt;&gt; /home/zookeeperData/myid
    node-2:
            #echo &quot;2&quot; &gt;&gt; /home/zookeeperData/myid
    node-3:
            #echo &quot;3&quot; &gt;&gt; /home/zookeeperData/myid
</code></pre>
<p>  (5) 在各个节点上开启zookeeper服务,并且查看服务是否成功启动<br>   <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">zkServer.sh start</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">zkServer.sh status</span></span><br></pre></td></tr></table></figure></p>
<p>4、Hadoop集群的搭建</p>
<p>   (1) 下载 hadoop-2.7.2.tar.gz,并解压<br>   <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -zxvf  hadoop-2.7.2.tar.gz -C /home/</span><br></pre></td></tr></table></figure><br>   (2)修改如下配置文件(在&#x2F;home&#x2F;hadoop-2.7.2&#x2F;etc&#x2F;hadoop&#x2F;下)</p>
<p>   <strong>修改core-site.xml</strong><br>   <figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://nameserver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hdfs_all/tmp/<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>io.file.buffer.size<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>1024<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">name</span>&gt;</span>ha.zookeeper.quorum<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">         <span class="tag">&lt;<span class="name">value</span>&gt;</span>node-1:2181,node-2:2181,node-3:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"> <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><br>   <strong>修改hdfs-site.xml</strong><br>   <figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.nameservices<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>nameserver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.namenodes.nameserver<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">value</span>&gt;</span>nn1,nn2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.nameserver.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">value</span>&gt;</span>node-1:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.nameserver.nn1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>node-1:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.rpc-address.nameserver.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">value</span>&gt;</span>node-2:9000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.http-address.nameserver.nn2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>node-2:50070<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.shared.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">value</span>&gt;</span>qjournal://node-1:8485;node-2:8485;node-3:8485/nameserver<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.journalnode.edits.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">              <span class="tag">&lt;<span class="name">value</span>&gt;</span>/home/hdfs_all/journal<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">              <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.automatic-failover.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">              <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.client.failover.proxy.provider.nameserver<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                 <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.methods<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                 <span class="tag">&lt;<span class="name">value</span>&gt;</span>sshfence<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.ha.fencing.ssh.private-key-files<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>/root/.ssh/id_rsa<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///home/hdfs_all/hdfs/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.datanode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:///home/hdfs_all/hdfs/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">           <span class="tag">&lt;<span class="name">value</span>&gt;</span>2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">     <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<p>   <strong>修改mapred-site.xml</strong>(刚解压的文件中没有给文件，将mapred-site-tempalte.xml复制一份即可)<br>   <figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.framework.name<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">value</span>&gt;</span>yarn<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><br>   <strong>修改yarn-site.xml</strong></p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">    </span><br><span class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 开启RM高可用 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定RM的cluster id --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.cluster-id<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>yrc<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定RM的名字 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.ha.rm-ids<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>rm1,rm2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 分别指定RM的地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm1<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>node-2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.hostname.rm2<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>node-3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 指定zk集群地址 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.resourcemanager.zk-address<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>node-1:2181,node-2:2181,node-3:2181<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>yarn.nodemanager.aux-services<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>mapreduce_shuffle<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>修改slaves</strong></p>
<p>  删除<code>localhost</code>,添加如下内容：<br>  <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">node-1</span><br><span class="line">node-2</span><br><span class="line">node-3</span><br></pre></td></tr></table></figure><br><strong>修改JAVA_HOME</strong></p>
<p>分别在文件hadoop-env.sh和yarn-env.sh中添加JAVA_HOME配置</p>
<p><img src="/images/java_home.bmp"></p>
<p>5、将hadoop配置文件发送至另外两个节点</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scp -r /home/hadoop-2.7.2  node-2:/home/</span><br><span class="line">scp -r /home/hadoop-2.7.2  node-3:/home/</span><br></pre></td></tr></table></figure>
<p>6、给Hadoop配置环境变量(完整的环境变量配置如下)</p>
<p><img src="/images/%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F.bmp"></p>
<p>7、将环境变量发送给另外两个节点</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">scp -r /etc/profile  node-2:/etc</span><br><span class="line">scp -r /etc/profile  node-3:/etc</span><br></pre></td></tr></table></figure>

<p><strong>在发送完成后，都要使用<code>source /etc/profile</code>命令重新加载环境变量</strong></p>
<p>8、启动集群</p>
<p><strong>按顺序执行以下操作</strong></p>
<p>在node-1上：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">zkServer.sh start</span><br><span class="line">zkServer.sh status(要确保zookeeper服务已经启动)</span><br><span class="line">hadoop-daemons.sh start journalnode   (启动journalnode服务)</span><br><span class="line">hdfs zkfc –formatZK(格式化zkfc,让在zookeeper中生成ha节点,只需在第一次启动集群是格式化即可)</span><br><span class="line"></span><br><span class="line">hadoop namenode -format (格式化hdfs,也只在第一次启动集群时格式化)</span><br><span class="line">hadoop-daemon.sh start namenode</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>在node-2上(设置node-2为备份的namenode,所以需要在node-2上启动namenode进程)：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hdfs namenode -bootstrapStandby(在第一次启动时执行)</span><br><span class="line">hadoop-daemon.sh start namenode</span><br></pre></td></tr></table></figure>
<p>启动datanode(任意节点都可以):</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hadoop-daemons.sh start datanode</span><br></pre></td></tr></table></figure>
<p>在node-3上启动yarn；</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">start-yarn.sh</span><br></pre></td></tr></table></figure>
<p>启动zkfc服务(任意节点都可以):</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hadoop-daemons.sh start zkfc</span><br></pre></td></tr></table></figure>



<p>然后就可以Web进行访问了</p>
<p><a href="http://node-1:50070/">http://node-1:50070</a></p>
<p><a href="http://node-2:50070/">http://node-2:50070</a></p>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
        <tag>HA</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM的知识点总结</title>
    <url>/2022/10/02/JVM%E7%9A%84%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/</url>
    <content><![CDATA[<h1 id="JVM的知识点总结"><a href="#JVM的知识点总结" class="headerlink" title="JVM的知识点总结"></a>JVM的知识点总结</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>JVM作为Java的基石，掌握其运行原理，有助于我们深入理解这门语言的设计初衷，更好的把握我们写下的每一行代码。内容包括：JVM运行时区域、垃圾回收、垃圾回收器、Hotspot算法实现过程、类加载机制、Hotspot对象</p>
<span id="more"></span>

<h3 id="JVM运行时区域"><a href="#JVM运行时区域" class="headerlink" title="JVM运行时区域"></a>JVM运行时区域</h3><p><img src="F:\study\blog\source\images\JVM运行时内存区域.png" alt="JVM运行时区域"></p>
<h3 id="垃圾回收"><a href="#垃圾回收" class="headerlink" title="垃圾回收"></a>垃圾回收</h3><p><img src="F:\study\blog\source\images\JVM垃圾回收.png" alt="垃圾回收"></p>
<h3 id="HotSpot的算法实现细节"><a href="#HotSpot的算法实现细节" class="headerlink" title="HotSpot的算法实现细节"></a>HotSpot的算法实现细节</h3><p><img src="F:\study\blog\source\images\HotSpot的算法实现细节.png" alt="HotSpot的算法实现细节"></p>
<h3 id="HotSpot-VM对象"><a href="#HotSpot-VM对象" class="headerlink" title="HotSpot VM对象"></a>HotSpot VM对象</h3><p>![HotSpot VM对象](F:\study\blog\source\images\HotSpot VM对象.png)</p>
<h3 id="类加载过程"><a href="#类加载过程" class="headerlink" title="类加载过程"></a>类加载过程</h3><p><img src="F:\study\blog\source\images\JVM类加载机制.png" alt="类加载过程"></p>
]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title>Kafka日志查找过程</title>
    <url>/2023/05/15/Kafka%E6%97%A5%E5%BF%97%E6%9F%A5%E6%89%BE%E8%BF%87%E7%A8%8B/</url>
    <content><![CDATA[<h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>Kafka基于顺序读写实现了对消息数据的快速检索，以下是其检索过程的分析</p>
<span id="more"></span>

<h3 id="Kafka日志存储基础"><a href="#Kafka日志存储基础" class="headerlink" title="Kafka日志存储基础"></a>Kafka日志存储基础</h3><ul>
<li><p>&lt;segment基础位移&gt;.index 位移索引文件</p>
<ul>
<li>其中记录了相对偏移量和物理偏移量</li>
<li>相对偏移量是针对当前Segment文件的第一条记录的偏移量</li>
</ul>
<figure class="highlight txt"><table><tr><td class="code"><pre><span class="line">Dumping 00000000000000000000.index</span><br><span class="line">offset: 39 position: 4527</span><br><span class="line">offset: 84 position: 9067</span><br><span class="line">offset: 143 position: 16039</span><br><span class="line">offset: 172 position: 20205</span><br><span class="line">offset: 218 position: 24668</span><br><span class="line">offset: 257 position: 29917</span><br><span class="line">offset: 290 position: 35025</span><br><span class="line">offset: 344 position: 39462</span><br><span class="line">offset: 389 position: 45985</span><br></pre></td></tr></table></figure>
</li>
<li><p>&lt;segment基础位移&gt;.timeindex 时间戳索引文件</p>
<ul>
<li>其中的记录项如 [timestamp: 1711530458508 offset: 172]，表明相对位移为172的batch的写入时间戳为1711530458508 。</li>
</ul>
<figure class="highlight txt"><table><tr><td class="code"><pre><span class="line">Dumping 00000000000000000000.timeindex</span><br><span class="line">timestamp: 1711530458431 offset: 39</span><br><span class="line">timestamp: 1711530458453 offset: 84</span><br><span class="line">timestamp: 1711530458490 offset: 143</span><br><span class="line">timestamp: 1711530458508 offset: 172</span><br><span class="line">timestamp: 1711530458538 offset: 218</span><br><span class="line">timestamp: 1711530458563 offset: 257</span><br><span class="line">timestamp: 1711530458584 offset: 290</span><br><span class="line">timestamp: 1711530458650 offset: 344</span><br><span class="line">timestamp: 1711530458683 offset: 389</span><br></pre></td></tr></table></figure>
</li>
<li><p>&lt;segment基础位移&gt;.log消息日志文件</p>
<ul>
<li>记录了每批次的消息日志数据，包含了基础offset、批消息大小、消息条数、position等</li>
</ul>
<figure class="highlight txt"><table><tr><td class="code"><pre><span class="line">Dumping 00000000000000000000.log</span><br><span class="line">Starting offset: 0</span><br><span class="line">baseOffset: 0 lastOffset: 7 count: 8 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 4 isTransactional: false isControl: false position: 0 CreateTime: 1711530458388 size: 902 magic: 2 compresscodec: NONE crc: 1847615439 isvalid: true</span><br><span class="line">| offset: 0 CreateTime: 1711530458378 keysize: 9 valuesize: 83 sequence: -1 headerKeys: [] key: 四川省 payload: &#123;&quot;province&quot;:&quot;四川省&quot;,&quot;city&quot;:&quot;内江市&quot;,&quot;county&quot;:&quot;隆昌县&quot;,&quot;zipCode&quot;:&quot;511028&quot;&#125;</span><br><span class="line">| offset: 1 CreateTime: 1711530458378 keysize: 9 valuesize: 80 sequence: -1 headerKeys: [] key: 四川省 payload: &#123;&quot;province&quot;:&quot;四川省&quot;,&quot;city&quot;:&quot;达州市&quot;,&quot;county&quot;:&quot;渠县&quot;,&quot;zipCode&quot;:&quot;511725&quot;&#125;</span><br><span class="line">| offset: 2 CreateTime: 1711530458379 keysize: 9 valuesize: 83 sequence: -1 headerKeys: [] key: 四川省 payload: &#123;&quot;province&quot;:&quot;四川省&quot;,&quot;city&quot;:&quot;雅安市&quot;,&quot;county&quot;:&quot;雨城区&quot;,&quot;zipCode&quot;:&quot;511802&quot;&#125;</span><br><span class="line">| offset: 3 CreateTime: 1711530458382 keysize: 9 valuesize: 83 sequence: -1 headerKeys: [] key: 四川省 payload: &#123;&quot;province&quot;:&quot;四川省&quot;,&quot;city&quot;:&quot;乐山市&quot;,&quot;county&quot;:&quot;市中区&quot;,&quot;zipCode&quot;:&quot;511102&quot;&#125;</span><br><span class="line">| offset: 4 CreateTime: 1711530458386 keysize: 9 valuesize: 95 sequence: -1 headerKeys: [] key: 四川省 payload: &#123;&quot;province&quot;:&quot;四川省&quot;,&quot;city&quot;:&quot;甘孜藏族自治州&quot;,&quot;county&quot;:&quot;巴塘县&quot;,&quot;zipCode&quot;:&quot;513335&quot;&#125;</span><br><span class="line">| offset: 5 CreateTime: 1711530458386 keysize: 9 valuesize: 95 sequence: -1 headerKeys: [] key: 四川省 payload: &#123;&quot;province&quot;:&quot;四川省&quot;,&quot;city&quot;:&quot;凉山彝族自治州&quot;,&quot;county&quot;:&quot;雷波县&quot;,&quot;zipCode&quot;:&quot;513437&quot;&#125;</span><br><span class="line">| offset: 6 CreateTime: 1711530458386 keysize: 9 valuesize: 83 sequence: -1 headerKeys: [] key: 四川省 payload: &#123;&quot;province&quot;:&quot;四川省&quot;,&quot;city&quot;:&quot;泸州市&quot;,&quot;county&quot;:&quot;合江县&quot;,&quot;zipCode&quot;:&quot;510522&quot;&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
<h4 id="如何查找时间戳1711530458631开始的消息？"><a href="#如何查找时间戳1711530458631开始的消息？" class="headerlink" title="如何查找时间戳1711530458631开始的消息？"></a>如何查找时间戳1711530458631开始的消息？</h4><ol>
<li><p>查找所有日志分段（.log）对应的时间戳索引（.timeindex）中比时间戳1711530458631大的最小时间戳所在的日志分段文件（.log），假如满足该要求的日志分段文件为00000000000000000000.log，则取其对应的时间戳索引文件00000000000000000000.timeindex</p>
</li>
<li><p>在时间戳索引文件00000000000000000000.timeindex中，查找 &gt;&#x3D; 1711530458631的最小时间戳所在项</p>
<figure class="highlight txt"><table><tr><td class="code"><pre><span class="line">timestamp: 1711530458650 offset: 344</span><br></pre></td></tr></table></figure>
</li>
<li><p>根据查找到的相对偏移量offset: 344，在偏移量索引文件中查找 &gt;&#x3D; 344的最小相对偏移量所在项</p>
<figure class="highlight txt"><table><tr><td class="code"><pre><span class="line">offset: 344 position: 39462</span><br></pre></td></tr></table></figure>
</li>
<li><p>根据查找到的position: 39462，在日志分段文件中查找时间戳1711530458631所在的batch</p>
<figure class="highlight txt"><table><tr><td class="code"><pre><span class="line">baseOffset: 327 lastOffset: 344 count: 18 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 4 isTransactional: false isControl: false position: 39462 CreateTime: 1711530458650 size: 1981 magic: 2 compresscodec: NONE crc: 2524610504 isvalid: true</span><br><span class="line">| offset: 327 CreateTime: 1711530458625 keysize: 9 valuesize: 95 sequence: -1 headerKeys: [] key: 四川省 payload: &#123;&quot;province&quot;:&quot;四川省&quot;,&quot;city&quot;:&quot;凉山彝族自治州&quot;,&quot;county&quot;:&quot;越西县&quot;,&quot;zipCode&quot;:&quot;513434&quot;&#125;</span><br><span class="line">| offset: 328 CreateTime: 1711530458627 keysize: 9 valuesize: 83 sequence: -1 headerKeys: [] key: 四川省 payload: &#123;&quot;province&quot;:&quot;四川省&quot;,&quot;city&quot;:&quot;成都市&quot;,&quot;county&quot;:&quot;大邑县&quot;,&quot;zipCode&quot;:&quot;510129&quot;&#125;</span><br><span class="line">| offset: 329 CreateTime: 1711530458629 keysize: 9 valuesize: 104 sequence: -1 headerKeys: [] key: 四川省 payload: &#123;&quot;province&quot;:&quot;四川省&quot;,&quot;city&quot;:&quot;阿坝藏族羌族自治州&quot;,&quot;county&quot;:&quot;若尔盖县&quot;,&quot;zipCode&quot;:&quot;513232&quot;&#125;</span><br><span class="line">| offset: 330 CreateTime: 1711530458630 keysize: 9 valuesize: 83 sequence: -1 headerKeys: [] key: 四川省 payload: &#123;&quot;province&quot;:&quot;四川省&quot;,&quot;city&quot;:&quot;达州市&quot;,&quot;county&quot;:&quot;大竹县&quot;,&quot;zipCode&quot;:&quot;511724&quot;&#125;</span><br><span class="line">| offset: 331 CreateTime: 1711530458630 keysize: 9 valuesize: 83 sequence: -1 headerKeys: [] key: 四川省 payload: &#123;&quot;province&quot;:&quot;四川省&quot;,&quot;city&quot;:&quot;广安市&quot;,&quot;county&quot;:&quot;岳池县&quot;,&quot;zipCode&quot;:&quot;511621&quot;&#125;</span><br><span class="line">| offset: 332 CreateTime: 1711530458632 keysize: 9 valuesize: 101 sequence: -1 headerKeys: [] key: 四川省 payload: &#123;&quot;province&quot;:&quot;四川省&quot;,&quot;city&quot;:&quot;阿坝藏族羌族自治州&quot;,&quot;county&quot;:&quot;黑水县&quot;,&quot;zipCode&quot;:&quot;513228&quot;&#125;</span><br><span class="line">| offset: 333 CreateTime: 1711530458633 keysize: 9 valuesize: 77 sequence: -1 headerKeys: [] key: 四川省 payload: &#123;&quot;province&quot;:&quot;四川省&quot;,&quot;city&quot;:&quot;广安市&quot;,&quot;county&quot;:&quot;前锋区&quot;,&quot;zipCode&quot;:&quot;&quot;&#125;</span><br><span class="line">| offset: 334 CreateTime: 1711530458633 keysize: 9 valuesize: 83 sequence: -1 headerKeys: [] key: 四川省 payload: &#123;&quot;province&quot;:&quot;四川省&quot;,&quot;city&quot;:&quot;雅安市&quot;,&quot;county&quot;:&quot;芦山县&quot;,&quot;zipCode&quot;:&quot;511826&quot;&#125;</span><br><span class="line">| offset: 335 CreateTime: 1711530458633 keysize: 9 valuesize: 86 sequence: -1 headerKeys: [] key: 四川省 payload: &#123;&quot;province&quot;:&quot;四川省&quot;,&quot;city&quot;:&quot;成都市&quot;,&quot;county&quot;:&quot;龙泉驿区&quot;,&quot;zipCode&quot;:&quot;510112&quot;&#125;</span><br><span class="line">| offset: 336 CreateTime: 1711530458634 keysize: 9 valuesize: 83 sequence: -1 headerKeys: [] key: 四川省 payload: &#123;&quot;province&quot;:&quot;四川省&quot;,&quot;city&quot;:&quot;南充市&quot;,&quot;county&quot;:&quot;仪陇县&quot;,&quot;zipCode&quot;:&quot;511324&quot;&#125;</span><br><span class="line">| offset: 337 CreateTime: 1711530458634 keysize: 9 valuesize: 95 sequence: -1 headerKeys: [] key: 四川省 payload: &#123;&quot;province&quot;:&quot;四川省&quot;,&quot;city&quot;:&quot;甘孜藏族自治州&quot;,&quot;county&quot;:&quot;稻城县&quot;,&quot;zipCode&quot;:&quot;513337&quot;&#125;</span><br><span class="line">| offset: 338 CreateTime: 1711530458636 keysize: 9 valuesize: 95 sequence: -1 headerKeys: [] key: 四川省 payload: &#123;&quot;province&quot;:&quot;四川省&quot;,&quot;city&quot;:&quot;凉山彝族自治州&quot;,&quot;county&quot;:&quot;布拖县&quot;,&quot;zipCode&quot;:&quot;513429&quot;&#125;</span><br><span class="line">| offset: 339 CreateTime: 1711530458640 keysize: 9 valuesize: 101 sequence: -1 headerKeys: [] key: 四川省 payload: &#123;&quot;province&quot;:&quot;四川省&quot;,&quot;city&quot;:&quot;阿坝藏族羌族自治州&quot;,&quot;county&quot;:&quot;黑水县&quot;,&quot;zipCode&quot;:&quot;513228&quot;&#125;</span><br><span class="line">| offset: 340 CreateTime: 1711530458642 keysize: 9 valuesize: 83 sequence: -1 headerKeys: [] key: 四川省 payload: &#123;&quot;province&quot;:&quot;四川省&quot;,&quot;city&quot;:&quot;遂宁市&quot;,&quot;county&quot;:&quot;射洪县&quot;,&quot;zipCode&quot;:&quot;510922&quot;&#125;</span><br><span class="line">| offset: 341 CreateTime: 1711530458643 keysize: 9 valuesize: 83 sequence: -1 headerKeys: [] key: 四川省 payload: &#123;&quot;province&quot;:&quot;四川省&quot;,&quot;city&quot;:&quot;成都市&quot;,&quot;county&quot;:&quot;蒲江县&quot;,&quot;zipCode&quot;:&quot;510131&quot;&#125;</span><br><span class="line">| offset: 342 CreateTime: 1711530458650 keysize: 9 valuesize: 95 sequence: -1 headerKeys: [] key: 四川省 payload: &#123;&quot;province&quot;:&quot;四川省&quot;,&quot;city&quot;:&quot;甘孜藏族自治州&quot;,&quot;county&quot;:&quot;乡城县&quot;,&quot;zipCode&quot;:&quot;513336&quot;&#125;</span><br><span class="line">| offset: 343 CreateTime: 1711530458650 keysize: 9 valuesize: 83 sequence: -1 headerKeys: [] key: 四川省 payload: &#123;&quot;province&quot;:&quot;四川省&quot;,&quot;city&quot;:&quot;德阳市&quot;,&quot;county&quot;:&quot;中江县&quot;,&quot;zipCode&quot;:&quot;510623&quot;&#125;</span><br><span class="line">| offset: 344 CreateTime: 1711530458650 keysize: 9 valuesize: 83 sequence: -1 headerKeys: [] key: 四川省 payload: &#123;&quot;province&quot;:&quot;四川省&quot;,&quot;city&quot;:&quot;宜宾市&quot;,&quot;county&quot;:&quot;宜宾县&quot;,&quot;zipCode&quot;:&quot;511521&quot;&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>根据查找到的消息内容可以看出，相对偏移量为332的消息开始，就是满足查询条件的消息开始位置。</p>
</li>
</ol>
<h4 id="如何查找offset为3948的消息？"><a href="#如何查找offset为3948的消息？" class="headerlink" title="如何查找offset为3948的消息？"></a>如何查找offset为3948的消息？</h4><ol>
<li><p>根据Kafka维护的ConcurrentSkipListMap维护的每个分段内偏移量的位置，快速查找到offset&#x3D;3948的消息所在的位移索引文件00000000000000003839.index</p>
</li>
<li><p>在00000000000000003839.index中，找到 &lt;&#x3D; 3948的最大索引项offset: 3898 position: 6829</p>
<figure class="highlight txt"><table><tr><td class="code"><pre><span class="line">Dumping 00000000000000003839.index</span><br><span class="line">offset: 3898 position: 6829</span><br><span class="line">offset: 3973 position: 13007</span><br><span class="line">offset: 4000 position: 18234</span><br><span class="line">offset: 4033 position: 23157</span><br><span class="line">offset: 4074 position: 27758</span><br></pre></td></tr></table></figure>
</li>
<li><p>根据查找到的 position: 6829，在00000000000000003839.log文件内顺序查找</p>
<figure class="highlight txt"><table><tr><td class="code"><pre><span class="line">baseOffset: 3894 lastOffset: 3894 count: 1 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 4 isTransactional: false isControl: false position: 6829 CreateTime: 1711530460098 size: 174 magic: 2 compresscodec: NONE crc: 3806654303 isvalid: true</span><br><span class="line">| offset: 3894 CreateTime: 1711530460098 keysize: 9 valuesize: 95 sequence: -1 headerKeys: [] key: 四川省 payload: &#123;&quot;province&quot;:&quot;四川省&quot;,&quot;city&quot;:&quot;乐山市&quot;,&quot;county&quot;:&quot;马边彝族自治县&quot;,&quot;zipCode&quot;:&quot;511133&quot;&#125;</span><br><span class="line">baseOffset: 3895 lastOffset: 3897 count: 3 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 4 isTransactional: false isControl: false position: 7003 CreateTime: 1711530460098 size: 367 magic: 2 compresscodec: NONE crc: 3925488033 isvalid: true</span><br><span class="line">| offset: 3895 CreateTime: 1711530460098 keysize: 9 valuesize: 83 sequence: -1 headerKeys: [] key: 四川省 payload: &#123;&quot;province&quot;:&quot;四川省&quot;,&quot;city&quot;:&quot;遂宁市&quot;,&quot;county&quot;:&quot;船山区&quot;,&quot;zipCode&quot;:&quot;510903&quot;&#125;</span><br><span class="line">| offset: 3896 CreateTime: 1711530460098 keysize: 9 valuesize: 83 sequence: -1 headerKeys: [] key: 四川省 payload: &#123;&quot;province&quot;:&quot;四川省&quot;,&quot;city&quot;:&quot;广元市&quot;,&quot;county&quot;:&quot;利州区&quot;,&quot;zipCode&quot;:&quot;510802&quot;&#125;</span><br><span class="line">| offset: 3897 CreateTime: 1711530460098 keysize: 9 valuesize: 86 sequence: -1 headerKeys: [] key: 四川省 payload: &#123;&quot;province&quot;:&quot;四川省&quot;,&quot;city&quot;:&quot;泸州市&quot;,&quot;county&quot;:&quot;龙马潭区&quot;,&quot;zipCode&quot;:&quot;510504&quot;&#125;</span><br><span class="line">baseOffset: 3898 lastOffset: 3898 count: 1 baseSequence: -1 lastSequence: -1 producerId: -1 producerEpoch: -1 partitionLeaderEpoch: 4 isTransactional: false isControl: false position: 7370 CreateTime: 1711530460100 size: 162 magic: 2 compresscodec: NONE crc: 3756346951 isvalid: true</span><br><span class="line">| offset: 3898 CreateTime: 1711530460100 keysize: 9 valuesize: 83 sequence: -1 headerKeys: [] key: 四川省 payload: &#123;&quot;province&quot;:&quot;四川省&quot;,&quot;city&quot;:&quot;德阳市&quot;,&quot;county&quot;:&quot;绵竹市&quot;,&quot;zipCode&quot;:&quot;510683&quot;&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ol>
]]></content>
      <categories>
        <category>Kafka</category>
      </categories>
      <tags>
        <tag>Kafka</tag>
      </tags>
  </entry>
  <entry>
    <title>Maven中的依赖传递</title>
    <url>/2018/04/28/Maven%E4%B8%AD%E7%9A%84%E4%BE%9D%E8%B5%96%E4%BC%A0%E9%80%92/</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Maven 是一款基于 Java 平台的项目管理和整合工具，它将项目的开发和管理过程抽象成一个项目对象模型（POM）。开发人员只需要做一些简单的配置，Maven 就可以自动完成项目的编译、测试、打包、发布以及部署等工作。</p>
<p>Maven 是使用 Java 语言编写的，因此它和 Java 一样具有跨平台性，这意味着无论是在 Windows ，还是在 Linux 或者 Mac OS 上，都可以使用相同的命令进行操作。</p>
<p>Maven 使用标准的目录结构和默认构建生命周期，因此开发者几乎不用花费多少时间就能够自动完成项目的基础构建工作。</p>
<p>Maven 能够帮助开发者完成以下任务：</p>
<ul>
<li>构建项目</li>
<li>生成文档</li>
<li>创建报告</li>
<li>维护依赖</li>
<li>软件配置管理</li>
<li>发布</li>
<li>部署</li>
</ul>
<p>总而言之，Maven 简化并标准化了项目构建过程。它将项目的编译，生成文档，创建报告，发布，部署等任务无缝衔接，构建成一套完整的生命周期。</p>
<h2 id="Maven-的目标"><a href="#Maven-的目标" class="headerlink" title="Maven 的目标"></a>Maven 的目标</h2><p>Maven 的主要目标是为为开发人员提供如下内容：</p>
<ul>
<li>一个可重复使用，可维护且易于理解的项目综合模型</li>
<li>与此模型进行交互的工具和插件</li>
</ul>
<span id="more"></span>

<h2 id="Maven-的目标-1"><a href="#Maven-的目标-1" class="headerlink" title="Maven 的目标"></a>Maven 的目标</h2><p>Maven 的主要目标是为为开发人员提供如下内容：</p>
<ul>
<li>一个可重复使用，可维护且易于理解的项目综合模型</li>
<li>与此模型进行交互的工具和插件</li>
</ul>
<h2 id="约定优于配置"><a href="#约定优于配置" class="headerlink" title="约定优于配置"></a>约定优于配置</h2><p>约定优于配置（Convention Over Configuration）是 Maven 最核心的涉及理念之一 ，Maven对项目的目录结构、测试用例命名方式等内容都做了规定，凡是使用 Maven 管理的项目都必须遵守这些规则。</p>
<p>Maven 项目构建过程中，会自动创建默认项目结构，开发人员仅需要在相应目录结构下放置相应的文件即可。</p>
<p>例如，下表显示了项目源代码文件，资源文件和其他配置在 Maven 项目中的默认位置。 </p>
<table>
<thead>
<tr>
<th>文件</th>
<th>目录</th>
</tr>
</thead>
<tbody><tr>
<td>Java 源代码</td>
<td>src&#x2F;main&#x2F;java</td>
</tr>
<tr>
<td>资源文件</td>
<td>src&#x2F;main&#x2F;resources</td>
</tr>
<tr>
<td>测试源代码</td>
<td>src&#x2F;test&#x2F;java</td>
</tr>
<tr>
<td>测试资源文件</td>
<td>src&#x2F;test&#x2F;resources</td>
</tr>
<tr>
<td>打包输出文件</td>
<td>target</td>
</tr>
<tr>
<td>编译输出文件</td>
<td>target&#x2F;classes</td>
</tr>
</tbody></table>
<h2 id="Maven-的特点"><a href="#Maven-的特点" class="headerlink" title="Maven 的特点"></a>Maven 的特点</h2><p>Maven 具有以下特点：</p>
<ol>
<li>设置简单。</li>
<li>所有项目的用法一致。</li>
<li>可以管理和自动进行更新依赖。</li>
<li>庞大且不断增长的资源库。</li>
<li>可扩展，使用 Java 或脚本语言可以轻松的编写插件。</li>
<li>几乎无需额外配置，即可立即访问新功能。</li>
<li>基于模型的构建：Maven 能够将任意数量的项目构建为预定义的输出类型，例如 JAR，WAR。</li>
<li>项目信息采取集中式的元数据管理：使用与构建过程相同的元数据，Maven 能够生成一个网站（site）和一个包含完整文档的 PDF。</li>
<li>发布管理和发行发布：Maven 可以与源代码控制系统（例如 Git、SVN）集成并管理项目的发布。</li>
<li>向后兼容性：您可以轻松地将项目从旧版本的 Maven 移植到更高版本的 Maven 中。</li>
<li>并行构建：它能够分析项目依赖关系，并行构建工作，使用此功能，可以将性能提高 20%-50％。</li>
<li>更好的错误和完整性报告：Maven 使用了较为完善的错误报告机制，它提供了指向 Maven Wiki 页面的链接，您将在其中获得有关错误的完整描述。</li>
</ol>
<h2 id="依赖范围scope"><a href="#依赖范围scope" class="headerlink" title="依赖范围scope"></a>依赖范围scope</h2><blockquote>
<p>Maven因为执行一系列编译、测试、和部署等操作，在不同的操作下使用的classpath不同，<strong>依赖范围就是控制依赖与三种classpath(编译classpath、测试classpath、运行classpath)的关系</strong>。</p>
</blockquote>
<p>一共有5种，compile(编译)、test(测试)、runtime(运行时)、provided、system不指定，则范围默认为compile。</p>
<ul>
<li>compile：编译依赖范围，在编译、测试、运行时都需要。    </li>
<li>test：测试依赖范围，测试时需要。编译和运行不需要。</li>
<li>runtime：运行时以来范围，测试和运行时需要，编译不需要。</li>
<li>provided：已提供依赖范围，编译和测试时需要。运行时不需要。</li>
<li>system：系统依赖范围。本地依赖，不在maven中央仓库。</li>
</ul>
<hr>
<h2 id="依赖的传递"><a href="#依赖的传递" class="headerlink" title="依赖的传递"></a>依赖的传递</h2><p>A-&gt;B(compile)   a依赖b<br>    &gt;b是A的编译依赖范围，在A编译、测试、运行时都依赖b</p>
<p>B-&gt;C(compile)   B依赖C<br>    &gt;c是B的编译依赖范围，在B编译、测试、运行时都依赖c</p>
<p>当在A中配置</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.B<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>B<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>则会自动导入c包。关系传递如下表：</p>
<p>由上表不难看出，项目A具体会不会导入B依赖的包c，取决于第一和第二依赖，但是依赖的范围不会超过第一直接依赖，即具体会不会引入c包，要看第一直接依赖的依赖范围。</p>
<h2 id="依赖冲突的调节"><a href="#依赖冲突的调节" class="headerlink" title="依赖冲突的调节"></a>依赖冲突的调节</h2><pre><code>A -&gt; B -&gt; C -&gt; X(1.0)
A -&gt; D -&gt; X(2.0)
</code></pre>
<p>由于只能引入一个版本的包，此时Maven按照最短路径选择导入X(2.0).</p>
<pre><code>A -&gt; B -&gt; X(1.0)
A -&gt; D -&gt; X(2.0)
</code></pre>
<p>路径长度一致，则优先选择第一个，此时导入X(1.0).</p>
<h2 id="排除依赖"><a href="#排除依赖" class="headerlink" title="排除依赖"></a>排除依赖</h2><pre><code>A -&gt; B -&gt; C(1.0)
</code></pre>
<p>此时在A项目中，不想使用C(1.0)，而使用C(2.0)</p>
<p>则需要使用exclusion排除B对C(1.0)的依赖。并在A中引入C(2.0).</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line">pom.xml中配置</span><br><span class="line"><span class="comment">&lt;!--排除B对C的依赖--&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>B<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>B<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>0.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">exclusions</span>&gt;</span></span><br><span class="line">             <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>C<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span>  </span><br><span class="line">             <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>C<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span><span class="comment">&lt;!--无需指定要排除项目的                                         版本号--&gt;</span></span><br><span class="line">             <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">exclusions</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span> </span><br><span class="line"></span><br><span class="line"><span class="comment">&lt;!---在A中引入C(2.0)--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>C<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>C<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span>  </span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span> </span><br></pre></td></tr></table></figure>




<h2 id="依赖关系的查看"><a href="#依赖关系的查看" class="headerlink" title="依赖关系的查看"></a>依赖关系的查看</h2><p>cmd进入工程根目录，执行  mvn dependency:tree</p>
<p>会列出依赖关系树及各依赖关系</p>
<p><strong>mvn dependency:analyze    分析依赖关系</strong>   </p>
<p>​    </p>
]]></content>
      <categories>
        <category>Web</category>
      </categories>
      <tags>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title>keepalived入门</title>
    <url>/2019/03/26/Keepalived%E5%85%A5%E9%97%A8/</url>
    <content><![CDATA[<h2 id="keepalived简介"><a href="#keepalived简介" class="headerlink" title="keepalived简介"></a>keepalived简介</h2><blockquote>
<p>&emsp;&emsp;keepalived是集群管理中保证集群高可用的一个服务软件，用来防止单点故障。</p>
</blockquote>
<blockquote>
<p>&emsp;&emsp;keepalived的作用是检测web服务器的状态，如果有一台web服务器死机，<br>或工作出现故障，keepalived将检测到，并将有故障的web服务器从系统中剔除，当web服务器<br>工作正常后，keepalived自动将web服务器加入到服务器集群中，这些工作全部自动完成，不需要<br>人工干涉，需要人工做的只是修复故障的web服务器。</p>
</blockquote>
<blockquote>
<p>&emsp;&emsp;keepalived是以VRRP协议位实现基础的，VRRP全称 Virtual Router<br>Redundancy Protocol，即虚拟路由冗余协议。</p>
</blockquote>
<blockquote>
<p>&emsp;&emsp;虚拟路由冗余协议，可以认为是实现路由器高可用的协议，即将N台提供相同<br>功能的路由器组成的一个路由器组，这个组里面有一个master和多个backup，master上面有一个对外提供服务<br>的VIP（Virtual IPAddress,虚拟IP地址，该路由器所在局域网内其他机器的默认路由为该VIP），<br>master会发组播，当backup收不到VRRP包时，就认为master宕掉了，这时就需要根据VRRP的优先级来<br>就可以保证路由器的高可用了。</p>
</blockquote>
<span id="more"></span>

<h3 id="keepalived核心内容"><a href="#keepalived核心内容" class="headerlink" title="keepalived核心内容"></a>keepalived核心内容</h3><blockquote>
<p>&emsp;&emsp;keepalived主要有三个模块，分别是core、check和VRRP。core模块为<br>keepalived的核心，负责主进程的启动、维护以及全局配置文件的加载和解析。check负责健康检查<br>，包括常见的各种检查。VRRP模块是来实现VRRP协议的。</p>
</blockquote>
<p>初始状态：</p>
<blockquote>
</blockquote>
<p><img src="/images/keep1.bmp" alt="初始状态"></p>
<p>主机状态：</p>
<blockquote>
</blockquote>
<p><img src="/images/keep2.bmp" alt="主机状态"></p>
<p>主机恢复：</p>
<blockquote>
</blockquote>
<p><img src="/images/keep3.bmp" alt="主机恢复"></p>
]]></content>
      <categories>
        <category>Web</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>MyCat分片</title>
    <url>/2019/03/28/MyCat%E5%88%86%E7%89%87/</url>
    <content><![CDATA[<h2 id="MyCat简介"><a href="#MyCat简介" class="headerlink" title="MyCat简介"></a>MyCat简介</h2><blockquote>
<p>&emsp;&emsp;Mycat 背后是阿里曾经开源的知名产品——Cobar。 Cobar的核心功能和优势是MySQL数据库分片。<br>&emsp;&emsp;Mycat 是基于 cobar 演变而来， 对 cobar 的代码进行了彻底的重构， 使用 NIO 重构了网络模块，并且优化了Buffer 内核， 增强了聚合，oin等基本特性， 同时兼容绝大多数数据库成为通用的数据库中间件。简单的说， MyCAT 就是： 一个新颖的数据库中间件产品支持 mysql 集群，或者mariadbcluster， 提供高可用性数据分片集群。你可以像使用 mysql 一样使用 mycat。 对于开<br>发人员来说根本感觉不到mycat的存在。</p>
</blockquote>
<span id="more"></span>

<h2 id="环境需求"><a href="#环境需求" class="headerlink" title="环境需求"></a>环境需求</h2><ul>
<li>JDK :  1.7及以上版本</li>
<li>MySQL: mysql5.5以上版本</li>
</ul>
<h4 id="Mysql安装与启动步骤："><a href="#Mysql安装与启动步骤：" class="headerlink" title="Mysql安装与启动步骤："></a>Mysql安装与启动步骤：</h4><ol>
<li>将MySQL的服务端和客户端安装包(RPM)上传到服务器</li>
<li>查询之前是否安装过MySQL<br> <code># rpm -qa|grep mysql</code></li>
<li>卸载旧版本的MySQL<br> <code> rpm -e --nodeps XXX</code></li>
<li>安装服务端<br> <code>rpm -ivh MySQL-server-5.6.17-1.el6.x86_64.rpm</code></li>
<li>安装客户端<br> <code>rpm -ivh MySQL-client-5.6.17-1.el6.x86_64.rpm</code></li>
<li>启动MySQL服务<br> <code>service mysql start</code></li>
<li>登陆MySQL(刚安装的Mysql密码在<code>/root/.mysql_secret</code>)<br><code>mysql -uroot -p密码</code></li>
<li>设置远程登录权限<br> <code>GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;%&#39;IDENTIFIED BY &#39;123456&#39; WITH GRANT OPTION;</code><br>  <code>flush privileges;</code></li>
</ol>
<h4 id="MyCat分片"><a href="#MyCat分片" class="headerlink" title="MyCat分片"></a>MyCat分片</h4><h5 id="分片相关的概念"><a href="#分片相关的概念" class="headerlink" title="分片相关的概念"></a>分片相关的概念</h5><ul>
<li><p>逻辑库(schema) </p>
<blockquote>
<p>&emsp;&emsp;前面一节讲了数据库中间件， 通常对实际应用来说， 并不需要知道中间件的存在， 业务开发<br>人员只需要知道数据库的概念， 所以数据库中间件可以被看做是一个或多个数据库集群构成<br>的逻辑库。(可以理解为一个保存了数据真实地址的映射集合)。</p>
</blockquote>
</li>
<li><p>逻辑表(table)</p>
<blockquote>
<p>&emsp;&emsp;既然有逻辑库，那么就会有逻辑表，分布式数据库中，对应用来说，读写数据的表就是逻辑表。逻辑表，可以是数据切分后，分布在一个或多个分片库中，也可以不做数据切分，不分片，只有一个表构成。<br>&emsp;<br><strong>分片表</strong>： 是指那些原有的很大数据的表，需要切分到多个数据库的表，这样， 每个分片都有一部分数据，所有分片构成了完整的数据。总而言之就是需要进行分片的表。<br>&emsp;<br><strong>非分片表</strong>： 一个数据库中并不是所有的表都很大，某些表是可以不用进行切分的， 非分片是相对分片表来说的， 就是那些不需要进行数据切分的表。</p>
</blockquote>
</li>
<li><p>分片节点(dateNode)</p>
<blockquote>
<p>&emsp;&emsp;数据切分后，一个大表被分到不同的分片数据库上面，每个表所在的数据库就是分片节点（dataNode)。</p>
</blockquote>
</li>
</ul>
<p>-节点主机(dateHost)</p>
<blockquote>
<p>&emsp;&emsp;数据分片后，每个分片节点(dateNode)不一定都会独占一台机器，同一台机器上可以有多个分片数据库，这样一个或多个分片节点所在的机器就是节点主机,为了规避单节点并发数限制，尽量将读写压力高的分片节点均衡放在不同的节点主机。</p>
</blockquote>
<p>-分片规则(rule)</p>
<blockquote>
<p>&emsp;&emsp;一个大表被分成若干个分片表，就需要一定的规则，这样按照某种业务规则把数据分到某个分片的规则就是分片规则，数据切分选择选择合适的分片规则非常重要，将极大的避免后续数据处理的难度。</p>
</blockquote>
<h4 id="MyCat分片配置"><a href="#MyCat分片配置" class="headerlink" title="MyCat分片配置"></a>MyCat分片配置</h4><h5 id="配置schema-xml"><a href="#配置schema-xml" class="headerlink" title="配置schema.xml"></a>配置schema.xml</h5><blockquote>
<p>schema 标签用于定义MyCat实例中的逻辑库<br>&emsp;<br>Table 标签定义了MyCat中的逻辑表<br>&emsp;<br>rule 用于指定分片规则，auto-sharding-long 的分片规则是按ID值的范围进行分片,1-5000000为第1片,5000001-10000000 为第 2 片….<br>&emsp;<br>dataNode标签定义了MyCat中的数据节点，也就是数据分片。<br>dataHost标签在mycat逻辑库中也是作为最底层的标签存在，直接定义了具体的数据库实例、读写分离配置和心跳语句。<br>schema.xml配置如下：</p>
</blockquote>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span>?&gt;</span></span><br><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">mycat</span>:schema <span class="keyword">SYSTEM</span> <span class="string">&quot;schema.dtd&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">mycat:schema</span> <span class="attr">xmlns:mycat</span>=<span class="string">&quot;http://org.opencloudb/&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">schema</span> <span class="attr">name</span>=<span class="string">&quot;PINYOUGOUDB&quot;</span> <span class="attr">checkSQLschema</span>=<span class="string">&quot;false&quot;</span> <span class="attr">sqlMaxLimit</span>=<span class="string">&quot;100&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">table</span> <span class="attr">name</span>=<span class="string">&quot;tb_test&quot;</span> <span class="attr">dataNode</span>=<span class="string">&quot;dn1,dn2,dn3&quot;</span> <span class="attr">rule</span>=<span class="string">&quot;auto-sharding-long&quot;</span> /&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">schema</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dataNode</span> <span class="attr">name</span>=<span class="string">&quot;dn1&quot;</span> <span class="attr">dataHost</span>=<span class="string">&quot;localhost1&quot;</span> <span class="attr">database</span>=<span class="string">&quot;db1&quot;</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dataNode</span> <span class="attr">name</span>=<span class="string">&quot;dn2&quot;</span> <span class="attr">dataHost</span>=<span class="string">&quot;localhost1&quot;</span> <span class="attr">database</span>=<span class="string">&quot;db2&quot;</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dataNode</span> <span class="attr">name</span>=<span class="string">&quot;dn3&quot;</span> <span class="attr">dataHost</span>=<span class="string">&quot;localhost1&quot;</span> <span class="attr">database</span>=<span class="string">&quot;db3&quot;</span> /&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">dataHost</span> <span class="attr">name</span>=<span class="string">&quot;localhost1&quot;</span> <span class="attr">maxCon</span>=<span class="string">&quot;1000&quot;</span> <span class="attr">minCon</span>=<span class="string">&quot;10&quot;</span> <span class="attr">balance</span>=<span class="string">&quot;0&quot;</span></span></span><br><span class="line"><span class="tag">    <span class="attr">writeType</span>=<span class="string">&quot;0&quot;</span> <span class="attr">dbType</span>=<span class="string">&quot;mysql&quot;</span> <span class="attr">dbDriver</span>=<span class="string">&quot;native&quot;</span> <span class="attr">switchType</span>=<span class="string">&quot;1&quot;</span></span></span><br><span class="line"><span class="tag">    <span class="attr">slaveThreshold</span>=<span class="string">&quot;100&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">heartbeat</span>&gt;</span>select user()<span class="tag">&lt;/<span class="name">heartbeat</span>&gt;</span></span><br><span class="line"></span><br><span class="line"><span class="tag">&lt;<span class="name">writeHost</span> <span class="attr">host</span>=<span class="string">&quot;hostM1&quot;</span> <span class="attr">url</span>=<span class="string">&quot;localhost:3306&quot;</span> <span class="attr">user</span>=<span class="string">&quot;root&quot;</span></span></span><br><span class="line"><span class="tag"><span class="attr">password</span>=<span class="string">&quot;123456&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">writeHost</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dataHost</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">mycat:schema</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h5 id="配置server-xml"><a href="#配置server-xml" class="headerlink" title="配置server.xml"></a>配置server.xml</h5><p>server.xml几乎保存了mycat需要的系统配置信息。最常见的是在此配置用户名、密码以及权限。<br>server.xml配置如下：<br>添加UTF-8字符集设置，否则存储中文会出现问号</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;charset&quot;</span>&gt;</span>utf8<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>修改user的设置，为TESTDB添加root、test用户</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">user</span> <span class="attr">name</span>=<span class="string">&quot;test&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;password&quot;</span>&gt;</span>test<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;schemas&quot;</span>&gt;</span>TESTDB<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">user</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">user</span> <span class="attr">name</span>=<span class="string">&quot;root&quot;</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;password&quot;</span>&gt;</span>123456<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;schemas&quot;</span>&gt;</span>TESTDB<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">user</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h5 id="MyCat分片测试"><a href="#MyCat分片测试" class="headerlink" title="MyCat分片测试"></a>MyCat分片测试</h5><p>进入逻辑库TESTDB<br><code># mysql -uroot -p123456 -P8066 -DTESTDB</code><br><code>show tables;</code>会发现已经有表<code>tb_test</code><br>执行以下语句创建一个表</p>
<figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> tb_test (</span><br><span class="line">id <span class="type">BIGINT</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">title <span class="type">VARCHAR</span>(<span class="number">100</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> ,</span><br><span class="line"><span class="keyword">PRIMARY</span> KEY (id)</span><br><span class="line">) ENGINE<span class="operator">=</span>INNODB <span class="keyword">DEFAULT</span> CHARSET<span class="operator">=</span>utf8</span><br></pre></td></tr></table></figure>
<p>在创建完成后，会对表<code>td_test</code>的结构进行初始化。查看物理数据库<code>db1,db2,db3</code>,会发现，每个物理数据库中都已经创建好了表<code>tb_test</code>。</p>
<p>然后就可以向逻辑库中的逻辑表中插入数据，数据会按照分片规则进行分片存储。</p>
<h5 id="MyCat分片规则"><a href="#MyCat分片规则" class="headerlink" title="MyCat分片规则"></a>MyCat分片规则</h5><p>rule.xml用于定义分片规则</p>
<ol>
<li>按主键范围分片(rang-long)</li>
</ol>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">tableRule</span> <span class="attr">name</span>=<span class="string">&quot;auto-sharding-long&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">rule</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">columns</span>&gt;</span>id<span class="tag">&lt;/<span class="name">columns</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">algorithm</span>&gt;</span>rang-long<span class="tag">&lt;/<span class="name">algorithm</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">rule</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">tableRule</span>&gt;</span></span><br></pre></td></tr></table></figure>

<p>配置文件详解：</p>
<ul>
<li>tableRule :用于定义固体某个表或某类表的分片规则名称</li>
<li>column：用于定义分片的列</li>
<li>algorithm：代表算法的名称</li>
</ul>
<p><strong>rang-long</strong>的定义：</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">&lt;<span class="keyword">function</span> name=<span class="string">&quot;rang-long&quot;</span></span><br><span class="line">    <span class="keyword">class</span>=<span class="string">&quot;org.opencloudb.route.function.AutoPartitionByLong&quot;</span>&gt;</span><br><span class="line">    <span class="language-xml"><span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;mapFile&quot;</span>&gt;</span>autopartition-long.txt<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span></span><br><span class="line">&lt;/<span class="keyword">function</span>&gt;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p> <strong>autopartition-long.txt</strong>的定义</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">range start-end ,data node index</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">K=1000,M=10000.</span></span><br><span class="line">0-500M=0</span><br><span class="line">500M-1000M=1</span><br><span class="line">1000M-1500M=2</span><br></pre></td></tr></table></figure>

<hr>
<ol start="2">
<li>一致性哈希murmur<br> 当我们需要将数据平均分在几个分区中，需要使用一致性hash规则<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">function</span> <span class="attr">name</span>=<span class="string">&quot;murmur&quot;</span></span></span><br><span class="line"><span class="tag">     <span class="attr">class</span>=<span class="string">&quot;org.opencloudb.route.function.PartitionByMurmurHash&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;seed&quot;</span>&gt;</span>0<span class="tag">&lt;/<span class="name">property</span>&gt;</span><span class="comment">&lt;!--     默认是 0 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;count&quot;</span>&gt;</span>3<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--要分片的数据库节点数量，必须指定，否则没法分片--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span> <span class="attr">name</span>=<span class="string">&quot;virtualBucketTimes&quot;</span>&gt;</span>160<span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 一个实际的数据库节点被映射为这么多虚拟节点， 默认是 160 倍，也就是虚拟节点数是物理节点数的 160 倍 --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- &lt;property name=&quot;weightMapFile&quot;&gt;weightMapFile&lt;/property&gt; 节点的权重，没有指定权重的节点默认是1。以properties文件的格式填写， 以从 0 开始到 count-1的整数值也就是节点索引为key，以节点权重值为值。 所有权重值必须是正整数， 否则以 1 代替 --&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- &lt;property name=&quot;bucketMapPath&quot;&gt;/etc/mycat/bucketMapPath&lt;/property&gt;</span></span><br><span class="line"><span class="comment">用于测试时观察各物理节点与虚拟节点的分布情况， 如果指定了这个属性， 会把虚拟节点的 murmur hash 值与物理节点的映射按行输出到这个文件， 没有默认值， 如果不指定， 就不会输出任何东西 --&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">function</span>&gt;</span></span><br></pre></td></tr></table></figure>
配置文件中表规则的定义：<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">tableRule</span> <span class="attr">name</span>=<span class="string">&quot;sharding-by-murmur&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">rule</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">columns</span>&gt;</span>id<span class="tag">&lt;/<span class="name">columns</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">algorithm</span>&gt;</span>murmur<span class="tag">&lt;/<span class="name">algorithm</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">rule</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">tableRule</span>&gt;</span></span><br></pre></td></tr></table></figure>
在这里是按照id进行hash运算，然后确定数据的分片存储位置</li>
</ol>
]]></content>
      <categories>
        <category>Web</category>
      </categories>
      <tags>
        <tag>MyCat</tag>
        <tag>分库分表</tag>
      </tags>
  </entry>
  <entry>
    <title>Nginx的安装与静态网站部署</title>
    <url>/2017/06/18/Nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%E4%B8%8E%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/</url>
    <content><![CDATA[<h2 id="Nginx简介"><a href="#Nginx简介" class="headerlink" title="Nginx简介"></a>Nginx简介</h2><blockquote>
<p>&emsp;&emsp;Nginx是一款高性能的HTTP服务器&#x2F;反向代理服务器及电子邮件服务器。<br>官方测试能够支撑5万并发访问，并且CPU、内存等资源消耗却非常低，运行非常稳定。</p>
</blockquote>
<h3 id="Nginx应用场景"><a href="#Nginx应用场景" class="headerlink" title="Nginx应用场景"></a>Nginx应用场景</h3><ul>
<li>HTTP服务器。Nginx可以做网页静态服务器。</li>
<li>虚拟主机。 可以实现在一台服务器虚拟出多个网站。</li>
<li>反向代理，负载均衡。当单台服务器不能满足用户的请求时，需要用多台服务器集群可以使用<br>nginx做反向代理。并且多台服务器可以平均分担负载，不会因为某台服务器负载过高宕机<br>而某台服务器闲置的情况。</li>
</ul>
<span id="more"></span>

<h3 id="Nginx在Linux下的安装"><a href="#Nginx在Linux下的安装" class="headerlink" title="Nginx在Linux下的安装"></a>Nginx在Linux下的安装</h3><p>环境：</p>
<ul>
<li>gcc-c++，pcre，pcre-devel，zlib，zlib-devel，openssl，openssl-devel</li>
</ul>
<p>1、上传并解压缩</p>
<blockquote>
<p><code>tar zxvf nginx-1.8.0.tar.gz</code></p>
</blockquote>
<p>2、进入nginx-1.8.0目录，使用configure命令创建MakeFile文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./configure \</span><br><span class="line">--prefix=/usr/local/nginx \</span><br><span class="line">--pid-path=/var/run/nginx/nginx.pid \</span><br><span class="line">--lock-path=/var/lock/nginx.lock \</span><br><span class="line">--error-log-path=/var/log/nginx/error.log \</span><br><span class="line">--http-log-path=/var/log/nginx/access.log \</span><br><span class="line">--with-http_gzip_static_module \</span><br><span class="line">--http-client-body-temp-path=/var/temp/nginx/client \</span><br><span class="line">--http-proxy-temp-path=/var/temp/nginx/proxy \</span><br><span class="line">--http-fastcgi-temp-path=/var/temp/nginx/fastcgi \</span><br><span class="line">--http-uwsgi-temp-path=/var/temp/nginx/uwsgi \</span><br><span class="line">--http-scgi-temp-path=/var/temp/nginx/scgi</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>configure 参数详解：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./configure \</span><br><span class="line">--prefix=/usr \ 指向安装目录</span><br><span class="line">--sbin-path=/usr/sbin/nginx \ 指向（执行） 程序文件（nginx）</span><br><span class="line">--conf-path=/etc/nginx/nginx.conf \ 指向配置文件</span><br><span class="line">--error-log-path=/var/log/nginx/error.log \ 指向 log</span><br><span class="line">--http-log-path=/var/log/nginx/access.log \ 指向 http-log</span><br><span class="line">--pid-path=/var/run/nginx/nginx.pid \ 指向 pid</span><br><span class="line">--lock-path=/var/lock/nginx.lock \ （安装文件锁定， 防止安装文件被别人利用， 或自己</span><br><span class="line">误操作。 ）</span><br><span class="line">--user=nginx \</span><br><span class="line">--group=nginx \</span><br><span class="line">--with-http_ssl_module \ 启用 ngx_http_ssl_module 支持（使支持 https 请求， 需已安装</span><br><span class="line">openssl）</span><br><span class="line">--with-http_flv_module \ 启用 ngx_http_flv_module 支持（提供寻求内存使用基于时间的</span><br><span class="line">偏移量文件）</span><br><span class="line">--with-http_stub_status_module \ 启用 ngx_http_stub_status_module 支持（获取 nginx 自上次启</span><br><span class="line">动以来的工作状态）</span><br><span class="line">--with-http_gzip_static_module \ 启用 ngx_http_gzip_static_module 支持（在线实时压缩输出数据</span><br><span class="line">流）</span><br><span class="line">--http-client-body-temp-path=/var/tmp/nginx/client/ \ 设定 http 客户端请求临时文件路径</span><br><span class="line">--http-proxy-temp-path=/var/tmp/nginx/proxy/ \ 设定 http 代理临时文件路径</span><br><span class="line">--http-fastcgi-temp-path=/var/tmp/nginx/fcgi/ \ 设定 http fastcgi 临时文件路径</span><br><span class="line">--http-uwsgi-temp-path=/var/tmp/nginx/uwsgi \ 设定 http uwsgi 临时文件路径</span><br><span class="line">--http-scgi-temp-path=/var/tmp/nginx/scgi \ 设定 http scgi 临时文件路径</span><br><span class="line">--with-pcre 启用 pcre 库</span><br></pre></td></tr></table></figure>
<p>3、编译</p>
<blockquote>
<p><code>make -j 8 </code><br>参数 <code>-j</code> 用于指定编译的线程的个数。</p>
</blockquote>
<p>4、安装</p>
<blockquote>
<p><code>make install</code></p>
</blockquote>
<p>5、创建启动参数需要的文件目录<code>/var/temp/nginx/client</code></p>
<blockquote>
<p><code>mkdir /var/temp/nginx/client -p</code></p>
</blockquote>
<p><strong>Nginx的相关命令</strong></p>
<ul>
<li>启动nginx :<code>./nginx</code></li>
<li>关闭nginx :<code>./nginx -s quit</code></li>
<li>重启nginx :<code>./nginx -s reload</code></li>
</ul>
<h2 id="Nginx虚拟主机的配置"><a href="#Nginx虚拟主机的配置" class="headerlink" title="Nginx虚拟主机的配置"></a>Nginx虚拟主机的配置</h2><p>1、上传静态网站</p>
<blockquote>
<p>将前端静态页cart.html以及图片样式等资源，上传至 &#x2F;usr&#x2F;local&#x2F;nginx&#x2F;cart</p>
</blockquote>
<p>2、修改Nginx的修改配置文件：&#x2F;usr&#x2F;local&#x2F;nginx&#x2F;conf&#x2F;nginx.conf</p>
<figure class="highlight json"><table><tr><td class="code"><pre><span class="line">server <span class="punctuation">&#123;</span></span><br><span class="line">    listen <span class="number">81</span>; # 对外访问端口</span><br><span class="line">    server_name localhost;</span><br><span class="line"></span><br><span class="line">    location / <span class="punctuation">&#123;</span></span><br><span class="line"></span><br><span class="line">        root cart;</span><br><span class="line">        index cart.html;</span><br><span class="line"></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    error_page <span class="number">500</span> <span class="number">502</span> <span class="number">503</span> <span class="number">504</span> /<span class="number">50</span>x.html;</span><br><span class="line">    location = /<span class="number">50</span>x.html<span class="punctuation">&#123;</span></span><br><span class="line">        root html;</span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<p>3、域名绑定</p>
<h2 id="3-1-修改nginx-conf3-2、修改本机hosts映射"><a href="#3-1-修改nginx-conf3-2、修改本机hosts映射" class="headerlink" title="3.1 修改nginx.conf3.2、修改本机hosts映射"></a>3.1 修改nginx.conf<br><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">server <span class="punctuation">&#123;</span></span><br><span class="line">    listen <span class="number">81</span>; # 对外访问端口</span><br><span class="line">    server_name cart.pinyougou.com;</span><br><span class="line"></span><br><span class="line">    location / <span class="punctuation">&#123;</span></span><br><span class="line"></span><br><span class="line">        root cart;</span><br><span class="line">        index cart.html;</span><br><span class="line"></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    error_page <span class="number">500</span> <span class="number">502</span> <span class="number">503</span> <span class="number">504</span> /<span class="number">50</span>x.html;</span><br><span class="line">    location = /<span class="number">50</span>x.html<span class="punctuation">&#123;</span></span><br><span class="line">        root html;</span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><br>3.2、修改本机hosts映射<br><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">127.0.0.1 cart.pinyougou.com</span><br></pre></td></tr></table></figure></h2><h2 id="Nginx反向代理与负载均衡"><a href="#Nginx反向代理与负载均衡" class="headerlink" title="Nginx反向代理与负载均衡"></a>Nginx反向代理与负载均衡</h2><blockquote>
<p>反向代理(Reverse Proxy):是指以<strong>代理服务器</strong>来接受Internet上的连接请求，然后将请求转发给内部网络<br>上的服务器，并将从服务器上得到的结果返回给Internet上的请求连接的客户端，此时代理服务器对外就表现<br>为一个反向代理服务器。正向代理针对的是客户端，而反向代理针对的是服务器。</p>
</blockquote>
<h3 id="配置反反向代理"><a href="#配置反反向代理" class="headerlink" title="配置反反向代理"></a>配置反反向代理</h3><p>1、在Nginx主机修改Nginx配置文件</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">upstream tomcat-cart&#123;</span><br><span class="line">    server 192.168.25.135:9102;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">    listen 80;</span><br><span class="line">    server_name cart.pinyougou.com;</span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">        proxy_pass http://tomcat-cart;</span><br><span class="line">        index index.html index.htm;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>2、配置域名解析</p>
<p>3、重启nginx,然后使用域名访问</p>
<blockquote>
<p><code>http://cart.pinyougou.com/cart/index.html</code></p>
</blockquote>
<hr>
<h1 id="负载均衡"><a href="#负载均衡" class="headerlink" title="负载均衡"></a>负载均衡</h1><blockquote>
<p>&emsp;&emsp; 负载均衡(Load Balance),其意思就是分摊到多个操作单元上进行执行，例如<br>Web服务器、FTP服务器、企业关键应用服务器和其他关键服务器等，从而共同完成工作任务。<br>它建立在现有网络结构上，提供了一种<strong>廉价有效透明的方法扩展网络设备</strong>和<strong>服务器带宽</strong>、<strong>增加吞吐量</strong><br><strong>加强网络数据处理能力</strong>、<strong>加强网络数据处理能力</strong>、<strong>提高网络的灵活性和可用性</strong>。</p>
</blockquote>
<h2 id="负载均衡的配置-示例"><a href="#负载均衡的配置-示例" class="headerlink" title="负载均衡的配置(示例)"></a>负载均衡的配置(示例)</h2><p>1、部署两个tomcat服务，端口分别为9801和9802.</p>
<p>2、部署网站首页</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost ~]# cp -r portal/* /usr/local/tomcat-cluster/tomcat-portal-1/webapps/ROOT</span><br><span class="line">[root@localhost ~]# cp -r portal/* /usr/local/tomcat-cluster/tomcat-portal-2/webapps/ROOT</span><br></pre></td></tr></table></figure>
<p>3、配置负载均衡</p>
<p>3.1、设置域名指向<br><code>192.168.25.135 www.pinyougou.com</code></p>
<p>3.2、修改Nginx配置文件：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">upstream tomcat-portal&#123;</span><br><span class="line">    #配置服务列表，轮询调度以实现负载均衡,**weight**设置服务被调用的权重</span><br><span class="line">    server 192.168.25.135:9801 weight=2;</span><br><span class="line">    server 192.168.25.135:9802;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">server &#123;</span><br><span class="line">    listen 80;</span><br><span class="line">    server_name www.pinyougou.com;</span><br><span class="line">    location / &#123;</span><br><span class="line">        proxy_pass http://tomcat-portal;</span><br><span class="line">        index index.html;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>





]]></content>
      <categories>
        <category>Web</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>反向代理</tag>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark collect方法分析-Driver端</title>
    <url>/2023/12/12/Spark%20collect%E6%96%B9%E6%B3%95%E5%88%86%E6%9E%90-Driver%E7%AB%AF/</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>​	在Spark框架中，理解用户代码是怎么被框架执行的，有助于我们写出高效高质量的代码，也有利于我们在问题分析时可以快速准确的定位问题。</p>
<p>​	collect方法作为一个简单的方法，其执行过程也足以展示整个框架的执行流程。</p>
<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>​	通过对调用过程的分析，深入理解整个框架的计算过程，从根本上理解程序的执行逻辑。</p>
<span id="more"></span>

<ol>
<li>在应用程序的main方法内，我们会根据需要编写Spark的算子链进行程序逻辑的安排，最后都会由一个action算子来触发执行。</li>
<li>以collect算子来解析执行过程，下边是在Driver端的分析</li>
</ol>
<ul>
<li><p>方法调用链分析：</p>
<ol>
<li>进入org.apache.spark.rdd.RDD#collect()</li>
</ol>
  <figure class="highlight java"><table><tr><td class="code"><pre><span class="line">def <span class="title function_">collect</span><span class="params">()</span>: Array[T] = withScope &#123;</span><br><span class="line">  <span class="type">val</span> <span class="variable">results</span> <span class="operator">=</span> sc.runJob(<span class="built_in">this</span>, (iter: Iterator[T]) =&gt; iter.toArray)</span><br><span class="line">  Array.concat(results: _*)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>上述withScope是一个柯里化操作，方法体内为一个匿名函数，这样做是为了在任务提交前对SparkContext做一些设置。</li>
</ul>
<ol start="2">
<li>org.apache.spark.SparkContext#runJob方法：</li>
</ol>
  <figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">runJob</span></span>[<span class="type">T</span>, <span class="type">U</span>: <span class="type">ClassTag</span>](rdd: <span class="type">RDD</span>[<span class="type">T</span>], func: <span class="type">Iterator</span>[<span class="type">T</span>] =&gt; <span class="type">U</span>): <span class="type">Array</span>[<span class="type">U</span>] = &#123;</span><br><span class="line">    <span class="comment">// 默认的分区数等于RDD的分区数。</span></span><br><span class="line">  runJob(rdd, func, <span class="number">0</span> until rdd.partitions.length)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>org.apache.spark.SparkContext#runJob方法经过多次重载调用，</li>
</ol>
  <figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">runJob</span></span>[<span class="type">T</span>, <span class="type">U</span>: <span class="type">ClassTag</span>](</span><br><span class="line">    rdd: <span class="type">RDD</span>[<span class="type">T</span>],</span><br><span class="line">    func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[<span class="type">T</span>]) =&gt; <span class="type">U</span>,</span><br><span class="line">    partitions: <span class="type">Seq</span>[<span class="type">Int</span>]): <span class="type">Array</span>[<span class="type">U</span>] = &#123;</span><br><span class="line">  <span class="keyword">val</span> results = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">U</span>](partitions.size)</span><br><span class="line">  runJob[<span class="type">T</span>, <span class="type">U</span>](rdd, func, partitions, (index, res) =&gt; results(index) = res)</span><br><span class="line">  results</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>(index, res) &#x3D;&gt; results(index) &#x3D; res 该函数表示将每个分区的计算结果存放在数组results相应的索引上。</li>
</ul>
  <figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">runJob</span></span>[<span class="type">T</span>, <span class="type">U</span>: <span class="type">ClassTag</span>](</span><br><span class="line">    rdd: <span class="type">RDD</span>[<span class="type">T</span>],</span><br><span class="line">    func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[<span class="type">T</span>]) =&gt; <span class="type">U</span>,</span><br><span class="line">    partitions: <span class="type">Seq</span>[<span class="type">Int</span>],</span><br><span class="line">    resultHandler: (<span class="type">Int</span>, <span class="type">U</span>) =&gt; <span class="type">Unit</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  ...</span><br><span class="line">    <span class="comment">//对func提前预设闭包清除</span></span><br><span class="line">  <span class="keyword">val</span> cleanedFunc = clean(func)</span><br><span class="line"> ...</span><br><span class="line">    <span class="comment">//调用DAGScheduler进行DAG构建</span></span><br><span class="line">  dagScheduler.runJob(rdd, cleanedFunc, partitions, callSite, resultHandler, localProperties.get)</span><br><span class="line">  progressBar.foreach(_.finishAll())</span><br><span class="line">  <span class="comment">// 对需要进行保存的RDD进行保存</span></span><br><span class="line">  rdd.doCheckpoint()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="4">
<li>org.apache.spark.scheduler.DAGScheduler#runJob</li>
</ol>
  <figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">runJob</span></span>[<span class="type">T</span>, <span class="type">U</span>](</span><br><span class="line">    rdd: <span class="type">RDD</span>[<span class="type">T</span>],</span><br><span class="line">    func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[<span class="type">T</span>]) =&gt; <span class="type">U</span>,</span><br><span class="line">    partitions: <span class="type">Seq</span>[<span class="type">Int</span>],</span><br><span class="line">    callSite: <span class="type">CallSite</span>,</span><br><span class="line">    resultHandler: (<span class="type">Int</span>, <span class="type">U</span>) =&gt; <span class="type">Unit</span>,</span><br><span class="line">    properties: <span class="type">Properties</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="keyword">val</span> start = <span class="type">System</span>.nanoTime</span><br><span class="line">  <span class="comment">//提交至消息总线，由DAGScheduler.doOnReceive处理</span></span><br><span class="line">  <span class="keyword">val</span> waiter = submitJob(rdd, func, partitions, callSite, resultHandler, properties)</span><br><span class="line">  <span class="type">ThreadUtils</span>.awaitReady(waiter.completionFuture, <span class="type">Duration</span>.<span class="type">Inf</span>)</span><br><span class="line">  <span class="comment">// 方法阻塞等待任务执行结束</span></span><br><span class="line">  waiter.completionFuture.value.get <span class="keyword">match</span> &#123;</span><br><span class="line">    ...</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="5">
<li>org.apache.spark.scheduler.DAGScheduler#submitJob</li>
</ol>
  <figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">submitJob</span></span>[<span class="type">T</span>, <span class="type">U</span>](</span><br><span class="line">    rdd: <span class="type">RDD</span>[<span class="type">T</span>],</span><br><span class="line">    func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[<span class="type">T</span>]) =&gt; <span class="type">U</span>,</span><br><span class="line">    partitions: <span class="type">Seq</span>[<span class="type">Int</span>],</span><br><span class="line">    callSite: <span class="type">CallSite</span>,</span><br><span class="line">    resultHandler: (<span class="type">Int</span>, <span class="type">U</span>) =&gt; <span class="type">Unit</span>,</span><br><span class="line">    properties: <span class="type">Properties</span>): <span class="type">JobWaiter</span>[<span class="type">U</span>] = &#123;</span><br><span class="line">    </span><br><span class="line">  <span class="keyword">val</span> maxPartitions = rdd.partitions.length</span><br><span class="line">...</span><br><span class="line">  <span class="comment">// 生成全局的JobId</span></span><br><span class="line">  <span class="keyword">val</span> jobId = nextJobId.getAndIncrement()</span><br><span class="line">  <span class="keyword">if</span> (partitions.size == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="comment">// Return immediately if the job is running 0 tasks</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">new</span> <span class="type">JobWaiter</span>[<span class="type">U</span>](<span class="keyword">this</span>, jobId, <span class="number">0</span>, resultHandler)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> func2 = func.asInstanceOf[(<span class="type">TaskContext</span>, <span class="type">Iterator</span>[_]) =&gt; _]</span><br><span class="line">  <span class="comment">// 分区数等于task数</span></span><br><span class="line">  <span class="keyword">val</span> waiter = <span class="keyword">new</span> <span class="type">JobWaiter</span>(<span class="keyword">this</span>, jobId, partitions.size, resultHandler)</span><br><span class="line">  <span class="comment">// 向总线发出JobSubmitted事件，通过监听器模式，通知给所有监听器</span></span><br><span class="line">  eventProcessLoop.post(<span class="type">JobSubmitted</span>(</span><br><span class="line">    jobId, rdd, func2, partitions.toArray, callSite, waiter,</span><br><span class="line">    <span class="type">SerializationUtils</span>.clone(properties)))</span><br><span class="line">  waiter</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="6">
<li>org.apache.spark.scheduler.DAGScheduler#handleJobSubmitted</li>
</ol>
  <figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">  <span class="keyword">private</span>[scheduler] <span class="function"><span class="keyword">def</span> <span class="title">handleJobSubmitted</span></span>(jobId: <span class="type">Int</span>,</span><br><span class="line">      finalRDD: <span class="type">RDD</span>[_],</span><br><span class="line">      func: (<span class="type">TaskContext</span>, <span class="type">Iterator</span>[_]) =&gt; _,</span><br><span class="line">      partitions: <span class="type">Array</span>[<span class="type">Int</span>],</span><br><span class="line">      callSite: <span class="type">CallSite</span>,</span><br><span class="line">      listener: <span class="type">JobListener</span>,</span><br><span class="line">      properties: <span class="type">Properties</span>) &#123;</span><br><span class="line">    <span class="keyword">var</span> finalStage: <span class="type">ResultStage</span> = <span class="literal">null</span></span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">// New stage creation may throw an exception if, for example, jobs are run on a</span></span><br><span class="line">      <span class="comment">// HadoopRDD whose underlying HDFS files have been deleted.</span></span><br><span class="line">      <span class="comment">// 从最后一个Stage开始向前创建DAG</span></span><br><span class="line">      finalStage = createResultStage(finalRDD, func, partitions, jobId, callSite)</span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> e: <span class="type">BarrierJobSlotsNumberCheckFailed</span> =&gt;</span><br><span class="line">  ...</span><br><span class="line">        <span class="keyword">val</span> numCheckFailures = barrierJobIdToNumTasksCheckFailures.compute(jobId,</span><br><span class="line">          <span class="keyword">new</span> <span class="type">BiFunction</span>[<span class="type">Int</span>, <span class="type">Int</span>, <span class="type">Int</span>] &#123;</span><br><span class="line">            <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">apply</span></span>(key: <span class="type">Int</span>, value: <span class="type">Int</span>): <span class="type">Int</span> = value + <span class="number">1</span></span><br><span class="line">          &#125;)</span><br><span class="line">        <span class="keyword">if</span> (numCheckFailures &lt;= maxFailureNumTasksCheck) &#123;</span><br><span class="line">          messageScheduler.schedule(</span><br><span class="line">            <span class="keyword">new</span> <span class="type">Runnable</span> &#123;</span><br><span class="line">              <span class="comment">// job提交失败，在最大允许次数内进行重新提交</span></span><br><span class="line">              <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(): <span class="type">Unit</span> = eventProcessLoop.post(<span class="type">JobSubmitted</span>(jobId, finalRDD, func,</span><br><span class="line">                partitions, callSite, listener, properties))</span><br><span class="line">...</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// Job submitted, clear internal data.</span></span><br><span class="line">    barrierJobIdToNumTasksCheckFailures.remove(jobId)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> job = <span class="keyword">new</span> <span class="type">ActiveJob</span>(jobId, finalStage, callSite, listener, properties)</span><br><span class="line">    clearCacheLocs()</span><br><span class="line">	...</span><br><span class="line">    <span class="keyword">val</span> jobSubmissionTime = clock.getTimeMillis()</span><br><span class="line">    jobIdToActiveJob(jobId) = job</span><br><span class="line">    activeJobs += job</span><br><span class="line">    finalStage.setActiveJob(job)</span><br><span class="line">    <span class="comment">// 任务提交流程 - 根据jobId获取其对应的所有Stages,通知给消息总线，</span></span><br><span class="line">    <span class="comment">// 在org.apache.spark.status.AppStatusListener.onJobStart方法中处理</span></span><br><span class="line">    <span class="keyword">val</span> stageIds = jobIdToStageIds(jobId).toArray</span><br><span class="line">    <span class="keyword">val</span> stageInfos = stageIds.flatMap(id =&gt; stageIdToStage.get(id).map(_.latestInfo))</span><br><span class="line">    <span class="comment">// 根据SparkListenerJobStart事件，构建stage的DAG执行图,并刷新至UI</span></span><br><span class="line">    listenerBus.post(</span><br><span class="line">      <span class="type">SparkListenerJobStart</span>(job.jobId, jobSubmissionTime, stageInfos, properties))</span><br><span class="line">    <span class="comment">// 提交Stage开始执行</span></span><br><span class="line">    submitStage(finalStage)</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>SparkListenerJobStart事件通过消息总线会通知到org.apache.spark.status.AppStatusListener#onJobStart，进行UI界面展示。</li>
</ul>
<ol start="7">
<li>org.apache.spark.scheduler.DAGScheduler#submitStage</li>
</ol>
  <figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">submitStage</span></span>(stage: <span class="type">Stage</span>) &#123;</span><br><span class="line">  <span class="keyword">val</span> jobId = activeJobForStage(stage)</span><br><span class="line">  <span class="keyword">if</span> (jobId.isDefined) &#123;</span><br><span class="line">    logDebug(<span class="string">s&quot;submitStage(<span class="subst">$stage</span> (name=<span class="subst">$&#123;stage.name&#125;</span>;&quot;</span> +</span><br><span class="line">      <span class="string">s&quot;jobs=<span class="subst">$&#123;stage.jobIds.toSeq.sorted.mkString(&quot;,&quot;)&#125;</span>))&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> (!waitingStages(stage) &amp;&amp; !runningStages(stage) &amp;&amp; !failedStages(stage)) &#123;</span><br><span class="line">      <span class="comment">// 通过查找missingStage构建出了所有的Stage,由于Stage从后向前构建的特性，</span></span><br><span class="line">      <span class="comment">// flinaStage的missingStage就是所有的直接依赖的Stage</span></span><br><span class="line">      <span class="keyword">val</span> missing = getMissingParentStages(stage).sortBy(_.id)</span><br><span class="line">      logDebug(<span class="string">&quot;missing: &quot;</span> + missing)</span><br><span class="line">      <span class="comment">// 只有最后一个Stage,即最贴近数据源的Stage才满足missing.isEmpty</span></span><br><span class="line">      <span class="keyword">if</span> (missing.isEmpty) &#123;</span><br><span class="line">        logInfo(<span class="string">&quot;Submitting &quot;</span> + stage + <span class="string">&quot; (&quot;</span> + stage.rdd + <span class="string">&quot;), which has no missing parents&quot;</span>)</span><br><span class="line">        <span class="comment">// 开始从最后一个Stage提交Task</span></span><br><span class="line">        submitMissingTasks(stage, jobId.get)</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">for</span> (parent &lt;- missing) &#123;</span><br><span class="line">          submitStage(parent)</span><br><span class="line">        &#125;</span><br><span class="line">        waitingStages += stage</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    abortStage(stage, <span class="string">&quot;No active job for stage &quot;</span> + stage.id, <span class="type">None</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>这是一个尾递归方法，由第一个Stage触发上游依赖的Stage的构建，从而完成DAG的构建。</li>
</ul>
<ol start="8">
<li>org.apache.spark.scheduler.DAGScheduler#getMissingParentStages</li>
</ol>
  <figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">getMissingParentStages</span></span>(stage: <span class="type">Stage</span>): <span class="type">List</span>[<span class="type">Stage</span>] = &#123;</span><br><span class="line">  <span class="keyword">val</span> missing = <span class="keyword">new</span> <span class="type">HashSet</span>[<span class="type">Stage</span>]</span><br><span class="line">  <span class="keyword">val</span> visited = <span class="keyword">new</span> <span class="type">HashSet</span>[<span class="type">RDD</span>[_]]</span><br><span class="line">  <span class="comment">// We are manually maintaining a stack here to prevent StackOverflowError</span></span><br><span class="line">  <span class="comment">// caused by recursively visiting</span></span><br><span class="line">  <span class="keyword">val</span> waitingForVisit = <span class="keyword">new</span> <span class="type">ArrayStack</span>[<span class="type">RDD</span>[_]]</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">visit</span></span>(rdd: <span class="type">RDD</span>[_]) &#123;</span><br><span class="line">    <span class="keyword">if</span> (!visited(rdd)) &#123;</span><br><span class="line">      visited += rdd</span><br><span class="line">      <span class="comment">// 查找缓存中的RDD的分区的TaskLocation,没有就通过BlockManagerMaster进行获取并存储</span></span><br><span class="line">      <span class="keyword">val</span> rddHasUncachedPartitions = getCacheLocs(rdd).contains(<span class="type">Nil</span>)</span><br><span class="line">      <span class="keyword">if</span> (rddHasUncachedPartitions) &#123;</span><br><span class="line">        <span class="keyword">for</span> (dep &lt;- rdd.dependencies) &#123;</span><br><span class="line">          dep <span class="keyword">match</span> &#123;</span><br><span class="line">            <span class="keyword">case</span> shufDep: <span class="type">ShuffleDependency</span>[_, _, _] =&gt;</span><br><span class="line">              <span class="comment">// 构建ShuffleMapStage，优先使用已经创建过的，复用已经生成的ShuffleMapStage的输出</span></span><br><span class="line">              <span class="keyword">val</span> mapStage = getOrCreateShuffleMapStage(shufDep, stage.firstJobId)</span><br><span class="line">              <span class="keyword">if</span> (!mapStage.isAvailable) &#123;</span><br><span class="line">                missing += mapStage</span><br><span class="line">              &#125;</span><br><span class="line">            <span class="keyword">case</span> narrowDep: <span class="type">NarrowDependency</span>[_] =&gt;</span><br><span class="line">              waitingForVisit.push(narrowDep.rdd)</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  waitingForVisit.push(stage.rdd)</span><br><span class="line">  <span class="keyword">while</span> (waitingForVisit.nonEmpty) &#123;</span><br><span class="line">    visit(waitingForVisit.pop())</span><br><span class="line">  &#125;</span><br><span class="line">  missing.toList</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="9">
<li>org.apache.spark.scheduler.DAGScheduler#submitMissingTasks</li>
</ol>
  <figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">/** Called when stage&#x27;s parents are available and we can now do its task. */</span></span><br><span class="line"><span class="keyword">private</span> <span class="function"><span class="keyword">def</span> <span class="title">submitMissingTasks</span></span>(stage: <span class="type">Stage</span>, jobId: <span class="type">Int</span>) &#123;</span><br><span class="line">  logDebug(<span class="string">&quot;submitMissingTasks(&quot;</span> + stage + <span class="string">&quot;)&quot;</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// First figure out the indexes of partition ids to compute.</span></span><br><span class="line">  <span class="keyword">val</span> partitionsToCompute: <span class="type">Seq</span>[<span class="type">Int</span>] = stage.findMissingPartitions()</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Use the scheduling pool, job group, description, etc. from an ActiveJob associated</span></span><br><span class="line">  <span class="comment">// with this Stage</span></span><br><span class="line">  <span class="keyword">val</span> properties = jobIdToActiveJob(jobId).properties</span><br><span class="line"></span><br><span class="line">  runningStages += stage</span><br><span class="line">  <span class="comment">// SparkListenerStageSubmitted should be posted before testing whether tasks are</span></span><br><span class="line">  <span class="comment">// serializable. If tasks are not serializable, a SparkListenerStageCompleted event</span></span><br><span class="line">  <span class="comment">// will be posted, which should always come after a corresponding SparkListenerStageSubmitted</span></span><br><span class="line">  <span class="comment">// event.</span></span><br><span class="line">  stage <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> s: <span class="type">ShuffleMapStage</span> =&gt;</span><br><span class="line">      outputCommitCoordinator.stageStart(stage = s.id, maxPartitionId = s.numPartitions - <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">case</span> s: <span class="type">ResultStage</span> =&gt;</span><br><span class="line">      outputCommitCoordinator.stageStart(</span><br><span class="line">        stage = s.id, maxPartitionId = s.rdd.partitions.length - <span class="number">1</span>)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">val</span> taskIdToLocations: <span class="type">Map</span>[<span class="type">Int</span>, <span class="type">Seq</span>[<span class="type">TaskLocation</span>]] = <span class="keyword">try</span> &#123;</span><br><span class="line">    stage <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> s: <span class="type">ShuffleMapStage</span> =&gt;</span><br><span class="line">        partitionsToCompute.map &#123; id =&gt; (id, getPreferredLocs(stage.rdd, id))&#125;.toMap</span><br><span class="line">      <span class="keyword">case</span> s: <span class="type">ResultStage</span> =&gt;</span><br><span class="line">        partitionsToCompute.map &#123; id =&gt;</span><br><span class="line">          <span class="keyword">val</span> p = s.partitions(id)</span><br><span class="line">          (id, getPreferredLocs(stage.rdd, p))</span><br><span class="line">        &#125;.toMap</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">NonFatal</span>(e) =&gt;</span><br><span class="line">      stage.makeNewStageAttempt(partitionsToCompute.size)</span><br><span class="line">      listenerBus.post(<span class="type">SparkListenerStageSubmitted</span>(stage.latestInfo, properties))</span><br><span class="line">      abortStage(stage, <span class="string">s&quot;Task creation failed: <span class="subst">$e</span>\n<span class="subst">$&#123;Utils.exceptionString(e)&#125;</span>&quot;</span>, <span class="type">Some</span>(e))</span><br><span class="line">      runningStages -= stage</span><br><span class="line">      <span class="keyword">return</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  stage.makeNewStageAttempt(partitionsToCompute.size, taskIdToLocations.values.toSeq)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// If there are tasks to execute, record the submission time of the stage. Otherwise,</span></span><br><span class="line">  <span class="comment">// post the even without the submission time, which indicates that this stage was</span></span><br><span class="line">  <span class="comment">// skipped.</span></span><br><span class="line">  <span class="keyword">if</span> (partitionsToCompute.nonEmpty) &#123;</span><br><span class="line">    stage.latestInfo.submissionTime = <span class="type">Some</span>(clock.getTimeMillis())</span><br><span class="line">  &#125;</span><br><span class="line">  listenerBus.post(<span class="type">SparkListenerStageSubmitted</span>(stage.latestInfo, properties))</span><br><span class="line"></span><br><span class="line">  <span class="comment">// <span class="doctag">TODO:</span> Maybe we can keep the taskBinary in Stage to avoid serializing it multiple times.</span></span><br><span class="line">  <span class="comment">// Broadcasted binary for the task, used to dispatch tasks to executors. Note that we broadcast</span></span><br><span class="line">  <span class="comment">// the serialized copy of the RDD and for each task we will deserialize it, which means each</span></span><br><span class="line">  <span class="comment">// task gets a different copy of the RDD. This provides stronger isolation between tasks that</span></span><br><span class="line">  <span class="comment">// might modify state of objects referenced in their closures. This is necessary in Hadoop</span></span><br><span class="line">  <span class="comment">// where the JobConf/Configuration object is not thread-safe.</span></span><br><span class="line">  <span class="keyword">var</span> taskBinary: <span class="type">Broadcast</span>[<span class="type">Array</span>[<span class="type">Byte</span>]] = <span class="literal">null</span></span><br><span class="line">  <span class="keyword">var</span> partitions: <span class="type">Array</span>[<span class="type">Partition</span>] = <span class="literal">null</span></span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="comment">// For ShuffleMapTask, serialize and broadcast (rdd, shuffleDep).</span></span><br><span class="line">    <span class="comment">// For ResultTask, serialize and broadcast (rdd, func).</span></span><br><span class="line">    <span class="keyword">var</span> taskBinaryBytes: <span class="type">Array</span>[<span class="type">Byte</span>] = <span class="literal">null</span></span><br><span class="line">    <span class="comment">// taskBinaryBytes and partitions are both effected by the checkpoint status. We need</span></span><br><span class="line">    <span class="comment">// this synchronization in case another concurrent job is checkpointing this RDD, so we get a</span></span><br><span class="line">    <span class="comment">// consistent view of both variables.</span></span><br><span class="line">    <span class="type">RDDCheckpointData</span>.synchronized &#123;</span><br><span class="line">      taskBinaryBytes = stage <span class="keyword">match</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> stage: <span class="type">ShuffleMapStage</span> =&gt;</span><br><span class="line">          <span class="type">JavaUtils</span>.bufferToArray(</span><br><span class="line">            closureSerializer.serialize((stage.rdd, stage.shuffleDep): <span class="type">AnyRef</span>))</span><br><span class="line">        <span class="keyword">case</span> stage: <span class="type">ResultStage</span> =&gt;</span><br><span class="line">          <span class="type">JavaUtils</span>.bufferToArray(closureSerializer.serialize((stage.rdd, stage.func): <span class="type">AnyRef</span>))</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      partitions = stage.rdd.partitions</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 通过广播将闭包序列化后的task信息广播出去</span></span><br><span class="line">    taskBinary = sc.broadcast(taskBinaryBytes)</span><br><span class="line">  &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">    <span class="comment">// In the case of a failure during serialization, abort the stage.</span></span><br><span class="line">    <span class="keyword">case</span> e: <span class="type">NotSerializableException</span> =&gt;</span><br><span class="line">      abortStage(stage, <span class="string">&quot;Task not serializable: &quot;</span> + e.toString, <span class="type">Some</span>(e))</span><br><span class="line">      runningStages -= stage</span><br><span class="line"></span><br><span class="line">      <span class="comment">// Abort execution</span></span><br><span class="line">      <span class="keyword">return</span></span><br><span class="line">    <span class="keyword">case</span> e: <span class="type">Throwable</span> =&gt;</span><br><span class="line">      abortStage(stage, <span class="string">s&quot;Task serialization failed: <span class="subst">$e</span>\n<span class="subst">$&#123;Utils.exceptionString(e)&#125;</span>&quot;</span>, <span class="type">Some</span>(e))</span><br><span class="line">      runningStages -= stage</span><br><span class="line"></span><br><span class="line">      <span class="comment">// Abort execution</span></span><br><span class="line">      <span class="keyword">return</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 拆解Stage，提取各分区最优计算位置，封装成task集合</span></span><br><span class="line">  <span class="keyword">val</span> tasks: <span class="type">Seq</span>[<span class="type">Task</span>[_]] = <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">val</span> serializedTaskMetrics = closureSerializer.serialize(stage.latestInfo.taskMetrics).array()</span><br><span class="line">    stage <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> stage: <span class="type">ShuffleMapStage</span> =&gt;</span><br><span class="line">        stage.pendingPartitions.clear()</span><br><span class="line">        partitionsToCompute.map &#123; id =&gt;</span><br><span class="line">          <span class="keyword">val</span> locs = taskIdToLocations(id)</span><br><span class="line">          <span class="keyword">val</span> part = partitions(id)</span><br><span class="line">          stage.pendingPartitions += id</span><br><span class="line">          <span class="keyword">new</span> <span class="type">ShuffleMapTask</span>(stage.id, stage.latestInfo.attemptNumber,</span><br><span class="line">            taskBinary, part, locs, properties, serializedTaskMetrics, <span class="type">Option</span>(jobId),</span><br><span class="line">            <span class="type">Option</span>(sc.applicationId), sc.applicationAttemptId, stage.rdd.isBarrier())</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">case</span> stage: <span class="type">ResultStage</span> =&gt;</span><br><span class="line">        partitionsToCompute.map &#123; id =&gt;</span><br><span class="line">          <span class="keyword">val</span> p: <span class="type">Int</span> = stage.partitions(id)</span><br><span class="line">          <span class="keyword">val</span> part = partitions(p)</span><br><span class="line">          <span class="keyword">val</span> locs = taskIdToLocations(id)</span><br><span class="line">          <span class="keyword">new</span> <span class="type">ResultTask</span>(stage.id, stage.latestInfo.attemptNumber,</span><br><span class="line">            taskBinary, part, locs, id, properties, serializedTaskMetrics,</span><br><span class="line">            <span class="type">Option</span>(jobId), <span class="type">Option</span>(sc.applicationId), sc.applicationAttemptId,</span><br><span class="line">            stage.rdd.isBarrier())</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">NonFatal</span>(e) =&gt;</span><br><span class="line">      abortStage(stage, <span class="string">s&quot;Task creation failed: <span class="subst">$e</span>\n<span class="subst">$&#123;Utils.exceptionString(e)&#125;</span>&quot;</span>, <span class="type">Some</span>(e))</span><br><span class="line">      runningStages -= stage</span><br><span class="line">      <span class="keyword">return</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (tasks.size &gt; <span class="number">0</span>) &#123;</span><br><span class="line">    logInfo(<span class="string">s&quot;Submitting <span class="subst">$&#123;tasks.size&#125;</span> missing tasks from <span class="subst">$stage</span> (<span class="subst">$&#123;stage.rdd&#125;</span>) (first 15 &quot;</span> +</span><br><span class="line">      <span class="string">s&quot;tasks are for partitions <span class="subst">$&#123;tasks.take(15).map(_.partitionId)&#125;</span>)&quot;</span>)</span><br><span class="line">    <span class="comment">// 将task集合构建为TaskSet提交给taskScheduler进行计算</span></span><br><span class="line">    taskScheduler.submitTasks(<span class="keyword">new</span> <span class="type">TaskSet</span>(</span><br><span class="line">      tasks.toArray, stage.id, stage.latestInfo.attemptNumber, jobId, properties))</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// Because we posted SparkListenerStageSubmitted earlier, we should mark</span></span><br><span class="line">    <span class="comment">// the stage as completed here in case there are no tasks to run</span></span><br><span class="line">    markStageAsFinished(stage, <span class="type">None</span>)</span><br><span class="line"></span><br><span class="line">    stage <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> stage: <span class="type">ShuffleMapStage</span> =&gt;</span><br><span class="line">        logDebug(<span class="string">s&quot;Stage <span class="subst">$&#123;stage&#125;</span> is actually done; &quot;</span> +</span><br><span class="line">            <span class="string">s&quot;(available: <span class="subst">$&#123;stage.isAvailable&#125;</span>,&quot;</span> +</span><br><span class="line">            <span class="string">s&quot;available outputs: <span class="subst">$&#123;stage.numAvailableOutputs&#125;</span>,&quot;</span> +</span><br><span class="line">            <span class="string">s&quot;partitions: <span class="subst">$&#123;stage.numPartitions&#125;</span>)&quot;</span>)</span><br><span class="line">        markMapStageJobsAsFinished(stage)</span><br><span class="line">      <span class="keyword">case</span> stage : <span class="type">ResultStage</span> =&gt;</span><br><span class="line">        logDebug(<span class="string">s&quot;Stage <span class="subst">$&#123;stage&#125;</span> is actually done; (partitions: <span class="subst">$&#123;stage.numPartitions&#125;</span>)&quot;</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 当前Stage计算完成后，开始提交其子Stage进行计算</span></span><br><span class="line">    submitWaitingChildStages(stage)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>至此，collect方法在Driver端的任务已经完成。</p>
</li>
</ul>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><ul>
<li>SparkContext作为整个程序的上下文对象，其初始化过程中，注册并启动了任务执行相关的各种组件：<ul>
<li>RPCEnv：网络通信组件，为各组件通信提供支持</li>
<li>UI : 程序执行进度和相关性能指标的展示。</li>
<li>DAGScheduler：根据用户代码，按照RDD依赖关系，构建出Stage的执行单元，继而组建出DAG图</li>
<li>TaskScheduler：用来处理Stage,将其构建出TaskSet,提交给Executor执行。</li>
</ul>
</li>
<li>RDD作为Spark框架中对数据的高度抽象，它只是对操作对象的概括，包含了以下核心内容：<ul>
<li>partition：数据块真实存放的位置</li>
<li>storageLevel：缓存数据的位置</li>
<li>dependencies：该RDD依赖的上游RDD集合</li>
</ul>
</li>
</ul>
<p>根据涉及到的类，及其初始化位置的分析，可以知道，用户程序在Driver端按照从后向前的顺序，由DAGscheduler对RDD进行解析，构建出Stage集合，再由TaskScheduler提交给Executor进行处理。</p>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>spark</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark collect方法分析-Executor端</title>
    <url>/2023/12/17/Spark-collect%E6%96%B9%E6%B3%95%E5%88%86%E6%9E%90-Executor%E7%AB%AF/</url>
    <content><![CDATA[<h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>​	在Spark框架中，理解用户代码是怎么被框架执行的，有助于我们写出高效高质量的代码，也有利于我们在问题分析时可以快速准确的定位问题。</p>
<p>​	collect方法作为一个简单的方法，其执行过程也足以展示整个框架的执行流程。</p>
<h2 id="目的"><a href="#目的" class="headerlink" title="目的"></a>目的</h2><p>​	通过对调用过程的分析，深入理解整个框架的计算过程，从根本上理解程序的执行逻辑。</p>
<span id="more"></span>

<h2 id="流程分析"><a href="#流程分析" class="headerlink" title="流程分析"></a>流程分析</h2><p>​	在上文（collect方法的Driver端分析）中，</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">taskScheduler.submitTasks(<span class="keyword">new</span> <span class="type">TaskSet</span>(</span><br><span class="line">      tasks.toArray, stage.id, stage.latestInfo.attemptNumber, jobId, properties))</span><br></pre></td></tr></table></figure>

<p>被DAGscheduler构建出来的TaskSet，会由taskScheduler进行调度执行。接下来，我们针对后续流程进行跟踪分析。</p>
<ul>
<li><p>提交后的流程分析</p>
<ul>
<li><p>org.apache.spark.scheduler.TaskSchedulerImpl#submitTasks</p>
<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">submitTasks</span></span>(taskSet: <span class="type">TaskSet</span>) &#123;</span><br><span class="line">  <span class="keyword">val</span> tasks = taskSet.tasks</span><br><span class="line">  logInfo(<span class="string">&quot;Adding task set &quot;</span> + taskSet.id + <span class="string">&quot; with &quot;</span> + tasks.length + <span class="string">&quot; tasks&quot;</span>)</span><br><span class="line">  <span class="keyword">this</span>.synchronized &#123;</span><br><span class="line">    <span class="comment">// 组合模式，创建TaskSetManager，将TaskSet托管给TaskSetManager，也就是说每个TaskSet有一个TaskSetManager</span></span><br><span class="line">    <span class="keyword">val</span> manager = createTaskSetManager(taskSet, maxTaskFailures)</span><br><span class="line">    <span class="keyword">val</span> stage = taskSet.stageId</span><br><span class="line">    <span class="keyword">val</span> stageTaskSets =</span><br><span class="line">      taskSetsByStageIdAndAttempt.getOrElseUpdate(stage, <span class="keyword">new</span> <span class="type">HashMap</span>[<span class="type">Int</span>, <span class="type">TaskSetManager</span>])</span><br><span class="line">    stageTaskSets.foreach &#123; <span class="keyword">case</span> (_, ts) =&gt;</span><br><span class="line">      ts.isZombie = <span class="literal">true</span></span><br><span class="line">    &#125;</span><br><span class="line">    stageTaskSets(taskSet.stageAttemptId) = manager</span><br><span class="line">    <span class="comment">// schedulableBuilder 会在org.apache.spark.scheduler.TaskSchedulerImpl.initialize()时进行初始化，</span></span><br><span class="line">    <span class="comment">// 该配置由“spark.scheduler.mode”的具体配置决定，默认FIFO调度策略</span></span><br><span class="line">    <span class="comment">// 根据配置，采用不同的调度策略执行TaskSet</span></span><br><span class="line">    schedulableBuilder.addTaskSetManager(manager, manager.taskSet.properties)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> (!isLocal &amp;&amp; !hasReceivedTask) &#123;</span><br><span class="line">      starvationTimer.scheduleAtFixedRate(<span class="keyword">new</span> <span class="type">TimerTask</span>() &#123;</span><br><span class="line">        <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>() &#123;</span><br><span class="line">          <span class="keyword">if</span> (!hasLaunchedTask) &#123;</span><br><span class="line">            logWarning(<span class="string">&quot;Initial job has not accepted any resources; &quot;</span> +</span><br><span class="line">              <span class="string">&quot;check your cluster UI to ensure that workers are registered &quot;</span> +</span><br><span class="line">              <span class="string">&quot;and have sufficient resources&quot;</span>)</span><br><span class="line">          &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">this</span>.cancel()</span><br><span class="line">          &#125;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;, <span class="type">STARVATION_TIMEOUT_MS</span>, <span class="type">STARVATION_TIMEOUT_MS</span>)</span><br><span class="line">    &#125;</span><br><span class="line">    hasReceivedTask = <span class="literal">true</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 由Driver上的后端进行TaskSet的分配和启动</span></span><br><span class="line">  backend.reviveOffers()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>消息中间件-ActiveMQ</title>
    <url>/2017/10/22/activemq/</url>
    <content><![CDATA[<h2 id="1-1-JMS简介"><a href="#1-1-JMS简介" class="headerlink" title="1.1 JMS简介"></a>1.1 JMS简介</h2><blockquote>
<p>JMS（Java Messaging Service） 是 Java 平台上有关面向消息中间件的技术规范， 它便于消息系统中的Java应用程序进行消息交换,并且通过提供标准的产生、发送、 接收消息的接口简化企业应用的开发。</p>
</blockquote>
<h2 id="1-2-ActiveMQ简介"><a href="#1-2-ActiveMQ简介" class="headerlink" title="1.2 ActiveMQ简介"></a>1.2 ActiveMQ简介</h2><blockquote>
<p>ActiveMQ 是 Apache 出品， 最流行的， 能力强劲的开源消息总线。 ActiveMQ 是一个完全支持 JMS1.1 和 J2EE 1.4 规范的 JMS Provider 实现， 尽管 JMS 规范出台已经是很久的事情了，但是JMS在当今的J2EE应用中间仍然扮演着特殊的地位。</p>
</blockquote>
<span id="more"></span>

<p>对消息的传递有两种类型：</p>
<ol>
<li>一种是点对点(Queue)：消息的生产者和消费者都可以是多个，但是对同一条消息而言，消息的制造者只有一个，消费者也只有一个，生产者和消费者一一对应</li>
<li>另一种是发布&#x2F;订阅模式：即一个生产者产生并发送一个消息后，可以由多个消费者进行接收。</li>
</ol>
<p><strong>JMS定义的五种消息正文格式</strong></p>
<ul>
<li>StreamMessage–Java原始值的数据流</li>
<li>MapMessage–一套名称-值对</li>
<li>TextMessage–一个字符串对象</li>
<li>ObjectMessage–一个序列化的Java对象</li>
<li>ByteMessage–一个字节的数据流</li>
</ul>
<hr>
<p>ActiveMQ安装：<br>下载并解压</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -zxvf apache-activemq-5.12.0-bin.tar.gz</span><br></pre></td></tr></table></figure>
<p>为apache-activemq-5.12.0赋权</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">chmod 777 apache-activemq-5.12.0</span><br></pre></td></tr></table></figure>
<p>进入apache-activemq-5.12.0\bin，并且给activemq赋权</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">chmod 755 activemq </span><br></pre></td></tr></table></figure>
<p>启动</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./activemq start</span><br></pre></td></tr></table></figure>
<p>ActiveMQ的默认管理端口：8161，通信端口：61616</p>
<hr>
<h2 id="ActiveMQ示例"><a href="#ActiveMQ示例" class="headerlink" title="ActiveMQ示例"></a>ActiveMQ示例</h2><h4 id="点对点模式"><a href="#点对点模式" class="headerlink" title="点对点模式"></a>点对点模式</h4><p>(1) 创建activemqDemo,引入依赖</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;groupId&gt;org.apache.activemq&lt;/groupId&gt;</span><br><span class="line">&lt;artifactId&gt;activemq-all&lt;/artifactId&gt;</span><br><span class="line">&lt;version&gt;5.11.2&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure>
<p>(2) 创建QueueProducer(核心步骤)</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//1、创建连接工厂</span></span><br><span class="line"><span class="type">ActiveMQConnectionFactory</span> <span class="variable">connectionFactory</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ActiveMQConnectionFaction</span>(<span class="string">&quot;tcp://192.168.25.133:61616&quot;</span>);</span><br><span class="line"><span class="comment">//2、获取连接</span></span><br><span class="line"><span class="type">Connection</span> <span class="variable">connection</span> <span class="operator">=</span> connectionFactory.createConnection();</span><br><span class="line"><span class="comment">//3、启动连接</span></span><br><span class="line">connection.start();</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">* 4、获取session</span></span><br><span class="line"><span class="comment">* 第 1 个参数 是否使用事务</span></span><br><span class="line"><span class="comment">* 第 2 个参数 消息的确认模式</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="type">Session</span> <span class="variable">session</span> <span class="operator">=</span> connection.createSession(<span class="literal">false</span>,Session.AUTO_ACKNOWLEDGE);</span><br><span class="line"><span class="comment">//5、创建队列对象,test-queue为消息队列的唯一标识</span></span><br><span class="line"><span class="type">Queue</span> <span class="variable">queue</span> <span class="operator">=</span> session.createQueue(<span class="string">&quot;test-queue&quot;</span>);</span><br><span class="line"><span class="comment">//6、创建消息生产者对象</span></span><br><span class="line"><span class="type">MessageProductor</span> <span class="variable">producer</span> <span class="operator">=</span> session.createProducer(queue);</span><br><span class="line"><span class="comment">//7、创建文本消息</span></span><br><span class="line"><span class="type">TextMessage</span> <span class="variable">textMessage</span> <span class="operator">=</span> session.createTextMessage(<span class="string">&quot;ActiveMQ消息测试！&quot;</span>);</span><br><span class="line"><span class="comment">//8、使用生产者发送消息</span></span><br><span class="line">producer.send(textMessage);</span><br><span class="line"><span class="comment">//9、关闭资源</span></span><br><span class="line">producer.close();</span><br><span class="line">session.close();</span><br><span class="line">connection.close();</span><br></pre></td></tr></table></figure>

<p>(3)消息消费者</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//1、创建连接工厂</span></span><br><span class="line"><span class="type">ActiveMQConnectionFactory</span> <span class="variable">connectionFactory</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ActiveMQConnectionFactory</span>(<span class="string">&quot;tcp://192.168.25.133:61616&quot;</span>);</span><br><span class="line"><span class="comment">//2、获取连接</span></span><br><span class="line"><span class="type">Connection</span> <span class="variable">connection</span> <span class="operator">=</span> connectionFactory.createConnection();</span><br><span class="line"><span class="comment">//3、启动连接</span></span><br><span class="line">connection.start();</span><br><span class="line"><span class="comment">//4、获取session</span></span><br><span class="line"><span class="type">Session</span> <span class="variable">session</span> <span class="operator">=</span> connection.createSession(<span class="literal">false</span>,Session.AUTO_ACKNOWLEDGE);</span><br><span class="line"><span class="comment">//5、创建队列对象</span></span><br><span class="line"><span class="type">Queue</span> <span class="variable">queue</span> <span class="operator">=</span> session.createQueue(<span class="string">&quot;test-queue&quot;</span>);</span><br><span class="line"><span class="comment">//6、创建消息消费者对象</span></span><br><span class="line"><span class="type">MessageConsumer</span> <span class="variable">consumer</span> <span class="operator">=</span> session.createConsumer(queue);</span><br><span class="line"><span class="comment">//7、接收消息</span></span><br><span class="line">consumer.setMessageListener(<span class="keyword">new</span> <span class="title class_">MessageListener</span>()&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onMessage</span><span class="params">(Message message)</span>&#123;</span><br><span class="line">        <span class="comment">//获取文本消息对象</span></span><br><span class="line">        <span class="type">TextMessage</span> <span class="variable">textMessage</span> <span class="operator">=</span> (TextMessage)message;</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            <span class="type">String</span> <span class="variable">text</span> <span class="operator">=</span> textMEssage.getText();<span class="comment">//提取文本</span></span><br><span class="line">            System.out.println(text);</span><br><span class="line">        &#125;<span class="keyword">catch</span>(JMSException e)&#123;</span><br><span class="line">           ·····</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br><span class="line"><span class="comment">//8、等待键盘输入，以阻塞线程，是线程保持监听状态</span></span><br><span class="line">System.in.read();</span><br><span class="line"><span class="comment">//9、关闭资源</span></span><br><span class="line">consumer.close();</span><br><span class="line">session.close();</span><br><span class="line">connection.close();</span><br></pre></td></tr></table></figure>

<h4 id="发布-订阅模式"><a href="#发布-订阅模式" class="headerlink" title="发布&#x2F;订阅模式"></a>发布&#x2F;订阅模式</h4><p>(1)创建消息生产者</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//1、创建连接工厂</span></span><br><span class="line"><span class="type">ActiveMQConnectionFactory</span> <span class="variable">connectionFactory</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">ActiveMQConnectionFactory</span>(<span class="string">&quot;tcp://192.168.25.133:61616&quot;</span>);</span><br><span class="line"><span class="comment">//2、创建连接</span></span><br><span class="line"><span class="type">Connection</span> <span class="variable">connection</span> <span class="operator">=</span> connectionFactory.createConnection();</span><br><span class="line"><span class="comment">//3、启动连接</span></span><br><span class="line">connection.start();</span><br><span class="line"><span class="comment">//4、创建会话</span></span><br><span class="line"><span class="type">Session</span> <span class="variable">session</span> <span class="operator">=</span> connection.createSession(<span class="literal">false</span>, Session.AUTO_ACKNOWLEDGE);</span><br><span class="line"><span class="comment">//5、创建一个订阅topic</span></span><br><span class="line"><span class="type">Topic</span> <span class="variable">topic</span> <span class="operator">=</span> session.createTopic(<span class="string">&quot;text-topic&quot;</span>);</span><br><span class="line"><span class="comment">//6、创建消息生产者</span></span><br><span class="line"><span class="type">MessageProducer</span> <span class="variable">producer</span> <span class="operator">=</span> session.CreateProducer(topic);</span><br><span class="line"><span class="comment">//7、创建消息</span></span><br><span class="line"><span class="type">TextMessage</span> <span class="variable">textMessage</span> <span class="operator">=</span> session.createTextMEssage(<span class="string">&quot;这是一个topic消息测试&quot;</span>);</span><br><span class="line"><span class="comment">//8、发送消息</span></span><br><span class="line">producer.send(textMessage);</span><br><span class="line"><span class="comment">//9、关闭资源</span></span><br><span class="line">producer.close();</span><br><span class="line">session.close();</span><br><span class="line">connection.close();</span><br></pre></td></tr></table></figure>
<p>(2)创建消息消费者</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//1.创建连接工厂</span></span><br><span class="line">ActiveMQConnectionFactory connectionFactory=<span class="keyword">new</span></span><br><span class="line"><span class="title class_">ActiveMQConnectionFactory</span>(<span class="string">&quot;tcp://192.168.25.133:61616&quot;</span>);</span><br><span class="line"><span class="comment">//2.获取连接</span></span><br><span class="line"><span class="type">Connection</span> <span class="variable">connection</span> <span class="operator">=</span> connectionFactory.createConnection();</span><br><span class="line"><span class="comment">//3.启动连接</span></span><br><span class="line">connection.start();</span><br><span class="line"><span class="comment">//4.获取 session</span></span><br><span class="line"><span class="type">Session</span> <span class="variable">session</span> <span class="operator">=</span> connection.createSession(<span class="literal">false</span>, Session.AUTO_ACKNOWLEDGE);</span><br><span class="line"><span class="comment">//5.创建主题对象</span></span><br><span class="line"><span class="type">Topic</span> <span class="variable">topic</span> <span class="operator">=</span> session.createTopic(<span class="string">&quot;test-topic&quot;</span>);</span><br><span class="line"><span class="comment">//6.创建消息消费者</span></span><br><span class="line">MessageConsumer consumer=session.createConsumer(topic);</span><br><span class="line"><span class="comment">//7、接收消息</span></span><br><span class="line">consumer.setMessageListener(<span class="keyword">new</span> <span class="title class_">MessageListener</span>()&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onMessage</span><span class="params">(Message message)</span>&#123;</span><br><span class="line">        <span class="type">TextMessage</span> <span class="variable">textMessage</span> <span class="operator">=</span> (TextMessage)message;</span><br><span class="line">        <span class="keyword">try</span>&#123;</span><br><span class="line">            <span class="type">String</span> <span class="variable">text</span> <span class="operator">=</span> textMessage.getText();</span><br><span class="line">            System.out.println(text);</span><br><span class="line">        &#125;<span class="keyword">catch</span>()&#123;</span><br><span class="line">            ·······</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br><span class="line"><span class="comment">//8、等待键盘输入</span></span><br><span class="line">System.in.read();</span><br><span class="line"><span class="comment">//9、关闭资源</span></span><br><span class="line">consumer.close();</span><br><span class="line">session.close();</span><br><span class="line">connection.close();</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Web</category>
      </categories>
      <tags>
        <tag>搜索引擎</tag>
      </tags>
  </entry>
  <entry>
    <title>Docker容器技术</title>
    <url>/2019/08/28/docker%E5%AE%B9%E5%99%A8/</url>
    <content><![CDATA[<h1 id="Docker"><a href="#Docker" class="headerlink" title="Docker"></a>Docker</h1><h2 id="容器技术"><a href="#容器技术" class="headerlink" title="容器技术"></a>容器技术</h2><blockquote>
<p>&emsp;&emsp;容器技术相比于管理程序虚拟化(hypervisor virtualization，HV)的不同之处在于，<br>管理程序虚拟化通过中间层将一台或者多台独立的机器虚拟运行与物理硬件之上，而容器则是直接运行在<br>操作系统内核之上的用户空间。因此，容器虚拟化也被称为“操作系统级虚拟化”，容器技术可以让多个<br>独立用户空间运行在同一台宿主机上。</p>
</blockquote>
<span id="more"></span>
<blockquote>
<p>&emsp;&emsp;由于容器依赖于操作系统，采用的是<strong>共享内核</strong>的运行方式，所以容器只能运行与底层宿主机相同或者相似的操作系统。</p>
</blockquote>
<blockquote>
<p>&emsp;&emsp;相对于彻底隔离的HV，容器被认为是不安全的。容器采用的是沙盒机制，其底层仍需<br>调用操作系统的接口来实现自身的功能，所以不能完全与宿主机系统完全隔离，会有潜在的风险。</p>
</blockquote>
<blockquote>
<p>&emsp;&emsp; 尽管有诸多的局限性，容器还是被广泛部署于各种各样的应用场合。在差大规模的多<br>租户服务部署、轻量级沙盒以及对安全要求不太高的隔离环境中，容器技术非常流行。</p>
</blockquote>
<blockquote>
<p>&emsp;&emsp;最新的容器技术引入了OpenVZ，Solaris Zones以及Linux容器(LXC)。使用这些新技<br>术，容器不再仅仅是一个单独的运行环境。在自己的权限内，容器更像一个完整的宿主机。对Dockers来<br>说，它得益于现代Linux特性，如控件组(control group)，命名空间(namespace)技术，容器和宿主机<br>之间的隔离更加彻底，容器有独立的网络和存储栈，还拥有自己的资源管理能力，使得同一台宿主机中的<br>多个容器可以友好的共存。</p>
</blockquote>
<blockquote>
<p>&emsp;&emsp;和传统的虚拟化以及半虚拟化相比，容器不需要模拟层(emulation layer)和管理层<br>(hypervisor layer)，而是使用操作系统的系统调用接口，这降低了运行单个容器所需的开销，也使得<br>宿主机中可以运行更多的容器。</p>
</blockquote>
<hr>
<h3 id="容器与虚拟机的比较"><a href="#容器与虚拟机的比较" class="headerlink" title="容器与虚拟机的比较"></a>容器与虚拟机的比较</h3><p>1、本质区别</p>
<blockquote>
<p>虚拟机依赖于<strong>hypervisor</strong>，在虚拟机使用硬件资源时，由hypervisor统一调度、分配，而容器是运行在<br>操作系统之上的一个隔离环境，可以认为是一个独立的进程，容器内的应用程序使用的其实是操作系统分<br>配给该容器的计算资源。</p>
</blockquote>
<p>2、资源使用率</p>
<blockquote>
<p>相比于虚拟机，容器因为采用的是<strong>共享内核</strong>的工作方式，所以<strong>容器可以看成是一个组装好了一套特定<br>应用程序的虚拟机，直接利用宿主机的内核，完成相应操作的虚拟机</strong>。正式由于这个特性，使得容器抽象层<br>比虚拟机更少，更加轻量化，启动速度更快。但是带来的弊端也是显而易见的，共享内核的机制使得容器受制于<br>操作系统，并且安全性得不到足够的保证。而虚拟机则是牺牲一部分性能，获得的是完整的隔离性，使得虚拟机的<br>安全性大大提高，可移植性也更强。</p>
</blockquote>
<table>
<thead>
<tr>
<th>对比项</th>
<th align="center">docker</th>
<th align="right">虚拟化</th>
</tr>
</thead>
<tbody><tr>
<td>快速创建、删除</td>
<td align="center">启动应用</td>
<td align="right">启动GuestOS + 启动应用</td>
</tr>
<tr>
<td>交付、部署</td>
<td align="center">容器镜像</td>
<td align="right">虚拟机镜像</td>
</tr>
<tr>
<td>单节点密度</td>
<td align="center">100~1000</td>
<td align="right">10~100</td>
</tr>
<tr>
<td>更新管理</td>
<td align="center">迭代式更新，修改Dockerfile，对增量内容进行分发、存储、传输、节点启动和恢复迅速</td>
<td align="right">向虚拟机推送安装、升级应用软件补丁包</td>
</tr>
<tr>
<td>稳定性</td>
<td align="center">每月更新一个版本</td>
<td align="right">KVM、Xen、VMware都已经很稳定</td>
</tr>
<tr>
<td>安全性</td>
<td align="center">Docker具有宿主机root权限</td>
<td align="right">硬件隔离：Guest OS运行在非根模式</td>
</tr>
<tr>
<td>监控成熟程度</td>
<td align="center">还在发展中</td>
<td align="right">Host、Hypervisor,VM的监控工具在生产环境已使用多年</td>
</tr>
<tr>
<td>高可用性</td>
<td align="center">通过业务本身的高可用性来保证</td>
<td align="right">快照、克隆、HA、动态迁移、异地容灾、异地双活</td>
</tr>
<tr>
<td>管理平台成熟度</td>
<td align="center">以k8s为代表，还在快速发展过程中</td>
<td align="right">以Openstack、vCenter、OPV-Suite为代表，已经在生产环境使用多年</td>
</tr>
</tbody></table>
<hr>
<h2 id="Docker特点"><a href="#Docker特点" class="headerlink" title="Docker特点"></a>Docker特点</h2><p>1、上手快</p>
<p>&emsp;&emsp;Docker依赖于“写时复制”(copy-on-write)模型，使得修改应用很快。然后就可以创建容器来运行应用程序。</p>
<p>2、职责的逻辑分类</p>
<p>&emsp;&emsp;使用Docker，开发人员只需关心容器内的应用程序，而运维人员只需要关系如何管理容器。Docker加强了开发人员写代码时的<br>开发环境与应用程序部署的生产环境的一致性。降低了“开发时一切正常，上线出问题”的环境问题发生概率。</p>
<p>3、快速高效的开发生命周期</p>
<p>&emsp;&emsp;缩短代码从开发、 测试到部署、 上线运行的周期， 让应用程序具备可移植性， 易于构建， 并易于协作。</p>
<p>4、鼓励使用面向服务的架构</p>
<p>&emsp;&emsp;Docker推荐单个容器只运行一个应用程序或进程，这样就形成了一个分布式的应用程序模型。在这种模型下，应用程序<br>或者服务都可以表示为一系列内部互联的容器，从而使得分布式部署应用程序，扩展或调试应用程序都变得简单，同时也提高了程序的内省性。</p>
<h2 id="Docker组件"><a href="#Docker组件" class="headerlink" title="Docker组件"></a>Docker组件</h2><h5 id="Docker客户端和服务器"><a href="#Docker客户端和服务器" class="headerlink" title="Docker客户端和服务器"></a>Docker客户端和服务器</h5><p>&emsp;&emsp;Docker是一个C&#x2F;S架构程序。Docker客户端只需要Docker服务器或者守护进程发出请求，服务器或者守护进程将完成所有工作<br>并返回结果。Docker提供了一个命令行工具Docker以及一套RESTful API。</p>
<h5 id="Docker镜像"><a href="#Docker镜像" class="headerlink" title="Docker镜像"></a>Docker镜像</h5><p>&emsp;&emsp;镜像是构建Docker的基石。镜像是基于联合文件系统的一种层式结构，有一系列指令一步步构建出来。镜像体积很小，非常“便捷”，<br>易于分享、存储和更新。</p>
<h5 id="Registry-注册中心"><a href="#Registry-注册中心" class="headerlink" title="Registry(注册中心)"></a>Registry(注册中心)</h5><p>&emsp;&emsp;Docker用Registry来保存用户构建的镜像。Registry分为公共和私有两种。Docker公司运营公共的Registry叫做Docker Hub。</p>
<h5 id="Docker容器"><a href="#Docker容器" class="headerlink" title="Docker容器"></a>Docker容器</h5><p>&emsp;&emsp;Docker可以帮助你构建和部署容器，我们只需把自己的应用程序或者服务打包进容器即可。容器是基于镜像启动起来的，容器中<br>可以运行一个或多个进程。我们可以认为，镜像是Docker生命周期中的构建或者打包阶段，而容器则是启动或者执行阶段。容器基于景象启动，<br>一旦容器启动完成，我们就可以登录到容器中安装自己需要的软件或者服务。</p>
<h2 id="Docker可以做什么"><a href="#Docker可以做什么" class="headerlink" title="Docker可以做什么"></a>Docker可以做什么</h2><ul>
<li><p>加速本地开发和构建流程，使其更加高效，更加轻量化。本地人员可以构建、运行并分享Docker容器。容器可以在开发环境中构建，然后提交到测试环境，<br>并最终部署至生产环境。</p>
</li>
<li><p>能够让独立的服务或应用程序在不同的环境中，得到相同的运行结果。这一点在面向服务和重度依赖微服务的部署尤为适用。</p>
</li>
<li><p>用docker创建隔离的环境来进行测试。例如，用Jenkins CI这样的持续集成工具启动一个用于测试的容器。</p>
</li>
<li><p>Docker 可以让开发者现在本机上构建一个复杂的程序或者架构来进行测试，而不是一开始就在生产环境部署、测试。</p>
</li>
</ul>
<hr>
<h2 id="Docker安装与启动"><a href="#Docker安装与启动" class="headerlink" title="Docker安装与启动"></a>Docker安装与启动</h2><h4 id="安装Docker"><a href="#安装Docker" class="headerlink" title="安装Docker"></a>安装Docker</h4><p>1、使用yum命令在线安装</p>
<blockquote>
<p><code>yum install docker</code></p>
</blockquote>
<p>2、查看docker版本</p>
<blockquote>
<p><code>docker -v</code></p>
</blockquote>
<h4 id="启动与停止docker"><a href="#启动与停止docker" class="headerlink" title="启动与停止docker"></a>启动与停止docker</h4><ul>
<li><p>启动docker:  <code>systemctl start docker</code></p>
</li>
<li><p>停止docker:  <code>systemctl stop docker</code></p>
</li>
<li><p>重启docker: <code>systemctl restart docker</code></p>
</li>
<li><p>查看docker状态：<code>systemctl status docker</code></p>
</li>
<li><p>开机启动： <code>systemctl enable docker</code></p>
</li>
</ul>
<p><strong>systemctl命令是系统服务管理器指令，是service和chkconfig两个命令的组合</strong></p>
<h4 id="Docker镜像的结构"><a href="#Docker镜像的结构" class="headerlink" title="Docker镜像的结构"></a>Docker镜像的结构</h4><p><img src="/images/docker%E9%95%9C%E5%83%8F%E7%9A%84%E7%BB%93%E6%9E%84.bmp" alt="docker镜像的结构"></p>
<h4 id="列出镜像"><a href="#列出镜像" class="headerlink" title="列出镜像"></a>列出镜像</h4><p>列出docker下的所有镜像：<code>docker images</code></p>
<p><img src="/images/%E5%88%97%E5%87%BAdocker%E4%B8%8B%E7%9A%84%E9%95%9C%E5%83%8F%E4%BF%A1%E6%81%AF.bmp" alt="docker下的镜像信息"></p>
<ul>
<li><p>REPOSITORY： 镜像所在的仓库名称</p>
</li>
<li><p>TAG： 镜像标签(可以直观地理解为镜像的版本号)</p>
</li>
<li><p>IMAGE ID： 镜像 ID(镜像的唯一标识)</p>
</li>
<li><p>CREATED： 镜像的创建日期（不是获取该镜像的日期，是镜像在构建成功时的时间）</p>
</li>
<li><p>SIZE： 镜像大小</p>
</li>
</ul>
<p>这些镜像都存储在宿主机的&#x2F;var&#x2F;lib&#x2F;docker目录下。</p>
<blockquote>
<p>我们在运行同一个仓库中的不同镜像时， 可以通过在仓库名后面加上一个冒号和标签名<br>来指定该仓库中的某一具体的镜像， 例如 <code>docker run --name custom_container_name –i –t docker.io/ubunto:12.04 /bin/bash</code>， 表明从镜像 Ubuntu:12.04 启动一个容器， 而这个镜像的操<br>作系统就是 Ubuntu:12.04。 在构建容器时指定仓库的标签也是一个好习惯。</p>
</blockquote>
<h4 id="配置Dcoker的镜像源"><a href="#配置Dcoker的镜像源" class="headerlink" title="配置Dcoker的镜像源"></a>配置Dcoker的镜像源</h4><p>1、编辑<code>/etc/docker/daemon.json</code>,不存在就手动创建。</p>
<p>2、在该文件中输入如下内容：</p>
<blockquote>
<p><code>&#123;   &quot;registry-mirrors&quot;: [&quot;https://docker.mirrors.ustc.edu.cn&quot;]   &#125;</code></p>
</blockquote>
<p>3、重启docker服务</p>
<h4 id="拉取、搜索、删除镜像"><a href="#拉取、搜索、删除镜像" class="headerlink" title="拉取、搜索、删除镜像"></a>拉取、搜索、删除镜像</h4><p>1、拉取镜像</p>
<p><code>docker pull 镜像名称</code></p>
<p>2、搜索镜像<br><code>docker search 镜像名称</code> ，例如：<code>docker search tomcat</code></p>
<p><img src="/images/%E6%90%9C%E7%B4%A2%E9%95%9C%E5%83%8F.bmp" alt="image/搜索镜像"></p>
<ul>
<li>NAME： 仓库名称</li>
<li>DESCRIPTION： 镜像描述</li>
<li>STARS： 用户评价， 反应一个镜像的受欢迎程度</li>
<li>OFFICIAL： 是否官方</li>
<li>AUTOMATED： 自动构建， 表示该镜像由 Docker Hub 自动构建流程创建的</li>
</ul>
<p>3、删除</p>
<ul>
<li><p>删除指定镜像<br><code>docker rmi 镜像ID</code></p>
</li>
<li><p>删除所有镜像</p>
<blockquote>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker rmi `docker image -q`</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="Docker容器操作"><a href="#Docker容器操作" class="headerlink" title="Docker容器操作"></a>Docker容器操作</h2><p>1、创建容器</p>
<p>&emsp;&emsp;命令:<code>docker run</code></p>
<p>&emsp;&emsp;命令参数说明：</p>
<ul>
<li><code>-i</code>: 表示以“交互模式”运行容器（类似于redis的前端启动）</li>
<li><code>-t</code>:表示容器启动后进入其命令行。加入这两个参数后，容器创建就能登陆进去，即分配<br>一个伪终端。</li>
<li><code>--name</code> :为创建的容器命名。</li>
<li><code>-v</code>:表示目录映射关系(前者是宿主机目录，后者是容器中映射到宿主机上的目录)，<br>可以使用多个<code>-v</code>做多个目录或文件映射。<strong>注意：最好做目录映射，在宿主机上做修改，然后共享到容器上</strong>。</li>
<li><code>-d</code>:在<code>run</code>后边加上<code>-d</code>参数，则会创建一个守护式容器在后台运行。（类似于redis的后端启动）</li>
<li><code>-p</code>:表示端口映射，前者是宿主机端口，后者是容器内的映射端口。也可以像<code>-v</code>一样做多个端口映射。</li>
</ul>
<p>2、查看容器</p>
<ul>
<li>查看所有的容器(历史启动过的容器)：<code>docker ps -a</code></li>
<li>查看最后一次运行的容器：<code>docker ps -l</code></li>
<li>查看正在运行的容器：<code>docker ps</code></li>
</ul>
<p>3、停止与启动容器</p>
<ul>
<li>停止正在运行的容器：<code>docker stop $CONTAINER_NAME/ID</code></li>
<li>启动已运行过的容器：<code>docker start $CONTAINER_NAME/ID</code></li>
</ul>
<p>4、删除容器</p>
<ul>
<li>删除指定的容器：<code>docker rm $CONTAINER_ID/NAME</code></li>
<li>删除所有容器：<blockquote>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker rm `docker ps -a -q`</span><br></pre></td></tr></table></figure></li>
</ul>
<h2 id="Docker部署应用-示例"><a href="#Docker部署应用-示例" class="headerlink" title="Docker部署应用(示例)"></a>Docker部署应用(示例)</h2><p>1、拉取MySQL镜像</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker pull mysql</span><br></pre></td></tr></table></figure>
<p>2、创建MySQL容器</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker run --name pinyougoou_mysql -p 33306:3306 -e MYSQL_ROOT_PASSWORD=123456</span><br><span class="line">-di mysql</span><br></pre></td></tr></table></figure>
<p>3、进入MySQL容器，并登录</p>
<p>进入容器</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker exec -it pinyougou_mysql /bin/bash</span><br></pre></td></tr></table></figure>
<p>登陆MySQL</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mysql -uroot -p</span><br></pre></td></tr></table></figure>

<p>4、远程登陆MySQL</p>
<p>原理:利用容器启动时的端口映射，我们只需要在Navicat上连接虚拟机的<code>33306</code>端口，<br>即可映射至容器内的3306端口，连接上容器内的MySQL，然后就可以像操作普通MySQL数据库<br>一样，对容器内MySQL数据库进行操作。</p>
<p><img src="/images/%E8%BF%9E%E6%8E%A5%E5%AE%B9%E5%99%A8%E5%86%85mysql.bmp" alt="连接容器内mysql"></p>
<p>5、查看容器IP地址</p>
<p>以下命令可以查看容器运行的各种数据：</p>
<p><code>docker inspect pinyougou_mysql</code></p>
<p><img src="/images/%E6%9F%A5%E7%9C%8B%E5%AE%B9%E5%99%A8%E8%BF%90%E8%A1%8C%E6%83%85%E5%86%B5.bmp" alt="查看容器运行情况"></p>
<p>也可以使用以下命令直接输出IP地址：</p>
<p><code>docker inspect --format=&#39;&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;&#39; mysql_pinyougou</code></p>
<p><strong>这个IP地址是由docker的服务端维护的，可以用于该服务端下所有客户端的通信</strong>。</p>
<hr>
<h2 id="备份与迁移"><a href="#备份与迁移" class="headerlink" title="备份与迁移"></a>备份与迁移</h2><h4 id="将容器保存成镜像"><a href="#将容器保存成镜像" class="headerlink" title="将容器保存成镜像"></a>将容器保存成镜像</h4><blockquote>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker commit pinyougou_mysql myMysql</span><br></pre></td></tr></table></figure>
<ul>
<li>pinyougou_mysql 是容器名称</li>
<li>myMysql是新的镜像名称</li>
</ul>
<h4 id="镜像备份"><a href="#镜像备份" class="headerlink" title="镜像备份"></a>镜像备份</h4><blockquote>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker save -o /home/myMysql.tar myMysql</span><br></pre></td></tr></table></figure>

<ul>
<li><code>-o</code> ：指定了<code>myMysql</code>镜像的备份文件的位置</li>
</ul>
<h4 id="镜像的恢复与迁移"><a href="#镜像的恢复与迁移" class="headerlink" title="镜像的恢复与迁移"></a>镜像的恢复与迁移</h4><blockquote>
</blockquote>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">docker load -i /home/myMysql.tar</span><br></pre></td></tr></table></figure>
<ul>
<li><code>-i</code>：加载的备份文件的路径</li>
</ul>
]]></content>
      <categories>
        <category>Web</category>
      </categories>
      <tags>
        <tag>虚拟化</tag>
      </tags>
  </entry>
  <entry>
    <title>使用Hexo搭建博客系统</title>
    <url>/2020/02/15/%E4%BD%BF%E7%94%A8Hexo%E6%90%AD%E5%BB%BA%E5%8D%9A%E5%AE%A2%E7%B3%BB%E7%BB%9F/</url>
    <content><![CDATA[<h2 id="Hexo简介"><a href="#Hexo简介" class="headerlink" title="Hexo简介"></a>Hexo简介</h2><p>Hexo是一款基于Node.js的静态博客框架，依赖少易于安装使用，可以方便的生成静态网页托管在GitHub和Coding上，是搭建博客的首选框架。大家可以进入<a href="https://hexo.io/zh-cn/index.html">Hexo官网</a>进行详细查看。</p>
<span id="more"></span>

<h2 id="Hexo搭建步骤"><a href="#Hexo搭建步骤" class="headerlink" title="Hexo搭建步骤"></a>Hexo搭建步骤</h2><ul>
<li>安装Git和Node.js</li>
<li>安装Hexo</li>
<li>配置Github Actions</li>
</ul>
<blockquote>
<p>Git和Node.js基础环境正常安装即可，只需要对Github做一下密钥登录，相关操作在网上有大量博客，不再赘述。</p>
</blockquote>
<h2 id="安装Hexo"><a href="#安装Hexo" class="headerlink" title="安装Hexo"></a>安装Hexo</h2><ol>
<li><p>安装hexo-cli脚手架</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">npm install -g hexo-cli	</span><br></pre></td></tr></table></figure>
</li>
<li><p>创建博客根目录</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir blog	</span><br></pre></td></tr></table></figure>
</li>
<li><p>初始化博客仓库</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo init blog	</span><br></pre></td></tr></table></figure>

<ul>
<li><p>新建完成后，指定文件夹目录下有：</p>
<ol>
<li><p><code>node_modules</code> : 依赖包</p>
</li>
<li><p><code>public</code> ：存放生成的页面</p>
</li>
<li><p><code>scaffolds</code> ：生成文章的一些模板</p>
</li>
<li><p><code>source</code> ：用来存放你的文章，MarkDown格式的文章，在<code>hexo g</code>生成时，会被自动构建出网页版，存放在public目录下</p>
</li>
<li><p><code>themes</code> ：主题目录</p>
</li>
<li><p><code>_config.yml</code> : <strong>博客的配置文件</strong>，具体配置参考官方，以下是我的配置</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Hexo Configuration</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># Docs: https://hexo.io/docs/configuration.html</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># Source: https://github.com/hexojs/hexo/</span></span></span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Site</span></span><br><span class="line">title: Duncan&#x27;s Blog</span><br><span class="line">subtitle: &#x27;记录学习 分享生活 品味人生&#x27;</span><br><span class="line">description: &#x27;吾生也有涯，而知也无涯，以有涯随无涯，殆己！已而为知者，殆而已矣。&#x27;</span><br><span class="line">keywords: </span><br><span class="line">author: Wang Fanming</span><br><span class="line">language: zh-CN</span><br><span class="line">timezone: &#x27;Asia/Shanghai&#x27;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">URL</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># Set your site url here. For example, if you use GitHub Page, set url as &#x27;https://username.github.io/project&#x27;</span></span></span><br><span class="line">url: https://www.wfanming.top</span><br><span class="line">root: /</span><br><span class="line">permalink: :year/:month/:day/:title/</span><br><span class="line">permalink_defaults:</span><br><span class="line">pretty_urls:</span><br><span class="line">  trailing_index: true # Set to false to remove trailing &#x27;index.html&#x27; from permalinks</span><br><span class="line">  trailing_html: true # Set to false to remove trailing &#x27;.html&#x27; from permalinks</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Directory</span></span><br><span class="line">source_dir: source</span><br><span class="line">public_dir: public</span><br><span class="line">tag_dir: tags</span><br><span class="line">archive_dir: archives</span><br><span class="line">category_dir: categories</span><br><span class="line">code_dir: downloads/code</span><br><span class="line">i18n_dir: :lang</span><br><span class="line">skip_render:</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Writing</span></span><br><span class="line">new_post_name: :title.md # File name of new posts</span><br><span class="line">default_layout: post</span><br><span class="line">titlecase: false # Transform title into titlecase</span><br><span class="line">external_link:</span><br><span class="line">  enable: true # Open external links in new tab</span><br><span class="line">  field: site # Apply to the whole site</span><br><span class="line">  exclude: &#x27;&#x27;</span><br><span class="line">filename_case: 0</span><br><span class="line">render_drafts: false</span><br><span class="line">post_asset_folder: false</span><br><span class="line">relative_link: false</span><br><span class="line">future: true</span><br><span class="line">syntax_highlighter: highlight.js</span><br><span class="line">highlight:</span><br><span class="line">  line_number: false</span><br><span class="line">  auto_detect: false</span><br><span class="line">  tab_replace: &#x27;&#x27;</span><br><span class="line">  wrap: true</span><br><span class="line">  hljs: false</span><br><span class="line">prismjs:</span><br><span class="line">  preprocess: false</span><br><span class="line">  line_number: true</span><br><span class="line">  tab_replace: &#x27;&#x27;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Home page setting</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">path: Root path <span class="keyword">for</span> your blogs index page. (default = <span class="string">&#x27;&#x27;</span>)</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">per_page: Posts displayed per page. (0 = <span class="built_in">disable</span> pagination)</span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">order_by: Posts order. (Order by <span class="built_in">date</span> descending by default)</span></span><br><span class="line">index_generator:</span><br><span class="line">  path: &#x27;&#x27;</span><br><span class="line">  per_page: 10</span><br><span class="line">  order_by: -date</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Category &amp; Tag</span></span><br><span class="line">default_category: uncategorized</span><br><span class="line">category_map:</span><br><span class="line">tag_map:</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Metadata elements</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># https://developer.mozilla.org/en-US/docs/Web/HTML/Element/meta</span></span></span><br><span class="line">meta_generator: true</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Date / Time format</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># Hexo uses Moment.js to parse and display date</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># You can customize the date format as defined in</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># http://momentjs.com/docs/#/displaying/format/</span></span></span><br><span class="line">date_format: YYYY-MM-DD</span><br><span class="line">time_format: HH:mm:ss</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># updated_option supports &#x27;mtime&#x27;, &#x27;date&#x27;, &#x27;empty&#x27;</span></span></span><br><span class="line">updated_option: &#x27;mtime&#x27;</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Pagination</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># Set per_page to 0 to disable pagination</span></span></span><br><span class="line">per_page: 10</span><br><span class="line">pagination_dir: page</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Include / Exclude file(s)</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># include:/exclude: options only apply to the &#x27;source/&#x27; folder</span></span></span><br><span class="line">include:</span><br><span class="line">exclude:</span><br><span class="line">ignore:</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Extensions</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># Plugins: https://hexo.io/plugins/</span></span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># Themes: https://hexo.io/themes/</span></span></span><br><span class="line">theme: next</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">Deployment</span></span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash"><span class="comment"># Docs: https://hexo.io/docs/one-command-deployment</span></span></span><br><span class="line">deploy:</span><br><span class="line">  type: &#x27;git&#x27;</span><br><span class="line">  repo: git@github.com:wangfanming/wangfanming.github.io.git</span><br><span class="line">  branch: main</span><br><span class="line"></span><br><span class="line">symbols_count_time:</span><br><span class="line"><span class="meta prompt_"> #</span><span class="language-bash">文章内是否显示</span></span><br><span class="line">  symbols: true</span><br><span class="line">  time: true</span><br><span class="line"><span class="meta prompt_"> # </span><span class="language-bash">网页底部是否显示</span></span><br><span class="line">  total_symbols: true</span><br><span class="line">  total_time: true</span><br><span class="line"><span class="meta prompt_"></span></span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">通用站点地图</span></span><br><span class="line">sitemap:</span><br><span class="line">  path: sitemap.xml</span><br><span class="line"><span class="meta prompt_"># </span><span class="language-bash">百度站点地图</span></span><br><span class="line">baidusitemap:</span><br><span class="line">  path: baidusitemap.xml</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ul>
</li>
<li><p>安装相关环境依赖</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd blog/</span><br><span class="line">npm install</span><br></pre></td></tr></table></figure>
</li>
<li><p>启动模板，检查初始化是否正常</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo s</span><br></pre></td></tr></table></figure>

<ul>
<li>通过<a href="http://localhost:4000/">http://localhost:4000</a>访问</li>
</ul>
</li>
<li><p>安装配置<a href="https://theme-next.iissnan.com/">Next主题</a> ，其他主题配置一样的方法</p>
<ul>
<li>安装</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">#</span><span class="language-bash">进入博客根目录</span></span><br><span class="line">cd blog/</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">下载自己喜欢的主题到Hexo主题目录 `themes/`</span></span><br><span class="line">git clone https://github.com/theme-next/hexo-theme-next themes/next</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ul>
<li>在博客配置文件_config.yml中启用Next主题</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">## Themes: https://hexo.io/themes/</span><br><span class="line">theme: next   #主题改为next</span><br></pre></td></tr></table></figure>

<ul>
<li>对Next主题的相关配置参考官网即可</li>
</ul>
</li>
<li><p>部署至本地测试一下，正常输出如下：</p>
<p><img src="/images/hexo%E5%8D%9A%E5%AE%A2%E9%A2%84%E8%A7%88.png" alt="hexo博客预览"></p>
</li>
<li><p>上传博客</p>
<ol>
<li><p>将书写好的MarkDown博客移至source&#x2F;_posts</p>
</li>
<li><p>构建网页，并部署</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">hexo clean</span><br><span class="line">hexo g</span><br><span class="line">hexo d</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>部署至Github前，必须保证远程仓库密钥配置成功</strong></li>
</ul>
</li>
</ol>
</li>
</ol>
<h2 id="配置Github-Actions"><a href="#配置Github-Actions" class="headerlink" title="配置Github Actions"></a>配置Github Actions</h2><blockquote>
<p>上述博客发布过程，每次必须编译然后进行上传，流程繁琐，且存在本地Node.js升级后与Hexo不匹配的问题，因此可以考虑使用Github Actions的持续集成能力来完成这个自动化过程。</p>
</blockquote>
<h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>Github Actions 可以很方便实现 CI&#x2F;CD 工作流，类似 Travis 的用法，来帮我们完成一些工作，比如实现自动化测试、打包、部署等操作。当我们运行 Jobs 时，它会创建一个容器 (runner)，容器支持：Ubuntu、Windows 和 MacOS 等系统，在容器中我们可以安装软件，利用安装的软件帮我们处理一些数据，然后把处理好的数据推送到某个地方。</p>
<p>本文将介绍利用 Github Actions 实现自动部署 hexo 到 Github Pages，在之前我们需要写完文章执行 <code>hexo generate --deploy</code> 来部署，当你文章比较多的时候，可能还需要等待很久，而且还可能会遇到本地安装的 Node.js 版本与 Hexo 不兼容的问题，目前我就是因为电脑的 Node.js 版本升到 v14 版本导致与 Hexo 不兼容部署不了，才来捣腾 Github Actions 功能的。利用 Github Actions 你将会没有这些烦恼。</p>
<h2 id="前提"><a href="#前提" class="headerlink" title="前提"></a>前提</h2><h3 id="创建所需仓库"><a href="#创建所需仓库" class="headerlink" title="创建所需仓库"></a>创建所需仓库</h3><ol>
<li>创建 <code>blog</code> 仓库用来存放 Hexo 项目</li>
<li>创建 <code>your.github.io</code> 仓库用来存放静态博客页面</li>
</ol>
<h3 id="生成部署密钥"><a href="#生成部署密钥" class="headerlink" title="生成部署密钥"></a>生成部署密钥</h3><p>一路按回车直到生成成功</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ ssh-keygen -f github-deploy-key</span><br></pre></td></tr></table></figure>

<p>当前目录下会有 <code>github-deploy-key</code> 和 <code>github-deploy-key.pub</code> 两个文件。</p>
<h3 id="配置部署密钥"><a href="#配置部署密钥" class="headerlink" title="配置部署密钥"></a>配置部署密钥</h3><p>复制 <code>github-deploy-key</code> 文件内容，在 <code>blog</code> 仓库 <code>Settings -&gt; Secrets -&gt; Add a new secret</code> 页面上添加。</p>
<ol>
<li>在 <code>Name</code> 输入框填写 <code>HEXO_DEPLOY_PRI</code>。</li>
<li>在 <code>Value</code> 输入框填写 <code>github-deploy-key</code> 文件内容。</li>
</ol>
<p><img src="https://sanonz.github.io/2020/deploy-a-hexo-blog-from-github-actions/add-secret@2x.png" alt="img"></p>
<p>复制 <code>github-deploy-key.pub</code> 文件内容，在 <code>your.github.io</code> 仓库 <code>Settings -&gt; Deploy keys -&gt; Add deploy key</code> 页面上添加。</p>
<ol>
<li>在 <code>Title</code> 输入框填写 <code>HEXO_DEPLOY_PUB</code>。</li>
<li>在 <code>Key</code> 输入框填写 <code>github-deploy-key.pub</code> 文件内容。</li>
<li>勾选 <code>Allow write access</code> 选项。</li>
</ol>
<p><img src="https://sanonz.github.io/2020/deploy-a-hexo-blog-from-github-actions/add-key@2x.png" alt="img"></p>
<h2 id="编写-Github-Actions"><a href="#编写-Github-Actions" class="headerlink" title="编写 Github Actions"></a>编写 Github Actions</h2><h3 id="Workflow-模版"><a href="#Workflow-模版" class="headerlink" title="Workflow 模版"></a>Workflow 模版</h3><p>在 <code>blog</code> 仓库根目录下创建 <code>.github/workflows/deploy.yml</code> 文件，目录结构如下。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">blog (repository)</span><br><span class="line">└── .github</span><br><span class="line">    └── workflows</span><br><span class="line">        └── deploy.yml</span><br></pre></td></tr></table></figure>

<p>在 <code>deploy.yml</code> 文件中粘贴以下内容。</p>
<figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">name:</span> <span class="string">Duncan&#x27;s</span> <span class="string">Blog</span> <span class="string">CI/CD</span></span><br><span class="line"></span><br><span class="line"><span class="attr">on:</span></span><br><span class="line">  <span class="attr">push:</span></span><br><span class="line">    <span class="attr">branches:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="string">main</span></span><br><span class="line"></span><br><span class="line"><span class="attr">env:</span></span><br><span class="line">  <span class="attr">GIT_USER:</span> <span class="string">wangfanming</span></span><br><span class="line">  <span class="attr">GIT_EMAIL:</span> <span class="string">wangfanming1204@gmail.com</span></span><br><span class="line">  <span class="attr">THEME_REPO:</span> <span class="string">wangfanming/hexo-theme-next</span></span><br><span class="line">  <span class="attr">THEME_BRANCH:</span> <span class="string">master</span></span><br><span class="line">  <span class="attr">DEPLOY_REPO:</span> <span class="string">wangfanming/wangfanming.github.io</span></span><br><span class="line">  <span class="attr">DEPLOY_BRANCH:</span> <span class="string">main</span></span><br><span class="line"></span><br><span class="line"><span class="attr">jobs:</span></span><br><span class="line">  <span class="attr">build:</span></span><br><span class="line">    <span class="attr">name:</span> <span class="string">Build</span> <span class="string">on</span> <span class="string">node</span> <span class="string">$&#123;&#123;</span> <span class="string">matrix.node_version</span> <span class="string">&#125;&#125;</span> <span class="string">and</span> <span class="string">$&#123;&#123;</span> <span class="string">matrix.os</span> <span class="string">&#125;&#125;</span></span><br><span class="line">    <span class="attr">runs-on:</span> <span class="string">ubuntu-latest</span></span><br><span class="line">    <span class="attr">strategy:</span></span><br><span class="line">      <span class="attr">matrix:</span></span><br><span class="line">        <span class="attr">os:</span> [<span class="string">ubuntu-latest</span>]</span><br><span class="line">        <span class="attr">node_version:</span> [<span class="number">21.4</span><span class="number">.0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="attr">steps:</span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Checkout</span></span><br><span class="line">        <span class="attr">uses:</span> <span class="string">actions/checkout@v2</span></span><br><span class="line"></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Checkout</span> <span class="string">theme</span> <span class="string">repo</span></span><br><span class="line">        <span class="attr">uses:</span> <span class="string">actions/checkout@v2</span></span><br><span class="line">        <span class="attr">with:</span></span><br><span class="line">          <span class="attr">repository:</span> <span class="string">$&#123;&#123;</span> <span class="string">env.THEME_REPO</span> <span class="string">&#125;&#125;</span></span><br><span class="line">          <span class="attr">ref:</span> <span class="string">$&#123;&#123;</span> <span class="string">env.THEME_BRANCH</span> <span class="string">&#125;&#125;</span></span><br><span class="line">          <span class="attr">path:</span> <span class="string">themes/next</span></span><br><span class="line"></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Checkout</span> <span class="string">deploy</span> <span class="string">repo</span></span><br><span class="line">        <span class="attr">uses:</span> <span class="string">actions/checkout@v2</span></span><br><span class="line">        <span class="attr">with:</span></span><br><span class="line">          <span class="attr">repository:</span> <span class="string">$&#123;&#123;</span> <span class="string">env.DEPLOY_REPO</span> <span class="string">&#125;&#125;</span></span><br><span class="line">          <span class="attr">ref:</span> <span class="string">$&#123;&#123;</span> <span class="string">env.DEPLOY_BRANCH</span> <span class="string">&#125;&#125;</span></span><br><span class="line">          <span class="attr">path:</span> <span class="string">.deploy_git</span></span><br><span class="line"></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Use</span> <span class="string">Node.js</span> <span class="string">$&#123;&#123;</span> <span class="string">matrix.node_version</span> <span class="string">&#125;&#125;</span></span><br><span class="line">        <span class="attr">uses:</span> <span class="string">actions/setup-node@v1</span></span><br><span class="line">        <span class="attr">with:</span></span><br><span class="line">          <span class="attr">node-version:</span> <span class="string">$&#123;&#123;</span> <span class="string">matrix.node_version</span> <span class="string">&#125;&#125;</span></span><br><span class="line"></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Cache</span> <span class="string">NPM</span> <span class="string">dependencies</span></span><br><span class="line">        <span class="attr">uses:</span> <span class="string">actions/cache@v2</span></span><br><span class="line">        <span class="attr">with:</span></span><br><span class="line">            <span class="comment"># npm cache files are stored in `~/.npm` on Linux/macOS</span></span><br><span class="line">            <span class="attr">path:</span> <span class="string">~/.npm</span></span><br><span class="line">            <span class="comment"># path: node_modules</span></span><br><span class="line">            <span class="attr">key:</span> <span class="string">$&#123;&#123;</span> <span class="string">runner.OS</span> <span class="string">&#125;&#125;-npm-cache</span></span><br><span class="line">            <span class="attr">restore-keys:</span> <span class="string">|</span></span><br><span class="line"><span class="string">              $&#123;&#123; runner.OS &#125;&#125;-npm-cache</span></span><br><span class="line"><span class="string"></span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Configuration</span> <span class="string">environment</span></span><br><span class="line">        <span class="attr">env:</span></span><br><span class="line">          <span class="attr">HEXO_DEPLOY_PRI:</span> <span class="string">$&#123;&#123;secrets.HEXO_DEPLOY_PRI&#125;&#125;</span></span><br><span class="line">        <span class="attr">run:</span> <span class="string">|</span></span><br><span class="line"><span class="string">          sudo timedatectl set-timezone &quot;Asia/Shanghai&quot;</span></span><br><span class="line"><span class="string">          mkdir -p ~/.ssh/</span></span><br><span class="line"><span class="string">          echo &quot;$HEXO_DEPLOY_PRI&quot; &gt; ~/.ssh/id_rsa</span></span><br><span class="line"><span class="string">          chmod 600 ~/.ssh/id_rsa</span></span><br><span class="line"><span class="string">          ssh-keyscan github.com &gt;&gt; ~/.ssh/known_hosts</span></span><br><span class="line"><span class="string">          git config --global user.name $GIT_USER</span></span><br><span class="line"><span class="string">          git config --global user.email $GIT_EMAIL</span></span><br><span class="line"><span class="string">          cp _config.next.yml themes/next/_config.yml</span></span><br><span class="line"><span class="string"></span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Init</span> <span class="string">Node.js</span> <span class="comment"># 安装源代码所需插件</span></span><br><span class="line">        <span class="attr">run:</span> <span class="string">|</span></span><br><span class="line"><span class="string">          npm install</span></span><br><span class="line"><span class="string">          echo &quot;Init node successful&quot;</span></span><br><span class="line"><span class="string"></span>      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Install</span> <span class="string">Hexo-cli</span> <span class="comment"># 安装 Hexo</span></span><br><span class="line">        <span class="attr">run:</span> <span class="string">|</span></span><br><span class="line"><span class="string">          npm install -g hexo-cli --save</span></span><br><span class="line"><span class="string">          npm i -S hexo-prism-plugin -g</span></span><br><span class="line"><span class="string">          npm i -S hexo-generator-search  -g</span></span><br><span class="line"><span class="string">          npm i -S hexo-symbols-count-time  -g</span></span><br><span class="line"><span class="string">          npm i -S hexo-permalink-pinyin  -g</span></span><br><span class="line"><span class="string">          npm i -S hexo-abbrlink -g</span></span><br><span class="line"><span class="string">          npm i -S hexo-wordcount  -g</span></span><br><span class="line"><span class="string">          npm i -S hexo-generator-feed  -g</span></span><br><span class="line"><span class="string">          npm i -S hexo-plugin-gitalk -g</span></span><br><span class="line"><span class="string">          echo &quot;install hexo successful&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line">      <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">Build</span> <span class="string">Blog</span> <span class="comment"># 编译创建静态博客文件</span></span><br><span class="line">        <span class="attr">run:</span> <span class="string">|</span></span><br><span class="line"><span class="string">          hexo clean</span></span><br><span class="line"><span class="string">          hexo g</span></span><br><span class="line"><span class="string">          hexo deploy</span></span><br><span class="line"><span class="string">          echo &quot;Build blog successful&quot;</span></span><br></pre></td></tr></table></figure>

<h3 id="模版参数说明"><a href="#模版参数说明" class="headerlink" title="模版参数说明"></a>模版参数说明</h3><ul>
<li><p><em>name</em> 为此 Action 的名字</p>
</li>
<li><p><em>on</em> 触发条件，当满足条件时会触发此任务，这里的 <code>on.push.branches.$.master</code> 是指当 <code>master</code> 分支收到 <code>push</code> 后执行任务。</p>
</li>
<li><p>env</p>
<p>为环境变量对象</p>
<ul>
<li><em>env.GIT_USER</em> 为 Hexo 编译后使用此 git 用户部署到仓库。</li>
<li><em>env.GIT_EMAIL</em> 为 Hexo 编译后使用此 git 邮箱部署到仓库。</li>
<li><em>env.THEME_REPO</em> 为您的 Hexo 所使用的主题的仓库，这里为 <code>sanonz/hexo-theme-concise</code>。</li>
<li><em>env.THEME_BRANCH</em> 为您的 Hexo 所使用的主题仓库的版本，可以是：branch、tag 或者 SHA。</li>
<li><em>env.DEPLOY_REPO</em> 为 Hexo 编译后要部署的仓库，例如：<code>sanonz/sanonz.github.io</code>。</li>
<li><em>env.DEPLOY_BRANCH</em> 为 Hexo 编译后要部署到的分支，例如：master。</li>
</ul>
</li>
<li><p>jobs</p>
<p>为此 Action 下的任务列表</p>
<ul>
<li><p><em>jobs.{job}.name</em> 任务名称</p>
</li>
<li><p><em>jobs.{job}.runs-on</em> 任务所需容器，可选值：<code>ubuntu-latest</code>、<code>windows-latest</code>、<code>macos-latest</code>。</p>
</li>
<li><p><em>jobs.{job}.strategy</em> 策略下可以写 <code>array</code> 格式，此 job 会遍历此数组执行。</p>
</li>
<li><p>jobs.{job}.steps</p>
<p>一个步骤数组，可以把所要干的事分步骤放到这里。</p>
<ul>
<li><em>jobs.{job}.steps.$.name</em> 步骤名，编译时会会以 LOG 形式输出。</li>
<li><em>jobs.{job}.steps.$.uses</em> 所要调用的 Action，可以到 <a href="https://github.com/actions">https://github.com/actions</a> 查看更多。</li>
<li><em>jobs.{job}.steps.$.with</em> 一个对象，调用 Action 传的参数，具体可以查看所使用 Action 的说明。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="第三方-Actions"><a href="#第三方-Actions" class="headerlink" title="第三方 Actions"></a>第三方 Actions</h3><p>使用第三方 Actions 语法 <code>&#123;owner&#125;/&#123;repo&#125;@&#123;ref&#125;</code> 或者 <code>&#123;owner&#125;/&#123;repo&#125;/&#123;path&#125;@&#123;ref&#125;</code> 例如：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">jobs:</span><br><span class="line">  build:</span><br><span class="line">    runs-on: ubuntu-latest</span><br><span class="line">    steps:</span><br><span class="line">      - uses: actions/checkout@v2</span><br></pre></td></tr></table></figure>

<p>一、调用 <code>actions/checkout@v2</code> 可以实现 Checkout 一个 git 仓库到容器。</p>
<p>例如 Checkout 当前仓库到本地，<code>with.repo</code> 不填写默认为当前仓库。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">jobs:</span><br><span class="line">  build:</span><br><span class="line">    runs-on: ubuntu-latest</span><br><span class="line">    steps:</span><br><span class="line">      - uses: actions/checkout@v2</span><br><span class="line">        # with:</span><br><span class="line">          # repository: $&#123;&#123; github.repository &#125;&#125;</span><br></pre></td></tr></table></figure>

<p>例如 Checkout 第三方仓库 <code>git@github.com:sanonz/hexo-theme-concise.git</code> 的 <code>master</code> 分支到容器 <code>themes/concise</code> 目录。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">jobs:</span><br><span class="line">  build:</span><br><span class="line">    runs-on: ubuntu-latest</span><br><span class="line">    steps:</span><br><span class="line">      - uses: actions/checkout@v2</span><br><span class="line">      - with:</span><br><span class="line">          repository: sanonz/hexo-theme-concise</span><br><span class="line">          ref: master</span><br><span class="line">          path: themes/concise</span><br></pre></td></tr></table></figure>

<p>二、调用 <code>actions/setup-node@v1</code> 可以配置容器 Node.js 环境。</p>
<p>例如安装 Node.js 版本 v12 到容器中，<code>with.node-version</code> 可以指定 Node.js 版本。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">jobs:</span><br><span class="line">  build:</span><br><span class="line">    runs-on: ubuntu-latest</span><br><span class="line">    steps:</span><br><span class="line">      - uses: actions/setup-node@v1</span><br><span class="line">      - with:</span><br><span class="line">          node-version: v12</span><br></pre></td></tr></table></figure>

<p>可以在这里查找更多 Actions 以及使用方式 <a href="https://github.com/marketplace?type=actions&query=checkout">官方 Actions 市场</a>。</p>
<h3 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h3><p>复制一份 <a href="https://github.com/sanonz/hexo-theme-concise/blob/master/_config.example.yml%EF%BC%8C%E6%94%BE%E5%88%B0">https://github.com/sanonz/hexo-theme-concise/blob/master/_config.example.yml，放到</a> <code>blog</code> 根目录下，名为 <code>_config.theme.yml</code>，如果您已经配置过此文件，只需要把您的复制过来就行。</p>
<p>最终目录结构</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">blog (repository)</span><br><span class="line">├── _config.theme.yml</span><br><span class="line">└── .github</span><br><span class="line">    └── workflows</span><br><span class="line">        └── deploy.yml</span><br></pre></td></tr></table></figure>

<p>把 <code>_config.theme.yml</code> 与 <code>deploy.yml</code> 文件推送到 <code>blog</code> 仓库，在此仓库 <code>Actions</code> 页面可以看到一个名字为 <code>CI</code> 的 Action。</p>
<h3 id="执行任务"><a href="#执行任务" class="headerlink" title="执行任务"></a>执行任务</h3><p>写一篇文章，<code>push</code> 到 <code>blog</code> 仓库的 <code>master</code> 分支，在此仓库 <code>Actions</code> 页面查看当前 task。</p>
<p><img src="https://sanonz.github.io/2020/deploy-a-hexo-blog-from-github-actions/run@2x.png" alt="img"></p>
<p>当任务完成后查看您的博客 <code>https://your.github.io</code>，如果不出意外的话已经可以看到新添加的文章了。</p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>偷懒是人类发展的动力，人都有偷懒的想法，目的就是为了让自己能够活得更好，经过几千年的不断发展，现在人偷懒的方式无疑更加的先进。</p>
<p>至此结束，感谢阅读。</p>
<h3 id="参考链接"><a href="#参考链接" class="headerlink" title="参考链接"></a>参考链接</h3><ul>
<li><a href="https://sanonz.github.io/2020/deploy-a-hexo-blog-from-github-actions/">利用 Github Actions 自动部署 Hexo 博客</a></li>
<li><a href="https://sanonz.github.io/2017/hello-world/">Hexo 搭建静态博客与 hexo-theme-concise 主题使用教程</a></li>
</ul>
]]></content>
      <categories>
        <category>Web</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>Java WEB项目中中文乱码</title>
    <url>/2017/05/12/%E5%85%B3%E4%BA%8EJavaWEB%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%B8%AD%E6%96%87%E4%B9%B1%E7%A0%81%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<hr>
<h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><p>如下表单：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&lt;form action=&quot;$&#123;pageContext.request.contextPath&#125;/UserServlet&quot; method=&quot;post&quot;&gt;</span><br><span class="line">    姓名：&lt;input type=&quot;text&quot; name=&quot;name&quot;&gt;</span><br><span class="line">    &lt;input type=&quot;submit&quot; value=&quot;提交&quot;&gt;</span><br><span class="line">&lt;/form&gt;    </span><br></pre></td></tr></table></figure>
<p>在这个表单中如果‘姓名’为中文，提交至web后端进行获取，如：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">name = request.getParameter(&quot;name&quot;);</span><br></pre></td></tr></table></figure>
<p>此时获取到的name的值一定是乱码，此时就要进行中文乱码处理了。</p>
<span id="more"></span>

<h2 id="处理方案可根据请求的类型分为两类"><a href="#处理方案可根据请求的类型分为两类" class="headerlink" title="处理方案可根据请求的类型分为两类:"></a>处理方案可根据请求的类型分为两类:</h2><p><strong>POST请求</strong>：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">request.setCharacterEncoding(&quot;UTF-8&quot;);//在接收请求参数之前，将request的缓冲区字符集设置为UTF-8</span><br><span class="line">request.getParameter(&quot;name&quot;);//此时再获取表单中的中文数据就不会乱码了</span><br></pre></td></tr></table></figure>
<p><strong>GET请求</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">String param = reques.getParameter(&quot;name&quot;);//首先获取表单数据</span><br><span class="line">String name = new String(param.getBytes(&quot;ISO-8859-1&quot;),&quot;UTF-8&quot;);//将获取到的表单数据以ISO-8859-1字符集转成字节数组，再按照UTF-8字符集编码成新的字符串，即可解决中文乱码</span><br></pre></td></tr></table></figure>

<p><strong>重点：</strong><br>    表单数据之所以乱码，是因为字符集不匹配，导致的，在Post请求时，我们在获取请求参数之前，将request缓冲区的字符集设置成UTF-8，即可在表单数据发送过来时，将表单数据按照UTF-8的编码放入缓冲区，在取出来时，自然就已经不会乱码了。在get请求时较为繁琐。需要首先将表单数据以ISO-8859-1字符集转成字节数组，因为request缓冲区的默认字符集是ISO-8859-1,所以以该字符集来将乱码数据转换成字节数组，不会丢失字节，从而保证了表单数据的完整性，进而以UTF-8字符集构造成新的字符串，将中文读出。<br>    但是如果需要将中文数据在页面展示，还需要：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">response.setContentType(&quot;text/html;charset=UTF-8&quot;);//向浏览器指明要以UTF-8字符集解析返回的数据</span><br></pre></td></tr></table></figure>

<p><em><strong>以上是针对单个网页的中文乱码解决方法</strong></em></p>
<!--more-->

<h3 id="在一个web项目中，中文乱码的解决方案"><a href="#在一个web项目中，中文乱码的解决方案" class="headerlink" title="在一个web项目中，中文乱码的解决方案"></a>在一个web项目中，中文乱码的解决方案</h3><h4 id="我认为最佳解决方案就是使用过滤器，拦截所有包含有中文的请求数据，转码后再传递给请求的目标地址。"><a href="#我认为最佳解决方案就是使用过滤器，拦截所有包含有中文的请求数据，转码后再传递给请求的目标地址。" class="headerlink" title="我认为最佳解决方案就是使用过滤器，拦截所有包含有中文的请求数据，转码后再传递给请求的目标地址。"></a>我认为最佳解决方案就是使用过滤器，拦截所有包含有中文的请求数据，转码后再传递给请求的目标地址。</h4><p>依旧以上述表单数据的中文乱码为例：<br>Filter代码如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">public class GenericEncodingFilter implements Filter &#123;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void destroy() &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void doFilter(ServletRequest request, ServletResponse response,</span><br><span class="line">            FilterChain chain) throws IOException, ServletException &#123;</span><br><span class="line">        // 转型为与协议相关对象</span><br><span class="line">        HttpServletRequest httpServletRequest = (HttpServletRequest) request;</span><br><span class="line">        // 对request包装增强</span><br><span class="line">        HttpServletRequest myrequest = new MyRequest(httpServletRequest);</span><br><span class="line">        chain.doFilter(myrequest, response);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void init(FilterConfig filterConfig) throws ServletException &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在上述代码中，我们思考到，之所以在获取表单数据时，拿到的中文都是乱码，是因为request对象本身并不具备对中乱码的解决能力，因此，我们想到以装饰者模式对request进行增强。(当然也可以使用动态代理来解决)<br><strong>关于装饰者模式的注意点：</strong></p>
<ol>
<li>增强的类要和被增强的类实现同一个接口 </li>
<li>增强的类需要传入一个被增强类的引用</li>
</ol>
<p>以下是增强HttpServletRequest对象的实现：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">// 自定义request对象</span><br><span class="line">class MyRequest extends HttpServletRequestWrapper &#123;</span><br><span class="line"></span><br><span class="line">    private HttpServletRequest request;</span><br><span class="line"></span><br><span class="line">    private boolean hasEncode;</span><br><span class="line"></span><br><span class="line">    public MyRequest(HttpServletRequest request) &#123;//此处传入了request的引用</span><br><span class="line">        super(request);// super必须写</span><br><span class="line">        this.request = request;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    // 对需要增强方法 进行覆盖</span><br><span class="line">    @Override</span><br><span class="line">    public Map getParameterMap() &#123;</span><br><span class="line">        // 先获得请求方式</span><br><span class="line">        String method = request.getMethod();</span><br><span class="line">        if (method.equalsIgnoreCase(&quot;post&quot;)) &#123;</span><br><span class="line">            // post请求</span><br><span class="line">            try &#123;</span><br><span class="line">                // 处理post乱码</span><br><span class="line">                request.setCharacterEncoding(&quot;utf-8&quot;);</span><br><span class="line">                return request.getParameterMap();</span><br><span class="line">            &#125; catch (UnsupportedEncodingException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; else if (method.equalsIgnoreCase(&quot;get&quot;)) &#123;</span><br><span class="line">            // get请求</span><br><span class="line">            Map&lt;String, String[]&gt; parameterMap = request.getParameterMap();</span><br><span class="line">            if (!hasEncode) &#123; // 确保get手动编码逻辑只运行一次</span><br><span class="line">                for (String parameterName : parameterMap.keySet()) &#123;</span><br><span class="line">                    String[] values = parameterMap.get(parameterName);</span><br><span class="line">                    if (values != null) &#123;</span><br><span class="line">                        for (int i = 0; i &lt; values.length; i++) &#123;</span><br><span class="line">                            try &#123;</span><br><span class="line">                                // 处理get乱码</span><br><span class="line">                                values[i] = new String(values[i]</span><br><span class="line">                                        .getBytes(&quot;ISO-8859-1&quot;), &quot;utf-8&quot;);</span><br><span class="line">                            &#125; catch (UnsupportedEncodingException e) &#123;</span><br><span class="line">                                e.printStackTrace();</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">                hasEncode = true;</span><br><span class="line">            &#125;</span><br><span class="line">            return parameterMap;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        return super.getParameterMap();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public String getParameter(String name) &#123;</span><br><span class="line">        Map&lt;String, String[]&gt; parameterMap = getParameterMap();</span><br><span class="line">        String[] values = parameterMap.get(name);</span><br><span class="line">        if (values == null) &#123;</span><br><span class="line">            return null;</span><br><span class="line">        &#125;</span><br><span class="line">        return values[0]; // 取回参数的第一个值</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public String[] getParameterValues(String name) &#123;</span><br><span class="line">        Map&lt;String, String[]&gt; parameterMap = getParameterMap();</span><br><span class="line">        String[] values = parameterMap.get(name);</span><br><span class="line">        return values;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在上述方法中，对request进行了增强，根据请求方法的不同，对request所携带的表单数据进行中文乱码的处理。然后将增强后的request向后传递：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">// 对request包装增强</span><br><span class="line">HttpServletRequest myrequest = new MyRequest(httpServletRequest);</span><br><span class="line">chain.doFilter(myrequest, response);//将包装后的myrequest对象作为request对象向后传递</span><br></pre></td></tr></table></figure>

<p>在web.xml中做如下配置</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&lt;filter&gt;</span><br><span class="line">    &lt;display-name&gt;GenericEncodingFilter&lt;/display-name&gt;</span><br><span class="line">    &lt;filter-name&gt;GenericEncodingFilter&lt;/filter-name&gt;</span><br><span class="line">    &lt;filter-class&gt;com.wfm.web.filter.GenericEncodingFilter&lt;/filter-class&gt;</span><br><span class="line">  &lt;/filter&gt;</span><br><span class="line">  &lt;filter-mapping&gt;</span><br><span class="line">    &lt;filter-name&gt;GenericEncodingFilter&lt;/filter-name&gt;</span><br><span class="line">    &lt;url-pattern&gt;/*&lt;/url-pattern&gt;</span><br><span class="line">  &lt;/filter-mapping&gt;</span><br></pre></td></tr></table></figure>
<p>上述配置中<code>&lt;url-pattern&gt;&lt;/url-pattern&gt; </code>,决定了该编码过滤器对哪些请求进行过滤，<code>/*</code>意思是指，对访问该web项目的所有请求都进行过滤。</p>
<h2 id="如何对所有的servlet进行请求的过滤？"><a href="#如何对所有的servlet进行请求的过滤？" class="headerlink" title="如何对所有的servlet进行请求的过滤？"></a>如何对所有的servlet进行请求的过滤？</h2><p>以下是一个servlet的配置：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&lt;servlet&gt;</span><br><span class="line">    &lt;description&gt;&lt;/description&gt;</span><br><span class="line">    &lt;display-name&gt;FormServlet&lt;/display-name&gt;</span><br><span class="line">    &lt;servlet-name&gt;FormServlet&lt;/servlet-name&gt;</span><br><span class="line">    &lt;servlet-class&gt;com.wfm.web.servlet.FormServlet&lt;/servlet-class&gt;</span><br><span class="line">  &lt;/servlet&gt;</span><br><span class="line">  &lt;servlet-mapping&gt;</span><br><span class="line">    &lt;servlet-name&gt;FormServlet&lt;/servlet-name&gt;</span><br><span class="line">    &lt;url-pattern&gt;/FormServlet&lt;/url-pattern&gt;</span><br><span class="line">  &lt;/servlet-mapping&gt;</span><br></pre></td></tr></table></figure>
<p>在上述配置中，请求通过访问<code>/FormServlet</code>路径触发FormServlet，因此，我们可以拦截所有对该路径的请求。但是如果我们要拦截的是指定的几个Servlet怎么办？此时，想到了如下方法：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&lt;servlet&gt;</span><br><span class="line">    &lt;description&gt;&lt;/description&gt;</span><br><span class="line">    &lt;display-name&gt;FormServlet&lt;/display-name&gt;</span><br><span class="line">    &lt;servlet-name&gt;FormServlet&lt;/servlet-name&gt;</span><br><span class="line">    &lt;servlet-class&gt;com.wfm.web.servlet.FormServlet&lt;/servlet-class&gt;</span><br><span class="line">&lt;/servlet&gt;</span><br><span class="line">&lt;servlet-mapping&gt;</span><br><span class="line">    &lt;servlet-name&gt;FormServlet&lt;/servlet-name&gt;</span><br><span class="line">    &lt;url-pattern&gt;/servlet/FormServlet&lt;/url-pattern&gt;</span><br><span class="line">&lt;/servlet-mapping&gt;</span><br></pre></td></tr></table></figure>
<p>我们可以在<code>FormServlet</code>的请求路径中加上一个虚拟路径，并将所有待拦截的Servlet的路径都添加<code>/servlet</code>即可构造出一个请求的目录，然后将Filter的<code> &lt;url-pattern&gt;/servlet/*&lt;/url-pattern&gt;</code>,这样就实现了对特定几个servlet的请求过滤。</p>
]]></content>
      <categories>
        <category>Web</category>
      </categories>
      <tags>
        <tag>中文乱码</tag>
      </tags>
  </entry>
  <entry>
    <title>搜索引擎的核心基础技术</title>
    <url>/2017/10/22/%E6%90%9C%E7%B4%A2%E5%BC%95%E6%93%8E%E7%9A%84%E6%A0%B8%E5%BF%83%E5%9F%BA%E7%A1%80%E6%8A%80%E6%9C%AF/</url>
    <content><![CDATA[<h3 id="Lucune-技术"><a href="#Lucune-技术" class="headerlink" title="Lucune 技术"></a>Lucune 技术</h3><ol>
<li><p>用户搜索的过程</p>
<ul>
<li>用户输入关键词</li>
</ul>
<ul>
<li>——–搜索过程——–</li>
<li>展示结果</li>
</ul>
</li>
<li><p>搜索相关技术</p>
<ul>
<li>lucene是什么？<ul>
<li>lucene是一个用来构建搜索引擎的类库，并不是一个完整的搜索引擎。</li>
<li>lucene核心功能：创建索引和查询索引</li>
</ul>
</li>
<li>solr是什么？<ul>
<li>是一个完整的搜索引擎，是基于lucene。</li>
<li><a href="http://lucene.apache.org/">官网地址</a></li>
</ul>
</li>
</ul>
</li>
<li><p>搜索的过程</p>
</li>
</ol>
<span id="more"></span>

<ul>
<li>在mysql数据库进行数据查询–mysql<ul>
<li>去哪里查？  mysql</li>
<li>怎么查询快一点？ select * from 表 where title like “%关键词%”；</li>
<li><strong>在海量数据下放弃数据库的查询技术</strong></li>
</ul>
</li>
<li>lucene的快速查询<ul>
<li>能够通过lucene的索引库实现海量数据的快速查询。</li>
<li>核心功能：创建索引、查询索引<ul>
<li>创建索引时，需要将数据读取之后进行分词。<strong>分词技术</strong></li>
</ul>
</li>
<li>lucene使用一个技术，叫做倒排索引，能够加快查询。<ul>
<li>什么是倒排索引</li>
<li>顺序查找的过程是 如果有一个万个文档，依次打开每个文档，然后逐行查询。</li>
<li>倒排索引时，<strong>通过提前计算，将一个关键词出现在哪些文档中，记录下来成为索引数据</strong>，查询的时候，去索引数据中查找。</li>
<li>举例</li>
</ul>
</li>
</ul>
</li>
</ul>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">document1</span><br><span class="line">我爱我的祖国，我的祖国很强大。</span><br><span class="line">document2</span><br><span class="line">我爱你祖国，祖国我爱你。</span><br><span class="line">document3</span><br><span class="line">爱我中华，为中华之崛起而编写爬虫。</span><br></pre></td></tr></table></figure>
<p>需求1：查找出现过“祖国”两个子的文档，并显示出来。<br>顺序查找：<br>readfile1-&gt;readline-&gt;find keyword<br>readfile2-&gt;readline-&gt;find keyword<br>……<br>倒排索引：提前创建索引<br>使用<strong>分词技术</strong>，将读取的一行句子分词。	</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">我|爱|我的|祖国|我的|祖国|很|强大</span><br><span class="line">我爱你|祖国|祖国|我爱你</span><br><span class="line">爱|我|中华|为|中华|之|崛起|而|编写|爬虫</span><br></pre></td></tr></table></figure>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">我：&#123;document1[1:1],document3[1:2]&#125;</span><br><span class="line">爱：&#123;docuemnt1[1:2],document3[1:1]&#125;</span><br><span class="line">我的：&#123;document1[1:3,1:5]&#125;</span><br><span class="line">祖国：&#123;document1[1:4,1:6],document2[1:2,1:3]&#125;</span><br></pre></td></tr></table></figure>
<p>使用倒排技术进行查询<br>1，先通过关键词找到对应的索引数据</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">祖国：&#123;document1[1:4,1:6],document2[1:2,1:3]&#125;</span><br></pre></td></tr></table></figure>
<p>2,根据索引数据拼装response返回结果集<br>3，展示给用户结果<br><img src="/images/2017-09-09_093931.png"></p>
<h1 id="4、lucene快速入门"><a href="#4、lucene快速入门" class="headerlink" title="4、lucene快速入门"></a>4、lucene快速入门</h1><ul>
<li>创建maven项目导入lucene的pom依赖<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&lt;dependencies&gt;</span><br><span class="line">	   &lt;dependency&gt;</span><br><span class="line">		&lt;groupId&gt;org.apache.lucene&lt;/groupId&gt;</span><br><span class="line">		&lt;artifactId&gt;lucene-core&lt;/artifactId&gt;</span><br><span class="line">		&lt;version&gt;4.10.2&lt;/version&gt;</span><br><span class="line">	&lt;/dependency&gt;</span><br><span class="line">	&lt;!-- 查询索引的一些包 --&gt;</span><br><span class="line">	&lt;dependency&gt;</span><br><span class="line">		&lt;groupId&gt;org.apache.lucene&lt;/groupId&gt;</span><br><span class="line">		&lt;artifactId&gt;lucene-queries&lt;/artifactId&gt;</span><br><span class="line">		&lt;version&gt;4.10.2&lt;/version&gt;</span><br><span class="line">	&lt;/dependency&gt;</span><br><span class="line">	&lt;dependency&gt;</span><br><span class="line">		&lt;groupId&gt;org.apache.lucene&lt;/groupId&gt;</span><br><span class="line">		&lt;artifactId&gt;lucene-test-framework&lt;/artifactId&gt;</span><br><span class="line">		&lt;version&gt;4.10.2&lt;/version&gt;</span><br><span class="line">	&lt;/dependency&gt;</span><br><span class="line">	&lt;!-- 创建索引时，需要创建倒排索引信息，创建倒排需要分词 --&gt;</span><br><span class="line">	&lt;dependency&gt;</span><br><span class="line">		&lt;groupId&gt;org.apache.lucene&lt;/groupId&gt;</span><br><span class="line">		&lt;artifactId&gt;lucene-analyzers-common&lt;/artifactId&gt;</span><br><span class="line">		&lt;version&gt;4.10.2&lt;/version&gt;</span><br><span class="line">	&lt;/dependency&gt;</span><br><span class="line">	&lt;!--  如果用户的输入的关键词是个组合词，或者一个句子：为什么打雷不下雨？ --&gt;</span><br><span class="line">	&lt;!-- 用来解析用户的查询意图 --&gt;</span><br><span class="line">	&lt;dependency&gt;</span><br><span class="line">		&lt;groupId&gt;org.apache.lucene&lt;/groupId&gt;</span><br><span class="line">		&lt;artifactId&gt;lucene-queryparser&lt;/artifactId&gt;</span><br><span class="line">		&lt;version&gt;4.10.2&lt;/version&gt;</span><br><span class="line">	&lt;/dependency&gt;</span><br><span class="line"> &lt;/dependencies&gt;</span><br></pre></td></tr></table></figure></li>
</ul>
<h1 id="4-1、创建索引的过程"><a href="#4-1、创建索引的过程" class="headerlink" title="4.1、创建索引的过程"></a>4.1、创建索引的过程</h1><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">LuceneMain</span> &#123;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">		<span class="comment">// 需求:使用lucene创建索引</span></span><br><span class="line">		<span class="comment">// 1.使用某种技术</span></span><br><span class="line">		<span class="comment">// document---&gt;分词---&gt;倒排---&gt;写入到索引库----介质(硬盘或者内存)</span></span><br><span class="line"></span><br><span class="line">		<span class="type">Directory</span> <span class="variable">d</span> <span class="operator">=</span> FSDirectory.open(<span class="keyword">new</span> <span class="title class_">File</span>(<span class="string">&quot;index&quot;</span>));</span><br><span class="line">		<span class="type">IndexWriterConfig</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IndexWriterConfig</span>(Version.LATEST, <span class="keyword">new</span> <span class="title class_">StandardAnalyzer</span>());</span><br><span class="line">		<span class="comment">// 第一步:创建indexWriter，传入两个参数，一个directory(FSDriectory,RAMDriectory);一个是IndexWriterConfig</span></span><br><span class="line">		<span class="comment">// IndexWriterConfig,传入两个参数，一个是版本号，一个分词器(中文分词器在3.1时过期了，推荐使用标准StandardAnalyzer)</span></span><br><span class="line">		<span class="type">IndexWriter</span> <span class="variable">indexWriter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IndexWriter</span>(d, conf);</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 第二步:对文件创建索引----虎嗅网站：id,title,author,createTime,content,url</span></span><br><span class="line">		<span class="comment">// 一个文档中，有很多字段，想通过title进行查询，这个字段需要被indexed。</span></span><br><span class="line">		<span class="comment">// 如果一个想创建索引，有两种选择，一种不被分词就是完全匹配，一种是分词。</span></span><br><span class="line">		<span class="type">Document</span> <span class="variable">document</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Document</span>();</span><br><span class="line">		<span class="comment">// StringField 不分词</span></span><br><span class="line">		document.add(<span class="keyword">new</span> <span class="title class_">StringField</span>(<span class="string">&quot;id&quot;</span>, <span class="string">&quot;100010&quot;</span>, Store.YES));</span><br><span class="line">		<span class="comment">// TextField 分词</span></span><br><span class="line">		document.add(<span class="keyword">new</span> <span class="title class_">TextField</span>(<span class="string">&quot;title&quot;</span>, <span class="string">&quot;《跑男》《极限挑战3》相继停播，政策已成为今年综艺的最大风险&quot;</span>, Store.YES));</span><br><span class="line">		<span class="comment">// StringField 不分词</span></span><br><span class="line">		document.add(<span class="keyword">new</span> <span class="title class_">StringField</span>(<span class="string">&quot;author&quot;</span>, <span class="string">&quot;文娱商业观察&quot;</span>, Store.YES));</span><br><span class="line">		<span class="comment">// StringField 不分词</span></span><br><span class="line">		document.add(<span class="keyword">new</span> <span class="title class_">StringField</span>(<span class="string">&quot;createTime&quot;</span>, <span class="string">&quot;100010&quot;</span>, Store.YES));</span><br><span class="line">		<span class="comment">// TextField 分词</span></span><br><span class="line">		document.add(<span class="keyword">new</span> <span class="title class_">TextField</span>(<span class="string">&quot;content&quot;</span>,</span><br><span class="line">				<span class="string">&quot;虽然安全播了三季，但每年都要被停播个那么几周。果不其然，这周日《极限挑战》又要停播，联系前段时间东方卫视《金星秀》《今晚80后脱口秀》宣布停播，这次《极限挑战》的停播是在警示谁？&quot;</span>,</span><br><span class="line">				Store.YES));</span><br><span class="line">		<span class="comment">// StringField 不分词</span></span><br><span class="line">		document.add(<span class="keyword">new</span> <span class="title class_">StringField</span>(<span class="string">&quot;url&quot;</span>, <span class="string">&quot;https://www.huxiu.com/article/213893.html&quot;</span>, Store.YES));</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 第三步：使用indexWriter创建索引</span></span><br><span class="line">		indexWriter.addDocument(document);</span><br><span class="line">		<span class="comment">// commit将内存中等待的数据提交到硬盘创建索引。</span></span><br><span class="line">		indexWriter.commit();</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 第四步：关闭indexwriter</span></span><br><span class="line">		indexWriter.close();</span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="/img/2017-09-09_110528.png"></p>
<h1 id="4-2、使用luke工具查看索引库"><a href="#4-2、使用luke工具查看索引库" class="headerlink" title="4.2、使用luke工具查看索引库"></a>4.2、使用luke工具查看索引库</h1><ul>
<li>分析出lucene索引库会存储两种类型的数据<ul>
<li>保存索引数据</li>
<li>保存原始数据<br>  <img src="/images/2017-09-09_105613.png"><br>  <img src="/images/2017-09-09_110305.png"></li>
</ul>
</li>
</ul>
<h1 id="4-3、查询索引的过程"><a href="#4-3、查询索引的过程" class="headerlink" title="4.3、查询索引的过程"></a>4.3、查询索引的过程</h1><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">private static void searchIndex() throws IOException &#123;</span><br><span class="line">		//需求:使用lucene查询索引</span><br><span class="line">		FSDirectory directory = FSDirectory.open(new File(&quot;index&quot;));</span><br><span class="line">		// 第一步:创建IndexSearcher，IndexSearcher 是基于索引库进行查询 ，需要先读取索引库。</span><br><span class="line">		IndexSearcher indexSearcher = new IndexSearcher(DirectoryReader.open(directory));</span><br><span class="line">		// 第二步：设置用户的关键词</span><br><span class="line">		String keyword = &quot;文娱商业观察&quot;;</span><br><span class="line">		// 第三步：根据词条进行查询</span><br><span class="line">		// 将关键词转换成一个term对象，需要指定关键词要查询字段 new Term(&quot;author&quot;, keyword)</span><br><span class="line">		TopDocs res = indexSearcher.search(new TermQuery(new Term(&quot;author&quot;, keyword)), Integer.MAX_VALUE);</span><br><span class="line">		// 第四步：从topdocs中获取数据</span><br><span class="line">		System.out.println(&quot;当前查询命中多少天数据:&quot;+res.totalHits);</span><br><span class="line">		ScoreDoc[] scoreDocs = res.scoreDocs;</span><br><span class="line">		for (ScoreDoc scoreDoc : scoreDocs) &#123;</span><br><span class="line">			System.out.println(&quot;维护在lucene内部的文档编号:&quot;+scoreDoc.doc);</span><br><span class="line">			System.out.println(&quot;当前文档的得分:&quot;+scoreDoc.score);</span><br><span class="line">			//第五步:获取单篇文章的信息</span><br><span class="line">			Document doc = indexSearcher.doc(scoreDoc.doc);</span><br><span class="line">			System.out.println(&quot;id:   &quot;+doc.get(&quot;id&quot;));</span><br><span class="line">			System.out.println(&quot;title:   &quot;+doc.get(&quot;title&quot;));</span><br><span class="line">			System.out.println(&quot;author:   &quot;+doc.get(&quot;author&quot;));</span><br><span class="line">			System.out.println(&quot;createTime:   &quot;+doc.get(&quot;createTime&quot;));</span><br><span class="line">			System.out.println(&quot;content:   &quot;+doc.get(&quot;content&quot;));</span><br><span class="line">			System.out.println(&quot;url:   &quot;+doc.get(&quot;url&quot;));</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br></pre></td></tr></table></figure>

<ul>
<li>如何知道一次搜索过程中，哪些文档相关性更强？<ul>
<li>10个文件，都包含关键词 “传智播客”</li>
<li>每篇文章中关键词都会出现？<ul>
<li>出现的次数比较多的，相关性比较大。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>#5、在项目中使用ikanalyzer分词器</p>
<ul>
<li>是什么？ <a href="https://www.oschina.net/question/28_61577">中国林良益 2012版本之后 在阿里</a></li>
<li>maven项目，2012年发布jar，没有发布到maven。<ul>
<li>需要将jar包导入到本地mvn仓库<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mvn install:install-file -Dfile=IKAnalyzer2012FF_u1.jar -DgroupId=org.wltea.ik-analyzer -DartifactId=ik-analyzer -Dversion=4.10.2 -Dpackaging=jar </span><br></pre></td></tr></table></figure>
<img src="/images/2017-09-09_143433.png"></li>
</ul>
</li>
<li>在项目中使用<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">	&lt;groupId&gt;org.wltea.ik-analyzer&lt;/groupId&gt;</span><br><span class="line">	&lt;artifactId&gt;ik-analyzer&lt;/artifactId&gt;</span><br><span class="line">	&lt;version&gt;4.10.2&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure></li>
<li>使用自己的词库<br><img src="/images/2017-09-09_143559.png"><br><img src="/images/2017-09-09_143637.png"></li>
<li>ik分词器和lucene的关系<ul>
<li>ik是一个独立的分词器<br>  <img src="/images/2017-09-09_152113.png"></li>
<li>由于lucene的查询功能底层使用了倒排索引的技术，而倒排索引需要对内容进行分词，才使用了分词技术。</li>
</ul>
</li>
</ul>
<h1 id="6、lucene的花式查询"><a href="#6、lucene的花式查询" class="headerlink" title="6、lucene的花式查询"></a>6、lucene的花式查询</h1><p><img src="/images/2017-09-09_152529.png"></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">// TermQuery query = new TermQuery(new Term(&quot;content&quot;, &quot;战&quot;));</span><br><span class="line"></span><br><span class="line">//// 通过两次置换，能够得到一个词条</span><br><span class="line"> Term term = new Term(&quot;content&quot;,&quot;大据数&quot;);</span><br><span class="line"> FuzzyQuery query = new FuzzyQuery(term);</span><br><span class="line"></span><br><span class="line">//通过前缀查询</span><br><span class="line">PrefixQuery query = new PrefixQuery(new Term(&quot;content&quot;, &quot;大&quot;));</span><br><span class="line"></span><br><span class="line">WildcardQuery query = new WildcardQuery(new Term(&quot;content&quot;,&quot;大*&quot;));</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">BooleanQuery query = new BooleanQuery();</span><br><span class="line"></span><br><span class="line">WildcardQuery wildcardQuery = new WildcardQuery(new Term(&quot;content&quot;, &quot;大*&quot;));</span><br><span class="line">query.add(wildcardQuery, Occur.MUST);</span><br><span class="line"></span><br><span class="line">PrefixQuery prefixQuery = new PrefixQuery(new Term(&quot;content&quot;, &quot;金&quot;));</span><br><span class="line">query.add(prefixQuery, Occur.MUST);</span><br><span class="line"></span><br><span class="line">//重要：在大多数情况下，用户的输入不一定是一个词条，</span><br><span class="line">//所以我们需要对用户的输入进行分词，将输入编程多个词条之后进行查询。</span><br><span class="line">Analyzer analyzer = new IKAnalyzer();</span><br><span class="line">QueryParser queryParser = new QueryParser(&quot;content&quot;, analyzer);</span><br><span class="line">Query query =queryParser.parse(&quot;学习大数据&quot;);</span><br><span class="line"></span><br><span class="line">//重要：有时候业务会提供多个字段供用户选择，店铺，商家，旺旺。</span><br><span class="line">MultiFieldQueryParser multiFieldQueryParser </span><br><span class="line">= new MultiFieldQueryParser(new String[]&#123;&quot;title&quot;,&quot;content&quot;&#125;,new IKAnalyzer());</span><br><span class="line">Query query =multiFieldQueryParser.parse(&quot;学习大数据&quot;);</span><br></pre></td></tr></table></figure>

<h1 id="7、如何使用lucene开发一个搜索引擎"><a href="#7、如何使用lucene开发一个搜索引擎" class="headerlink" title="7、如何使用lucene开发一个搜索引擎"></a>7、如何使用lucene开发一个搜索引擎</h1><ul>
<li>对外开发一个controller，这个controller提供两个方法<ul>
<li>init:读取数据库的数据，创建索引<ul>
<li>———dao————-</li>
<li>mysql jdbc DataSource</li>
<li>jdbctemplate mybatis访问</li>
<li>select * from huxiu_article;</li>
<li>———-service———–</li>
<li>得到数据库查询的结果，并封装到list集合当中</li>
<li>迭代list中的元素，将每个元素封装一个document对象<ul>
<li>调用indexWriter.add(doc)创建索引</li>
<li>调用indexWriter.commit()</li>
</ul>
</li>
<li>关闭indexWriter.close()</li>
</ul>
</li>
<li>query:查询方法，主要接受用户输入的关键字。<ul>
<li>——–controller———</li>
<li>获取数据</li>
<li>————service——–</li>
<li>将用户的关键词封装成一个query对象<ul>
<li>使用QueryParser对用户输入的关键词进行分词</li>
<li>indexSearcher.search(query,integer.max)</li>
</ul>
</li>
<li>得到索引库的返回值，封装成一个list对象。</li>
<li>返回list对象给页面</li>
<li>页面通过jstl等等技术，进行展现。</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>​		</p>
]]></content>
      <categories>
        <category>Web</category>
      </categories>
      <tags>
        <tag>搜索引擎</tag>
      </tags>
  </entry>
  <entry>
    <title>网站流量日志数据自定义采集</title>
    <url>/2019/05/28/%E7%BD%91%E7%AB%99%E6%B5%81%E9%87%8F%E6%97%A5%E5%BF%97%E6%95%B0%E6%8D%AE%E8%87%AA%E5%AE%9A%E4%B9%89%E9%87%87%E9%9B%86/</url>
    <content><![CDATA[<h3 id="原理分析"><a href="#原理分析" class="headerlink" title="原理分析"></a>原理分析</h3><p>首先，用户的行为会触发浏览器对被统计页面的一个HTTP请求。比如，让用户打开<br>一个页面时，触发页面中的埋点代码的执行。</p>
<p><img src="/images/%E5%9F%8B%E7%82%B9%E6%97%B6%E5%BA%8F%E5%9B%BE.bmp"></p>
<p><strong>埋点</strong>：事先在网页中加入的一小段js代码，这个代码片段一般会动态创建一个<br>script标签，并将src属性指向一个单独的js文件，然后这个js文件会从数据采集服务器端返回，并自动触发(js匿名函数自调用)，<br>这个js往往就是真正的数据收集脚本。数据收集完成后，js会请求一个后端的数据收集脚本，这个脚本一般是一个伪装成图片的动态<br>脚本程序，js会将收集到的数据通过HTTP参数的形式传递给后端脚本。后端脚本解析参数并按指定的格式存储该数据。同时可能会在<br>HTTP响应中给客户端种植一些用于追踪的cookie。</p>
<span id="more"></span>
<p><strong>模拟图片资源的请求，是因为<code>&lt;img&gt;</code>标签的<code>src</code>  属性有跨域请求的特性</strong></p>
<hr>
<h3 id="设计实现"><a href="#设计实现" class="headerlink" title="设计实现"></a>设计实现</h3><p>&emsp;&emsp;根据原理分析结合Google Analytics，搭建一个自定义日志数据采集系统，可以按照如下步骤进行：</p>
<p><img src="/images/%E6%97%A5%E5%BF%97%E9%87%87%E9%9B%86%E6%9E%B6%E6%9E%84%E5%9B%BE.bmp"></p>
<ul>
<li>确定收集的字段</li>
</ul>
<p><img src="/images/%E9%87%87%E9%9B%86%E5%AD%97%E6%AE%B5%E8%A1%A8.bmp"></p>
<ul>
<li>确定埋点代码</li>
</ul>
<p>&emsp;&emsp;以谷歌的Google Analytics来说，需要在页面中插入它提供的JavaScript片段，这个片段就被称为<strong>埋点代码</strong>。</p>
<figure class="highlight js"><table><tr><td class="code"><pre><span class="line">&lt;script type=<span class="string">&quot;text/javascript&quot;</span>&gt;</span><br><span class="line"><span class="keyword">var</span> _maq = _maq || [];</span><br><span class="line">_maq.<span class="title function_">push</span>([<span class="string">&#x27;_setAccount&#x27;</span>, <span class="string">&#x27;UA-XXXXX-X&#x27;</span>]);<span class="comment">//向_maq中添加一条配置</span></span><br><span class="line">(<span class="keyword">function</span>(<span class="params"></span>) &#123;</span><br><span class="line"><span class="keyword">var</span> ma = <span class="variable language_">document</span>.<span class="title function_">createElement</span>(<span class="string">&#x27;script&#x27;</span>); ma.<span class="property">type</span> =</span><br><span class="line"><span class="string">&#x27;text/javascript&#x27;</span>; ma.<span class="property">async</span> = <span class="literal">true</span>;</span><br><span class="line">ma.<span class="property">src</span> = (<span class="string">&#x27;https:&#x27;</span> == <span class="variable language_">document</span>.<span class="property">location</span>.<span class="property">protocol</span> ?</span><br><span class="line"><span class="string">&#x27;https://ssl&#x27;</span> : <span class="string">&#x27;http://www&#x27;</span>) + <span class="string">&#x27;.google-analytics.com/ma.js&#x27;</span>;</span><br><span class="line"><span class="keyword">var</span> s = <span class="variable language_">document</span>.<span class="title function_">getElementsByTagName</span>(<span class="string">&#x27;script&#x27;</span>)[<span class="number">0</span>];</span><br><span class="line">s.<span class="property">parentNode</span>.<span class="title function_">insertBefore</span>(ma, s);</span><br><span class="line">&#125;)();</span><br><span class="line">&lt;/script&gt;</span><br></pre></td></tr></table></figure>
<p>其中_maq是全局数组，用于放置配置信息，每条配置的格式为：</p>
<p><code>_maq.push([&#39;Action&#39;, &#39;param1&#39;, &#39;param2&#39;, ...]);</code></p>
<p>&emsp;&emsp;后边的匿名函数的代码主要目的就是引入一个外部的js文件(ma.js),方式是通过document.createElement方法<br>创建一个script并将<code>src</code>属性指向数据采集服务器上的ma.js，最后将这个元素插入到dom树上。<br><strong><code>ma.sync=true</code>的意思是异步调用外部js文件，即不阻塞浏览器的解析，待外部下载完成后异步执行，这个是HTML5新引入的</strong>。</p>
<p>3、前端数据收集脚本</p>
<p>&emsp;&emsp;数据收集脚本(ma.js)被请求后会被执行，一般要做如下几件事：</p>
<ol>
<li><p>通过浏览器内置的JavaScript对象收集信息，如页面title(document.title)、上一跳(document.referrer)、用户显示器分辨率(windows.screen)、cookie信息(document.cookie)等信息。</p>
</li>
<li><p>解析_maq数组，收集配置信息。可能会包含用户自定义的事件跟踪、业务数据等。</p>
</li>
<li><p>将上面两步收集的数据按预定义格式解析并拼接(get请求参数)</p>
</li>
<li><p>请求一个后端脚本，将信息放在http.request参数中携带给后端脚本。</p>
</li>
</ol>
<p> 示例代码：<br> <figure class="highlight javascript"><table><tr><td class="code"><pre><span class="line">(<span class="keyword">function</span> (<span class="params"></span>) &#123;</span><br><span class="line">    <span class="keyword">var</span> params = &#123;&#125;;</span><br><span class="line">    <span class="comment">//Document 对象数据</span></span><br><span class="line">    <span class="keyword">if</span>(<span class="variable language_">document</span>) &#123;</span><br><span class="line">        params.<span class="property">domain</span> = <span class="variable language_">document</span>.<span class="property">domain</span> || <span class="string">&#x27;&#x27;</span>;</span><br><span class="line">        params.<span class="property">url</span> = <span class="variable language_">document</span>.<span class="property">URL</span> || <span class="string">&#x27;&#x27;</span>;</span><br><span class="line">        params.<span class="property">title</span> = <span class="variable language_">document</span>.<span class="property">title</span> || <span class="string">&#x27;&#x27;</span>;</span><br><span class="line">        params.<span class="property">referrer</span> = <span class="variable language_">document</span>.<span class="property">referrer</span> || <span class="string">&#x27;&#x27;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//Window 对象数据</span></span><br><span class="line">    <span class="keyword">if</span>(<span class="variable language_">window</span> &amp;&amp; <span class="variable language_">window</span>.<span class="property">screen</span>) &#123;</span><br><span class="line">        params.<span class="property">sh</span> = <span class="variable language_">window</span>.<span class="property">screen</span>.<span class="property">height</span> || <span class="number">0</span>;</span><br><span class="line">        params.<span class="property">sw</span> = <span class="variable language_">window</span>.<span class="property">screen</span>.<span class="property">width</span> || <span class="number">0</span>;</span><br><span class="line">        params.<span class="property">cd</span> = <span class="variable language_">window</span>.<span class="property">screen</span>.<span class="property">colorDepth</span> || <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//navigator 对象数据</span></span><br><span class="line">    <span class="keyword">if</span>(navigator) &#123;</span><br><span class="line">        params.<span class="property">lang</span> = navigator.<span class="property">language</span> || <span class="string">&#x27;&#x27;</span>;</span><br><span class="line">     &#125;</span><br><span class="line"><span class="comment">//解析_maq 配置</span></span><br><span class="line"><span class="keyword">if</span>(_maq) &#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="keyword">var</span> i <span class="keyword">in</span> _maq) &#123;</span><br><span class="line">        <span class="keyword">switch</span>(_maq[i][<span class="number">0</span>]) &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="string">&#x27;_setAccount&#x27;</span>:</span><br><span class="line">        params.<span class="property">account</span> = _maq[i][<span class="number">1</span>];</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">        <span class="attr">default</span>:</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//拼接参数串</span></span><br><span class="line"><span class="keyword">var</span> args = <span class="string">&#x27;&#x27;</span>;</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">var</span> i <span class="keyword">in</span> params) &#123;</span><br><span class="line">    <span class="keyword">if</span>(args != <span class="string">&#x27;&#x27;</span>) &#123;</span><br><span class="line">        args += <span class="string">&#x27;&amp;&#x27;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    args += i + <span class="string">&#x27;=&#x27;</span> + <span class="built_in">encodeURIComponent</span>(params[i]);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//通过 Image 对象请求后端脚本</span></span><br><span class="line"><span class="keyword">var</span> img = <span class="keyword">new</span> <span class="title class_">Image</span>(<span class="number">1</span>, <span class="number">1</span>);</span><br><span class="line">img.<span class="property">src</span> = <span class="string">&#x27;http://xxx.xxxxx.xxxxx/log.gif?&#x27;</span> + args;</span><br><span class="line">&#125;)();</span><br></pre></td></tr></table></figure><br><strong>脚本放在匿名函数里，确保不会污染全局环境。其中log.gif就是后端脚本。</strong></p>
<p>4、后端脚本</p>
<p>&emsp;&emsp;log.gif是一个伪装成GIF图片的脚本。后端脚本一般需要完成以下几件事情：</p>
<p>  （1）解析HTTP请求参数得到信息。</p>
<p>  （2）从web服务器中获取一些客户端无法获取的信息。</p>
<p>  （3）将信息按格式写入log。</p>
<p>  （4）生成一个1*1的空GIF图片作为响应内容并将响应头的Content-type设为image&#x2F;gif。</p>
<p>  （5）在响应头中通过Set-cookie设置一些需要的cookie信息。(用于追踪唯一访客)</p>
<p>基于nginx的日志收集受制于nginx配置本身的逻辑表达能力有限,所以选用OpenResty来做。</p>
<p>&emsp;&emsp;OpenResty是一个基于nginx扩展出的高性能应用开发平台，内部集成了诸多有用的模块，<br>其中的核心模块就是通过ngx_lua模块集成了Lua，从而在nginx配置文件中可以通过Lua，来表述业务。</p>
<p>&emsp;&emsp;Lua是一中轻量小巧使用C语言编写的脚本语言。其设计目的就是为了嵌入应用程序中，<br>从而为应用程序提供灵活的扩展和定制功能。</p>
<p>&emsp;&emsp;首先需要在nginx的配置文件中定义日志格式：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">log_format tick</span><br><span class="line">&quot;$msec||$remote_addr||$status||$body_bytes_sent||$u_domain||$u_url|</span><br><span class="line">|$u_title||$u_referrer||$u_sh||$u_sw||$u_cd||$u_lang||$http_user_ag</span><br><span class="line">ent||$u_account&quot;;</span><br></pre></td></tr></table></figure>
<p>这里以 u_开头的是我们待会会自己定义的变量，其它的是 nginx 内置变<br>量。 然后是核心的两个 location：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">location / log.gif &#123;</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">伪装成 gif 文件</span></span><br><span class="line">default_type image/gif;</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">本身关闭 access_log，通过 subrequest 记录 <span class="built_in">log</span></span></span><br><span class="line">access_log off;</span><br><span class="line">access_by_lua &quot;</span><br><span class="line">-- 用户跟踪 cookie 名为__utrace</span><br><span class="line">local uid = ngx.var.cookie___utrace</span><br><span class="line">if not uid then</span><br><span class="line">-- 如果没有则生成一个跟踪 cookie，算法为</span><br><span class="line">md5(时间戳+IP+客户端信息)</span><br><span class="line">uid = ngx.md5(ngx.now() ..</span><br><span class="line">ngx.var.remote_addr .. ngx.var.http_user_agent)</span><br><span class="line">end</span><br><span class="line">ngx.header[&#x27;Set-Cookie&#x27;] = &#123;&#x27;__utrace=&#x27; .. uid ..</span><br><span class="line">&#x27;; path=/&#x27;&#125;</span><br><span class="line">if ngx.var.arg_domain then</span><br><span class="line">-- 通过 subrequest 子请求到/i-log 记录日志，</span><br><span class="line">将参数和用户跟踪 cookie 带过去</span><br><span class="line">ngx.location.capture(&#x27;/i-log?&#x27; ..</span><br><span class="line">ngx.var.args .. &#x27;&amp;utrace=&#x27; .. uid)</span><br><span class="line">end</span><br><span class="line">&quot;;</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">此请求资源本地不缓存</span></span><br><span class="line">add_header Expires &quot;Fri, 01 Jan 1980 00:00:00 GMT&quot;;</span><br><span class="line">add_header Pragma &quot;no-cache&quot;;</span><br><span class="line">add_header Cache-Control &quot;no-cache, max-age=0, mustrevalidate&quot;;</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">返回一个 1×1 的空 gif 图片</span></span><br><span class="line">empty_gif;</span><br><span class="line">&#125;</span><br><span class="line">location /i-log &#123;</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">内部 location，不允许外部直接访问</span></span><br><span class="line">internal;</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">设置变量，注意需要 unescape，来自 ngx_set_misc 模块</span></span><br><span class="line">set_unescape_uri $u_domain $arg_domain;</span><br><span class="line">set_unescape_uri $u_url $arg_url;</span><br><span class="line">set_unescape_uri $u_title $arg_title;</span><br><span class="line">set_unescape_uri $u_referrer $arg_referrer;</span><br><span class="line">set_unescape_uri $u_sh $arg_sh;</span><br><span class="line">set_unescape_uri $u_sw $arg_sw;</span><br><span class="line">set_unescape_uri $u_cd $arg_cd;</span><br><span class="line">set_unescape_uri $u_lang $arg_lang;</span><br><span class="line">set_unescape_uri $u_account $arg_account;</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">打开日志</span></span><br><span class="line">log_subrequest on;</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">记录日志到 ma.log 格式为 tick</span></span><br><span class="line">access_log /path/to/logs/directory/ma.log tick;</span><br><span class="line"><span class="meta prompt_">#</span><span class="language-bash">输出空字符串</span></span><br><span class="line">echo &#x27;&#x27;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>5、日志切分</p>
<p>&emsp;&emsp;日志格式主要考虑日志分隔符，一般会有一下几种选择：</p>
<ul>
<li>固定数量的字符</li>
<li>制表符分割</li>
<li>空格分隔符</li>
<li>其他一个或多个字符</li>
<li>特定的开始和结束文本</li>
</ul>
<p>6、日志切分</p>
<p>&emsp;&emsp;日志收集系统访问日志时间一长文件变得很大，而且日志放在一个文件不便<br>于管理。 通常要按时间段将日志切分，例如每天或每小时切分一个日志。通过<br>crontab 定时调用一个 shell 脚本实现，如下：</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">_prefix=&quot;/path/to/nginx&quot;</span><br><span class="line">time=`date +%Y%m%d%H`</span><br><span class="line">mv $&#123;_prefix&#125;/logs/ma.log $&#123;_prefix&#125;/logs/ma/ma-$&#123;time&#125;.log</span><br><span class="line">kill -USR1 `cat $&#123;_prefix&#125;/logs/nginx.pid `</span><br></pre></td></tr></table></figure>
<p>&emsp;&emsp;USR1 通常被用来告知应用程序重载配置文件, 向服务器发送一个 USR1 信号<br>将导致以下步骤的发生：停止接受新的连接，等待当前连接停止，重新载入配置<br>文件，重新打开日志文件，重启服务器，从而实现相对平滑的不关机的更改。</p>
<p>然后向<code>/etc/crontab</code>里加入一行：</p>
<p><code>59 * * * * root /path/to/directory/rotatelog.sh</code></p>
<p>在每个小时的 59 分启动这个脚本进行日志轮转操作。</p>
<h2 id="自定义采集数据实现"><a href="#自定义采集数据实现" class="headerlink" title="自定义采集数据实现"></a>自定义采集数据实现</h2><p>方案一：基本功能实现</p>
<p>1、创建index.html，添加埋点代码，放入nginx默认目录<code>nginx/html</code>下。</p>
<p>2、在默认目录<code>nginx/html</code>下添加一个数据采集脚本<code>ma.js</code>。</p>
<p>3、修改nginx的配置文件，添加自定义相关业务逻辑。</p>
<p>4、启动nginx,通过浏览器访问nginx。</p>
<p>5、观察自定义日志采集文件是否有对应的内容输出<br>  <code>tail -F logs/user_defined.log</code></p>
<p>方案二：页面点击事件</p>
<p>修改方案一中的数据采集脚本，将脚本内的匿名函数自调用改成由点击事件触发执行。</p>
<p>附件：<br><a href="https://github.com/wangfanming/wangfanming.GitHub.io/blob/master/%E7%BD%91%E7%AB%99%E6%97%A5%E5%BF%97%E8%87%AA%E5%AE%9A%E4%B9%89%E9%87%87%E9%9B%86/">相关文件下载</a></p>
]]></content>
      <categories>
        <category>Web</category>
      </categories>
      <tags>
        <tag>埋点</tag>
        <tag>日志采集</tag>
      </tags>
  </entry>
</search>
